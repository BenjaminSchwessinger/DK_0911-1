{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO\n",
    "import distance\n",
    "import editdistance\n",
    "import math\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import collections\n",
    "\n",
    "mpl.rcParams['font.size'] = 24\n",
    "TITLE_SIZE = 32\n",
    "AXIS_LABEL_SIZE = 28\n",
    "AXIS_TICK_SIZE = 24\n",
    "INLINE_LABEL_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENOME_VERSION = 'v04'\n",
    "PROTEINORTHO_STATUS = 'no_proteinortho' # either 'proteinortho' or 'no_proteinortho'\n",
    "\n",
    "YN00_PATH = '/home/gamran/genome_analysis/Warrior/Richard/output/post_analysis/yn00.ctl'\n",
    "BASE_OUT_PATH = '/home/gamran/genome_analysis/Warrior/Richard/output/post_analysis/%s_%s' % (GENOME_VERSION, PROTEINORTHO_STATUS)\n",
    "ALLELE_PATH = '/home/gamran/genome_analysis/Warrior/Richard/output/defining_alleles/%s_%s/allele_analysis/alleles_proteinortho_graph516/' % (GENOME_VERSION, PROTEINORTHO_STATUS)\n",
    "UNFILTERED_DF_PATH = '/home/gamran/genome_analysis/Warrior/Richard/output/defining_alleles/%s_%s/allele_analysis/DK_0911_%s_p_ctg.DK_0911_%s_h_ctg.0.001.blastp.outfmt6.allele_analysis' % (GENOME_VERSION, PROTEINORTHO_STATUS, GENOME_VERSION, GENOME_VERSION)\n",
    "GENOME_PATH = '/home/gamran/genome_analysis/Warrior/Richard/output/genome_%s/' % GENOME_VERSION\n",
    "FIGURE_PATH = os.path.join(BASE_OUT_PATH, 'figures')\n",
    "\n",
    "GENOME = 'DK_0911_%s' % GENOME_VERSION\n",
    "P_GENOME = GENOME + '_p_ctg'\n",
    "H_GENOME = GENOME + '_h_ctg'\n",
    "\n",
    "PAML_PATH = os.path.join(BASE_OUT_PATH, 'paml')\n",
    "if not os.path.exists(BASE_OUT_PATH):\n",
    "    os.mkdir(BASE_OUT_PATH)\n",
    "if not os.path.exists(FIGURE_PATH):\n",
    "    os.mkdir(FIGURE_PATH)\n",
    "if not os.path.exists(PAML_PATH):\n",
    "    os.mkdir(PAML_PATH)\n",
    "    shutil.copy2(YN00_PATH, PAML_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with all alleles\n",
    "overlapDf = pd.read_csv(os.path.join(ALLELE_PATH, '%s.h_contig_overlap.alleles' % P_GENOME), header=None, names=['alleleOne', 'alleleTwo'], sep='\\t')\n",
    "noOverlapDf = pd.read_csv(os.path.join(ALLELE_PATH, '%s.no_specific_h_contig_overlap.alleles' % P_GENOME), header=None, names=['alleleOne', 'alleleTwo'], sep='\\t')\n",
    "diffContigDf = pd.read_csv(os.path.join(ALLELE_PATH, '%s.no_respective_h_contig_overlap.alleles' % P_GENOME), header=None, names=['alleleOne', 'alleleTwo'], sep='\\t')\n",
    "manualAssignDf = pd.read_csv(os.path.join(ALLELE_PATH, '%s.manual_assigned.alleles' % H_GENOME), header=None, names=['alleleOne', 'alleleTwo'], sep='\\t')\n",
    "noAlleleDf = pd.read_csv(os.path.join(ALLELE_PATH, '%s.no_alleles' % P_GENOME), header=None, names=['alleleOne'], sep='\\t')\n",
    "\n",
    "overlapDf['matchType'] = 'overlap'\n",
    "noOverlapDf['matchType'] = 'no_overlap'\n",
    "diffContigDf['matchType'] = 'different_pcontig'\n",
    "manualAssignDf['matchType'] = 'manual_assigned'\n",
    "\n",
    "alleleDf = overlapDf.append([noOverlapDf, diffContigDf, manualAssignDf])\n",
    "\n",
    "alleleDf['folder'] = alleleDf.alleleOne + '_' + alleleDf.alleleTwo\n",
    "alleleDf.set_index('folder', inplace=True)\n",
    "\n",
    "assert(len(alleleDf) == len(overlapDf) + len(noOverlapDf) + len(diffContigDf) + len(manualAssignDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine haplotig & primary contig fasta files for each allele type\n",
    "# (protein, gene, CDS), and change headings so that they use id \n",
    "# (e.g. evm.model.pcontig_057.39) instead of locus tag (e.g. DK0911_16805).\n",
    "\n",
    "## obsolete in v031. All relevant fasta files are generated in DK_0911_v03_generate_fa_files_from_gff3.ipynb\n",
    "# os.chdir('/home/gamran/genome_analysis/Warrior/Richard/scripts')\n",
    "# %run DK_0911_v03_dictionaries.ipynb\n",
    "# locusToIdDict = getLocusToIdDict()\n",
    "\n",
    "# def combineCtgFastaFiles(fastaFiles, fOut):\n",
    "#     '''combines fasta files and rewrites headings from locus tags\n",
    "#     (DK0911_16805) to id tags (evm.model.pcontig_057.39)'''\n",
    "#     with open(fOut, 'w') as outFile:\n",
    "#         for fastaFile in fastaFiles:\n",
    "#             with open(fastaFile, 'r') as inFile:\n",
    "#                 for line in inFile:\n",
    "#                     if '>' in line:\n",
    "#                         line = '>' + locusToIdDict[line[1:-1]] + '\\n'\n",
    "#                     outFile.write(line)\n",
    "#     return True\n",
    "\n",
    "# hProteinFasta = os.path.join(GENOME_PATH, 'DK_0911_v03_h_ctg.protein.fa')\n",
    "# pProteinFasta = os.path.join(GENOME_PATH, 'DK_0911_v03_p_ctg.protein.fa')\n",
    "# hGeneFasta = os.path.join(GENOME_PATH, 'DK_0911_v03_h_ctg.gene.fa')\n",
    "# pGeneFasta = os.path.join(GENOME_PATH, 'DK_0911_v03_p_ctg.gene.fa')\n",
    "# hCDSFasta = os.path.join(GENOME_PATH, 'DK_0911_v03_h_ctg.CDS.fa')\n",
    "# pCDSFasta = os.path.join(GENOME_PATH, 'DK_0911_v03_p_ctg.CDS.fa')\n",
    "\n",
    "PH_PROTEIN_FASTA = os.path.join(GENOME_PATH, GENOME + '_ph_ctg.protein.fa')\n",
    "PH_GENE_FASTA = os.path.join(GENOME_PATH, GENOME + '_ph_ctg.gene.fa')\n",
    "PH_CDS_FASTA = os.path.join(GENOME_PATH, GENOME + '_ph_ctg.cds.fa')\n",
    "\n",
    "# combineCtgFastaFiles([hProteinFasta, pProteinFasta], PH_PROTEIN_FASTA)\n",
    "# combineCtgFastaFiles([hGeneFasta, pGeneFasta], PH_GENE_FASTA)\n",
    "# combineCtgFastaFiles([hCDSFasta, pCDSFasta], PH_CDS_FASTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFastaDict(fastaFile):\n",
    "    d = {}\n",
    "    for gene in SeqIO.parse(fastaFile, 'fasta'):\n",
    "        d[gene.id] = gene\n",
    "    return d\n",
    "\n",
    "SEQRECORD_PROTEIN_DICT = getFastaDict(PH_PROTEIN_FASTA)\n",
    "SEQRECORD_GENE_DICT = getFastaDict(PH_GENE_FASTA)\n",
    "SEQRECORD_CDS_DICT = getFastaDict(PH_CDS_FASTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getSpecificFasta(geneList, fastaFile):\n",
    "#     '''Returns the fasta of gene in list as SeqIO object '''\n",
    "#     # Ben's original code had CDS with '.model.' and \n",
    "#     # protein as '.TU.'\n",
    "#     l = []\n",
    "#     for gene in SeqIO.parse(fastaFile, 'fasta'):\n",
    "#         if gene.id in geneList:\n",
    "#             l.append(gene)\n",
    "#     return l\n",
    "# \n",
    "# def writeAllelicFasta(alleleOne, alleleTwo, alleleType, outPath):\n",
    "#     '''writes fasta file containing fasta information for two alleles\n",
    "#     in the outPath'''\n",
    "#     assert(alleleType.upper() in ['CDS', 'GENE', 'PROTEIN'])\n",
    "#     fastaFilePath = globals()['PH_' + alleleType.upper() + '_FASTA'] # e.g. alleleType = 'GENE', then fastaFile = PH_GENE_FASTA\n",
    "#     specificFastaList = getSpecificFasta([alleleOne, alleleTwo], fastaFilePath)\n",
    "#     with open(os.path.join(outPath, alleleType.lower() + '.fa'), 'w') as outFile:\n",
    "#         SeqIO.write(specificFastaList, outFile, 'fasta')\n",
    "#     return True\n",
    "\n",
    "def writeAllelicFasta(alleleOne, alleleTwo, alleleType, outPath):\n",
    "    '''writes fasta file containing fasta information for two alleles\n",
    "    in the outPath'''\n",
    "    assert(alleleType.upper() in ['CDS', 'GENE', 'PROTEIN'])\n",
    "    \n",
    "    seqRecordDict = globals()['SEQRECORD_' + alleleType.upper() + '_DICT']\n",
    "    \n",
    "    alleleSeqRecords = [seqRecordDict[alleleOne], seqRecordDict[alleleTwo]]\n",
    "    with open(os.path.join(outPath, alleleType.lower() + '.fa'), 'w') as outFile:\n",
    "        SeqIO.write(alleleSeqRecords, outFile, 'fasta')\n",
    "    return True\n",
    "\n",
    "def writeAlignmentScript(alleleOutPath, scriptLoc = os.path.join(PAML_PATH, 'paml_script.sh')):\n",
    "    with open(scriptLoc, 'a') as outFile:\n",
    "        print('cd %s' % alleleOutPath, file=outFile)\n",
    "        print('/home/gamran/anaconda3/muscle3.8.31_i86linux64 -clwstrict -in protein.fa -out protein.aln', file=outFile)\n",
    "        print('perl /home/gamran/anaconda3/pal2nal.v14/pal2nal.pl -output paml protein.aln cds.fa > cds_codon.aln', file=outFile)\n",
    "        print('perl /home/gamran/anaconda3/pal2nal.v14/pal2nal.pl protein.aln cds.fa > cds_codon.clustal', file=outFile)\n",
    "        print('cp %s/yn00.ctl ./' % PAML_PATH, file=outFile)\n",
    "        print('/home/gamran/anaconda3/paml4.9g/bin/yn00', file=outFile)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareAlignmentBashScript(scriptLoc = os.path.join(PAML_PATH, 'paml_script.sh')):\n",
    "    with open(scriptLoc, 'w') as pamlScript:\n",
    "        print('#!/bin/bash', file=pamlScript)\n",
    "\n",
    "    for index, [alleleOne, alleleTwo, alleleType] in alleleDf.iterrows():\n",
    "        alleleOutPath = os.path.join(PAML_PATH, '%s_%s' % (alleleOne, alleleTwo))\n",
    "        if not os.path.exists(alleleOutPath):\n",
    "            os.mkdir(os.path.join(PAML_PATH, '%s_%s' % (alleleOne, alleleTwo)))\n",
    "\n",
    "        writeAllelicFasta(alleleOne, alleleTwo, 'CDS', alleleOutPath)\n",
    "        writeAllelicFasta(alleleOne, alleleTwo, 'PROTEIN', alleleOutPath)\n",
    "\n",
    "        writeAlignmentScript(alleleOutPath, os.path.join(PAML_PATH, 'paml_script.sh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignDistancesToAlleles(df, folder, alignmentFile, alleleType):\n",
    "    '''Adds Hamming and Levenshtein distance columns to an allele pair\n",
    "    (indexed by 'folder' name) in df'''\n",
    "    assert(alleleType.upper() in ['PROTEIN', 'CDS', 'GENE'])\n",
    "    seq1, seq2 = AlignIO.read(open(alignmentFile, 'r'), format='clustal', seq_count=2)\n",
    "    seq1 = str(seq1.seq).upper()\n",
    "    seq2 = str(seq2.seq).upper()\n",
    "    assert(len(seq1) == len(seq2))\n",
    "    df.loc[folder, alleleType.lower() + '_hamming'] = distance.hamming(seq1, seq2, normalized=True)\n",
    "    df.loc[folder, alleleType.lower() + '_levenshtein'] = editdistance.eval(seq1, seq2)/len(seq1)\n",
    "    return df\n",
    "\n",
    "def assignDistancesToAllAlleles(alleleDf):\n",
    "    count = 0\n",
    "    total = len(alleleDf)\n",
    "    percentDone = 0\n",
    "    \n",
    "    print(\"Calculating distances and adding them to the allele DataFrame...\")\n",
    "    \n",
    "    for folder in alleleDf.index:\n",
    "\n",
    "        proteinAlignmentFile = os.path.join(PAML_PATH, folder, 'protein.aln')\n",
    "        alleleDf = assignDistancesToAlleles(alleleDf, folder, proteinAlignmentFile, 'PROTEIN')\n",
    "\n",
    "        cdsAlignmentFile = os.path.join(PAML_PATH, folder, 'cds_codon.clustal')\n",
    "        alleleDf = assignDistancesToAlleles(alleleDf, folder, cdsAlignmentFile, 'CDS')\n",
    "\n",
    "        count += 1\n",
    "        if round(count/total * 100) > percentDone:\n",
    "            percentDone = round(count/total * 100)\n",
    "            print(\"%s%% complete\" % percentDone)\n",
    "    return alleleDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dNdS_to_df(line, alleleDf, folder, dNdS_label):\n",
    "    dN = re.findall(r'dN = [-| ]?(.*) w', line)[0]\n",
    "    dS = re.findall(r'dS = [-| ]?(.*) dN', line)[0]\n",
    "    return assign_dNdS(dN, dS, alleleDf, folder, dNdS_label)\n",
    "\n",
    "def assign_dNdS(dN, dS, alleleDf, folder, dNdS_label):\n",
    "    if float(dS) > 0:\n",
    "        alleleDf.loc[folder, dNdS_label] = float(dN)/float(dS)\n",
    "    else:\n",
    "        alleleDf.loc[folder, dNdS_label] = np.nan\n",
    "    return alleleDf\n",
    "\n",
    "def assign_dNdS_to_all_alleles(alleleDf):\n",
    "    for folder in alleleDf.index:\n",
    "        alleleYn = os.path.join(PAML_PATH, folder,'yn.out')\n",
    "        with open(alleleYn, 'r') as ynOut:\n",
    "            #now loop over the lines and parse out stuff\n",
    "            for i, line in enumerate(ynOut):\n",
    "                if line.startswith('seq. seq. ') and i > 0:\n",
    "                    next(ynOut) # we want the line that is two after the line starting with 'seq. seq '\n",
    "                    dataLine = next(ynOut)\n",
    "                    dN = dataLine.split('+-')[0].rstrip().split(' ')[-1]\n",
    "                    dS = dataLine.split('+-')[1].rstrip().split(' ')[-1]\n",
    "                    alleleDf = assign_dNdS(dN, dS, alleleDf, folder, 'yn00_dN/dS')\n",
    "                elif line.startswith('LWL85:') and 'nan' not in line:\n",
    "                    alleleDf = parse_dNdS_to_df(line, alleleDf, folder, 'LWL85_dN/dS')\n",
    "                elif line.startswith('LWL85m:') and 'nan' not in line:\n",
    "                    alleleDf = parse_dNdS_to_df(line, alleleDf, folder, 'LWL85m_dN/dS')\n",
    "                elif line.startswith('LPB93:') and 'nan' not in line:\n",
    "                    alleleDf = parse_dNdS_to_df(line, alleleDf, folder, 'LPB93_dN/dS')\n",
    "                else:\n",
    "                    continue\n",
    "    return alleleDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(alleleDf = alleleDf):\n",
    "    prepareAlignmentBashScript(os.path.join(PAML_PATH, 'paml_script.sh'))\n",
    "    \n",
    "    # !bash {os.path.join(PAML_PATH, 'paml_script.sh')}\n",
    "    \n",
    "    distDfPath = os.path.join(BASE_OUT_PATH, GENOME+'_distanceDf.df')\n",
    "    if os.path.exists(distDfPath) and os.path.getsize(distDfPath) > 0:\n",
    "        print(\"DataFrame with distance calculations at %s appears to have already been generated. Reading in this dataframe instead of re-generating it.\" % distDfPath)\n",
    "        alleleDf = pd.read_csv(distDfPath, sep='\\t', index_col=0)\n",
    "    else:\n",
    "        alleleDf = assignDistancesToAllAlleles(alleleDf)\n",
    "        alleleDf.to_csv(distDfPath, sep='\\t')\n",
    "        pd.util.testing.assert_frame_equal(alleleDf, pd.read_csv(distDfPath, sep='\\t', index_col=0))\n",
    "    \n",
    "    alleleDf = assign_dNdS_to_all_alleles(alleleDf)\n",
    "    alleleDf.to_csv(distDfPath, sep='\\t')\n",
    "    \n",
    "    return alleleDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with distance calculations at /home/gamran/genome_analysis/Warrior/Richard/output/post_analysis/v04_no_proteinortho/DK_0911_v04_distanceDf.df appears to have already been generated. Reading in this dataframe instead of re-generating it.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    alleleDf = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceGroups(g):\n",
    "    '''returns the best hit based on e-value and BitScore per group'''\n",
    "    if len(g) == 1:\n",
    "        return g\n",
    "    tmp_g = g[g['e-value'] == g['e-value'].min()]\n",
    "    if len(tmp_g) == 1:\n",
    "        return tmp_g\n",
    "    return tmp_g[tmp_g['BitScore'] == tmp_g['BitScore'].max()]\n",
    "\n",
    "def filterAlleleDf(alleleDf, qCov, pctId):\n",
    "    unfilteredDf = pd.read_csv(UNFILTERED_DF_PATH, sep='\\t')\n",
    "    unfilteredDf['folder'] = unfilteredDf['Query'] + '_' + unfilteredDf['Target']\n",
    "    filteredDf = unfilteredDf[unfilteredDf['folder'].isin(alleleDf.index)].groupby('folder').apply(lambda g:reduceGroups(g))\n",
    "    detailedAlleleDf = alleleDf.merge(filteredDf, left_index=True, right_on='folder')\n",
    "    if qCov and pctId:\n",
    "        filteredAlleleDf = detailedAlleleDf[(detailedAlleleDf['QCov'] > qCov) & (detailedAlleleDf['PctID'] > pctId)]\n",
    "    elif qCov:\n",
    "        filteredAlleleDf = detailedAlleleDf[detailedAlleleDf['QCov'] > qCov]\n",
    "    elif pctId:\n",
    "        filteredAlleleDf = detailedAlleleDf[detailedAlleleDf['PctID'] > pctId]\n",
    "    else:\n",
    "        filteredAlleleDf = alleleDf # no filtering\n",
    "\n",
    "    displacedAlleles = len(detailedAlleleDf) - len(filteredAlleleDf)\n",
    "    return filteredAlleleDf, displacedAlleles\n",
    "    ## assert(len(filteredDf) == len(alleleDf) - len(manualAssignDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        return '{p:.2f}%\\n({v:d})'.format(p=pct,v=val)\n",
    "    return my_autopct\n",
    "\n",
    "def autolabel(rects, labels, ax, fontsize):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for i, rect in enumerate(rects):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., height, str(labels[i]), ha='center', va='bottom', fontsize=fontsize)\n",
    "\n",
    "def plotPrimaryProteinPie(ax, colors, extraNoAllele=0):\n",
    "    # OrderedDict to preserve order, so that plots are coloured with same key as the distance \n",
    "    # bar graphs. This is a bit of a hack-fix; must enter these by hand again in the same order \n",
    "    # as 'matchType' occurs in the dist DataFrame.\n",
    "    pProteinTypeCountDict = collections.OrderedDict()\n",
    "    pProteinTypeCountDict['different_pcontig'] = len(alleleDf[alleleDf['matchType'] == 'different_pcontig']['alleleOne'].unique())\n",
    "    pProteinTypeCountDict['no_allele'] = len(noAlleleDf['alleleOne'].unique()) + extraNoAllele\n",
    "    pProteinTypeCountDict['no_overlap'] = len(alleleDf[alleleDf['matchType'] == 'no_overlap']['alleleOne'].unique())\n",
    "    pProteinTypeCountDict['overlap'] = len(alleleDf[alleleDf['matchType'] == 'overlap']['alleleOne'].unique())\n",
    "\n",
    "    patches, texts, autotexts = ax.pie(list(pProteinTypeCountDict.values()), labels=pProteinTypeCountDict.keys(), autopct=make_autopct(list(pProteinTypeCountDict.values())), colors=colors)\n",
    "    ax.axis('equal')\n",
    "    ax.set_title('Primary Protein Allele Types', loc='center', fontsize=TITLE_SIZE, position=(0.5, 1.1))\n",
    "\n",
    "def plotLevenshteinBar(distDf, ax, colors):\n",
    "    ind = np.arange(len(distDf.protein_levenshtein))\n",
    "    rects = ax.bar(ind, distDf.protein_levenshtein, color=colors, align='center')\n",
    "\n",
    "    barLabels = []\n",
    "    for levDist in distDf.protein_levenshtein:\n",
    "        barLabels.append(str(int((1-levDist)*100)) + '%')\n",
    "    autolabel(rects, barLabels, ax, INLINE_LABEL_SIZE)\n",
    "\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels(distDf.index, {'fontsize':AXIS_TICK_SIZE, 'horizontalalignment':'center'})\n",
    "\n",
    "    ax.set_xlabel('Primary Protein Allele Type', fontsize=AXIS_LABEL_SIZE)\n",
    "    ax.set_ylabel('Protein Normalised Levenshtein Distance', fontsize=AXIS_LABEL_SIZE)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=AXIS_TICK_SIZE, pad=3)\n",
    "\n",
    "    for tick in ax.get_xaxis().get_major_ticks():\n",
    "        tick.set_pad(2*tick.get_pad())\n",
    "        tick.label1 = tick._get_text1()\n",
    "        \n",
    "def plotAlleles(alleleDf):\n",
    "    cmap = plt.cm.Greens\n",
    "    colors = cmap(np.linspace(0.0, 0.6, len(alleleDf['matchType'].unique())))\n",
    "    \n",
    "    fig, ax = plt.subplots(3, 2, figsize=(26*2, 12*3))\n",
    "    \n",
    "    for i, qCovCutoff in enumerate([50, 70, 90]):\n",
    "        filteredAlleleDf, extraNoAllele = filterAlleleDf(alleleDf, qCovCutoff, False)\n",
    "        dist = filteredAlleleDf.groupby(['matchType']).mean()\n",
    "\n",
    "        plotLevenshteinBar(dist, ax[i, 0], colors)\n",
    "        plotPrimaryProteinPie(ax[i, 1], colors, extraNoAllele)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(FIGURE_PATH, 'fig'), bbox_inches='tight')\n",
    "\n",
    "plotAlleles(alleleDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailedAlleleDf = alleleDf.merge(filteredDf, left_index=True, right_on='folder')\n",
    "len(detailedAlleleDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
