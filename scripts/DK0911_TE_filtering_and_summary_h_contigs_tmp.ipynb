{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed at summarzing the REPET output at different levels of the nomenclature and to plot this out. Parts of it are really slow.\n",
    "\n",
    "\n",
    "This notebook was only designed for the purpose of analyzing the Pst-104E genome. No gurantees it works in any other situtation. It will have spelling errors due to the lack of autocorrection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:44:54.641666Z",
     "start_time": "2019-04-07T06:44:51.667667Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/Bio/SearchIO/__init__.py:211: BiopythonExperimentalWarning: Bio.SearchIO is an experimental submodule which may undergo significant changes prior to its future official release.\n",
      "  BiopythonExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SearchIO\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import multiprocessing\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:11.506390Z",
     "start_time": "2019-04-07T06:58:11.391828Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ID_filter_gff(_feature, _id):\n",
    "    \"\"\"\n",
    "    This filter parses out the top level id form the 9th gff column form a REPET gff file.\n",
    "    It has a specific search pattern for each feature type in column 2.\n",
    "    _type is defined by the feature '_'.join(feature.split(\"_\")[-2:])\n",
    "    This function expects that the variable genome either ends with p_ctg or h_ctg and adapts the\n",
    "    search pattern accordingly.\n",
    "    \"\"\"\n",
    "    _type = '_'.join(_feature.split(\"_\")[-2:])\n",
    "    if _type == 'REPET_TEs':\n",
    "        if genome.endswith('p_ctg'):\n",
    "            TE_pattern = r'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_([^;| ]*)'\n",
    "        elif genome.endswith('h_ctg'):\n",
    "            TE_pattern = r'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_[0-9]*_([^;| ]*)'\n",
    "        TE_prog = re.compile(TE_pattern)\n",
    "        TE_match = TE_prog.search(_id)\n",
    "\n",
    "        try:\n",
    "            return TE_match.group(1)\n",
    "        except AttributeError:\n",
    "            print(_id)\n",
    "\n",
    "    if _type == 'REPET_SSRs':\n",
    "        if genome.endswith('p_ctg'):\n",
    "            SSR_pattern = 'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_([A-Z,a-z,0-9,-]*)'\n",
    "        elif genome.endswith('h_ctg'):\n",
    "            SSR_pattern = 'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_[0-9]*_([A-Z,a-z,0-9,-]*)'\n",
    "        SSR_prog = re.compile(SSR_pattern)\n",
    "        SSR_match = SSR_prog.search(_id)\n",
    "        return SSR_match.group(1)\n",
    "    if _type == 'REPET_tblastx' or _type == 'REPET_blastx':\n",
    "        if genome.endswith('p_ctg'):\n",
    "            blast_prog = re.compile(r'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_([^;| ]*)')\n",
    "        elif genome.endswith('h_ctg'):\n",
    "             blast_prog = re.compile(r'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_[0-9]*_([^;| ]*)')\n",
    "        #blast_prog = re.compile(blast_pattern)\n",
    "        blast_match = blast_prog.search(_id)\n",
    "        return blast_match.group(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:12.245177Z",
     "start_time": "2019-04-07T06:58:12.107778Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blast_hit_gff(_feature, _row8, _id):\n",
    "    \"\"\"\n",
    "    This filter parses the blast hit for REPET_TEs from the new 'ID' column. If no blast hit available returns Pastec ids.\n",
    "    If the result is blast already the value is simple parse the blast hit.\n",
    "    SSRs also get SSR\n",
    "    !!!Requires the three_letter_dict to be defined previously.!!!\n",
    "    _type is defined by the feature '_'.join(feature.split(\"_\")[-2:])\n",
    "    \"\"\"\n",
    "    _type = '_'.join(_feature.split(\"_\")[-2:])\n",
    "    if _type == 'REPET_TEs':\n",
    "        #split the pastec_cat into the first three letter code\n",
    "        #the spliting of the 'ID' column needs to be done differently depending on the h or p contigs.\n",
    "        #h contigs contain one additional '_' in the contig id\n",
    "\n",
    "        pastec_cat = _id.split('_')[0]\n",
    "        if 'TE_BLR' in _row8:\n",
    "            #hit_list = [x.split(';')[3] for x in _row8]\n",
    "            blast_hit_pattern = r'TE_BLR\\w*: (\\S*)[ |;]'\n",
    "            blast_hit_prog = re.compile(blast_hit_pattern)\n",
    "            TE_match = blast_hit_prog.findall(_row8)\n",
    "            first_sub_class = ':'.join(TE_match[0][:-1].split(':')[1:])\n",
    "            if len([x for x in TE_match if first_sub_class in x]) == len(TE_match):\n",
    "                if ';' in first_sub_class:\n",
    "                    return first_sub_class.split(';')[0]\n",
    "                else:\n",
    "                    return first_sub_class\n",
    "#fix this here to include the there letter code of the first bit of the ID similar to the blast hits\n",
    "#e.g. ClassI:?:? and so on. a dict might be the easiest here.\n",
    "            \n",
    "            else:\n",
    "                return three_letter_dict[pastec_cat]\n",
    "        else:\n",
    "            return three_letter_dict[pastec_cat]\n",
    "    if _type == 'REPET_SSRs':\n",
    "        return 'SSR'\n",
    "        \n",
    "\n",
    "        return SSR_match.group(1)\n",
    "    if _type == 'REPET_tblastx' or _type == 'REPET_blastx':\n",
    "        return ':'.join(_id.split(':')[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:12.821058Z",
     "start_time": "2019-04-07T06:58:12.759826Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TE_classification_filter(_id, level = 0):\n",
    "    \"\"\"\n",
    "    This function pulls out the class == level1, Order == level2, Superfamily == leve3.\n",
    "    If SSR or noCat return these values.\n",
    "    \n",
    "    \"\"\"\n",
    "    if len(_id.split(':')) == 1:\n",
    "        return _id\n",
    "    if level == 0:\n",
    "        _class = _id.split(':')[0]\n",
    "        if _class == 'ClassI':\n",
    "            return 'Retrotransposon'\n",
    "        if _class == 'ClassII':\n",
    "            return 'DNA_transposon'\n",
    "    elif level == 1:\n",
    "        _order = _id.split(':')[1]\n",
    "        if _order == '?':\n",
    "            return 'noCat'\n",
    "        else:\n",
    "            return _order\n",
    "    elif level == 2:\n",
    "        _superfamily = _id.split(':')[2]\n",
    "        if _superfamily == '?':\n",
    "            return 'noCat'\n",
    "        else:\n",
    "            return _superfamily\n",
    "    else:\n",
    "        print('Something wrong! Check if level is 0, 1 or 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:13.425168Z",
     "start_time": "2019-04-07T06:58:13.375815Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset the id and safe in specific folder\n",
    "# return the subsetted file as bedtool\n",
    "def subset_id(_id, bed_fh, repet_prefix, genome_file_fh):\n",
    "    '''A function that takes the a ID, e.g. from the ID column 9 of a gff,\n",
    "    a bed file handle, e.g. the gff frame, a certain file prefix, and a genome_file handle.\n",
    "    It saves out the coverage file and the gff file for the specific ID.'''\n",
    "    #ClassI are retrotransposon form blast\n",
    "    if 'ClassI:' in _id:\n",
    "        out_path = TE_path_dict['Retrotransposon']   \n",
    "    #ClassII are DNA_transponson\n",
    "    elif 'ClassII' in _id:\n",
    "        out_path = TE_path_dict['DNA_transposon'] \n",
    "    #The rest with '_' should be REPET_TEs\n",
    "    elif _id == 'noCat':\n",
    "        out_path = TE_path_dict['noCat']\n",
    "    #everything without '_' at the end should be SSR\n",
    "    elif _id == 'SSR':\n",
    "        out_path = TE_path_dict['SSR']\n",
    "    cov_fh = os.path.join(out_path,'%s.%s.cov' %(repet_prefix,_id))\n",
    "    gff_fh = cov_fh.replace('.cov', '.gff')\n",
    "    result = pybedtools.BedTool(bed_fh).filter(id_filter, _id).saveas(gff_fh)\n",
    "    result.genome_coverage(dz=True,g=genome_file_fh).saveas(cov_fh)\n",
    "    print('Done with callculating coverage of %s.'% _id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:14.017187Z",
     "start_time": "2019-04-07T06:58:13.987771Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next, we create a function to pass only features for a particular\n",
    "# featuretype.  This is similar to a \"grep\" operation when applied to every\n",
    "# feature in a BedTool\n",
    "def id_filter(feature, _id):\n",
    "    if feature[8] == _id:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:14.897178Z",
     "start_time": "2019-04-07T06:58:14.775865Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def samcov_slurp(file_name, mean=False, fil=True):\n",
    "    \"\"\"\n",
    "    Function that slurps in the the file via the file_name and tests if looks a samcov file.\n",
    "    If this is the case it makes a dataframe out of the samcov file and calculates the following values.\n",
    "    Ave_cov per window, which is the average coverage for each genomic interval. \n",
    "    Norm_cov per window, is the normalized coverage for each genomic interavl. This\n",
    "    can be either calculated by via the mean coverage of the dataframe or via a provided mean.\n",
    "    \"\"\"\n",
    "    if file_name.endswith('.samcov') == False:\n",
    "        print(\"%s Might not be a samcov file. Please check\" % file_name)\n",
    "        return False\n",
    "        \n",
    "    samcov_header_bed_3 = ['contig', 'start', 'stop', 'total_cov']\n",
    "    samcov_header_bed_6 = ['contig', 'start', 'stop', 'ID', 'score', 'strand','total_cov']\n",
    "    df = pd.read_csv(file_name, sep='\\t', header=None)\n",
    "    if len(df.columns) == 4:\n",
    "        df.rename(columns=dict(zip(df.columns, samcov_header_bed_3)), inplace=True)\n",
    "    elif len(df.columns) == 7:\n",
    "        df.rename(columns=dict(zip(df.columns, samcov_header_bed_6)), inplace=True)\n",
    "    else:\n",
    "        print(\"%s Might not be a samcov file. Please check\" % file_name)\n",
    "        return False\n",
    "    \n",
    "    df['interval_size'] = (df.stop-df.start)\n",
    "    df['ave_cov'] = df.total_cov/df['interval_size']\n",
    "    if mean == False:\n",
    "        df_mean = sum(df.total_cov)/sum(df.interval_size)\n",
    "        df['norm_cov'] = df['ave_cov']/df_mean\n",
    "    else:\n",
    "        df['norm_cov'] = df['ave_cov']/mean\n",
    "    #rounder = pd.Series([0,0,0,0,2], index = df.columns)\n",
    "    df.ave_cov = df.ave_cov.round()\n",
    "    if fil == True:\n",
    "        low = 0 #these were defined empirical based on the iqr caculations using 0.01 \n",
    "        high = 400 #and 0.99 as cut off.\n",
    "        df = df[(df.ave_cov >= low) & (df.ave_cov <= high)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:16.521164Z",
     "start_time": "2019-04-07T06:58:16.499807Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_samtools_bedcov(window_bed_fn, bam_fn, output_fh):\n",
    "    \"\"\"Runs samtools bedcov as a subprocess so we can paralize the different runs saving some time.\n",
    "    Input: \n",
    "    The window_bed fn for which the samtools bedcov should be calculated.\n",
    "    The bam_fn file that contains the read mapping.\n",
    "    The output_fn where the output is saved to.\n",
    "    These should be absolute path\"\"\"\n",
    "    cmd = r'samtools bedcov %s %s > %s' % (window_bed_fn, bam_fn,output_fh)\n",
    "    stderr = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)\n",
    "    print('Done with %s' % cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "This notebook runs on DK0911v03/4 which are the same as the pwoh to h re-assignment has already been completed. \n",
    "REPET was run in the two round annotation mode (see /home/benjamin/genome_assembly/Warrior/REPET/TEanno/primary/TEanno01_finish.sh) for details. The repeat database was 104Ep_DK0911p/104Ep_DK0911p_withoutRedundancy.fa which was produced by combining newly discovered REPEATs from DK0911 and Pst104Ep. The classif_table in the SQL was 104Ep_DK0911p_classif.\n",
    "All REPET gff files got combined as follows using the the naming convention GENOME.DENOVODATABASE.REPET.gff.  \n",
    "\n",
    "This is the summary for the haplotigs with the same settings as for the primary contigs the folder is /home/benjamin/genome_assembly/Warrior/REPET/TEanno/haplotigs\n",
    "\n",
    "\n",
    "DK_0911_v04_p_ctg.104Ep_DK0911p.REPET.gff3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change following input here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:19.893155Z",
     "start_time": "2019-04-07T06:58:19.875685Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_dir = '/home/benjamin/genome_assembly/Warrior/genome_v04/'\n",
    "genome = 'DK_0911_v04_h_ctg'\n",
    "#in case the genome version for the REPET run had a different ID.\n",
    "genome_repet = 'DK0911v04ha1'\n",
    "Tenovodb = '104Ep_DK0911p'\n",
    "out_dir = '/home/benjamin/genome_assembly/Warrior/TE_analysis'\n",
    "repet_db_dir = '/home/benjamin/databases/REPET'\n",
    "#This needs to be updated here according to genome\n",
    "TE_postanalysis_dir = '/home/benjamin/genome_assembly/Warrior/REPET/TEanno/haplotigs/TEanno_full/postanalysis'\n",
    "#threads to use for multithreading\n",
    "threads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:21.885135Z",
     "start_time": "2019-04-07T06:58:21.878399Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T08:00:36.982380Z",
     "start_time": "2018-04-05T08:00:36.975525Z"
    },
    "collapsed": true
   },
   "source": [
    "###here are some input files for the mapping rate coverage analysis using SRM\n",
    "SRM_dir = '/home/benjamin/genome_assembly/Warrior/SRM'\n",
    "pbam_fh = os.path.join(SRM_dir, 'DK_0911_v03_p_ctg.bwamem.PRI_NTKN_DK0911.sam.sorted.bam')\n",
    "genome_fh = os.path.join(source_dir, '%s.fa' %genome)\n",
    "genome_file_fh = os.path.join(source_dir, '%s.genome_file' %genome)\n",
    "TE_gff_fh = os.path.join(out_dir,'%s.%s.REPET.gff3' % (genome, Tenovodb))\n",
    "#protein_busco_fh = '/home/benjamin/genome_assembly/Warrior/busco/genome_v4/run_DK_0911_v04LT_p_ctg.protein/full_table_DK_0911_v04LT_p_ctg.protein.tsv'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T08:00:36.986737Z",
     "start_time": "2018-04-05T08:00:36.983992Z"
    },
    "collapsed": true
   },
   "source": [
    "#the window size for downstream coverage analysis\n",
    "window_size = 5000\n",
    "slide_size = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T08:00:36.991813Z",
     "start_time": "2018-04-05T08:00:36.988215Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "source": [
    "#now generate the genmoe files if not present yet\n",
    "if not os.path.exists(genome_file_fh):\n",
    "    !samtools faidx {genome_fh}\n",
    "    !cat {genome_fh}.fai | sort -k1,1n | cut -f 1,2 > {genome_file_fh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:28.505256Z",
     "start_time": "2019-04-07T06:58:27.979754Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove all commenting lines from the initial repet file\n",
    "!grep -v \"^#\" {source_dir}/{genome}.{Tenovodb}.REPET.gff3 > {out_dir}/{genome}.{Tenovodb}.REPET.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:30.654806Z",
     "start_time": "2019-04-07T06:58:28.699796Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in repet_gff file\n",
    "repet_gff = pd.read_csv(os.path.join(out_dir, '%s.%s.REPET.gff3'%(genome,Tenovodb)), sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:30.664136Z",
     "start_time": "2019-04-07T06:58:30.656601Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TE_post_analysis_p_header = 'TE      length  covg    frags   fullLgthFrags   copies  fullLgthCopies  meanId  sdId    minId   q25Id   medId   q75Id   maxId   meanLgth        sdLgth  minLgth q25Lgth medLgth q75Lgth maxLgth meanLgthPerc    sdLgthPerc      minLgthPerc  q25LgthPerc     medLgthPerc     q75LgthPerc     maxLgthPerc'.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:30.672992Z",
     "start_time": "2019-04-07T06:58:30.665659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TE_post_analysis_p_header = [x for x in TE_post_analysis_p_header if x != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:32.253231Z",
     "start_time": "2019-04-07T06:58:32.038241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blastclust.log\r\n",
      "DK0911v04ha1_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_FullLengthCopy.fa\r\n",
      "DK0911v04ha1_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_FullLengthCopy.txt\r\n",
      "DK0911v04ha1_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_FullLengthFrag.fa\r\n",
      "DK0911v04ha1_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_FullLengthFrag.txt\r\n",
      "DK0911v04ha1_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_OneCopyAndMore.fa\r\n",
      "DK0911v04ha1_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_OneCopyAndMore.txt\r\n",
      "DK0911v04ha1_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE.tab\r\n",
      "DK0911v04ha1_chr_allTEs_nr_noSSR_join_path.globalAnnotStatsPerTE.txt\r\n",
      "DK0911v04ha1_chr_allTEs_path.annotStatsPerTE_FullLengthCopy.fa\r\n",
      "DK0911v04ha1_chr_allTEs_path.annotStatsPerTE_FullLengthCopy.txt\r\n",
      "DK0911v04ha1_chr_allTEs_path.annotStatsPerTE_FullLengthFrag.fa\r\n",
      "DK0911v04ha1_chr_allTEs_path.annotStatsPerTE_FullLengthFrag.txt\r\n",
      "DK0911v04ha1_chr_allTEs_path.annotStatsPerTE_OneCopyAndMore.fa\r\n",
      "DK0911v04ha1_chr_allTEs_path.annotStatsPerTE_OneCopyAndMore.txt\r\n",
      "DK0911v04ha1_chr_allTEs_path.annotStatsPerTE.tab\r\n",
      "DK0911v04ha1_chr_allTEs_path.globalAnnotStatsPerTE.txt\r\n",
      "DK0911v04ha1_chr_bankBLRtx_path.annotStatsPerTE_FullLengthCopy.fa\r\n",
      "DK0911v04ha1_chr_bankBLRtx_path.annotStatsPerTE_FullLengthCopy.txt\r\n",
      "DK0911v04ha1_chr_bankBLRtx_path.annotStatsPerTE_FullLengthFrag.fa\r\n",
      "DK0911v04ha1_chr_bankBLRtx_path.annotStatsPerTE_FullLengthFrag.txt\r\n",
      "DK0911v04ha1_chr_bankBLRtx_path.annotStatsPerTE_OneCopyAndMore.fa\r\n",
      "DK0911v04ha1_chr_bankBLRtx_path.annotStatsPerTE_OneCopyAndMore.txt\r\n",
      "DK0911v04ha1_chr_bankBLRtx_path.annotStatsPerTE.tab\r\n",
      "DK0911v04ha1_chr_bankBLRtx_path.globalAnnotStatsPerTE.txt\r\n",
      "DK0911v04ha1_chr_bankBLRx_path.annotStatsPerTE_FullLengthCopy.fa\r\n",
      "DK0911v04ha1_chr_bankBLRx_path.annotStatsPerTE_FullLengthCopy.txt\r\n",
      "DK0911v04ha1_chr_bankBLRx_path.annotStatsPerTE_FullLengthFrag.fa\r\n",
      "DK0911v04ha1_chr_bankBLRx_path.annotStatsPerTE_FullLengthFrag.txt\r\n",
      "DK0911v04ha1_chr_bankBLRx_path.annotStatsPerTE_OneCopyAndMore.fa\r\n",
      "DK0911v04ha1_chr_bankBLRx_path.annotStatsPerTE_OneCopyAndMore.txt\r\n",
      "DK0911v04ha1_chr_bankBLRx_path.annotStatsPerTE.tab\r\n",
      "DK0911v04ha1_chr_bankBLRx_path.globalAnnotStatsPerTE.txt\r\n",
      "DK0911v04ha1_refTEs.fa\r\n",
      "DK0911v04ha1_refTEs.fa_blastclust.classifStatsPerCluster.tab\r\n",
      "DK0911v04ha1_refTEs.fa_blastclust.globalStatsPerCluster.txt\r\n",
      "DK0911v04ha1_refTEs.fa_blastclust.statsPerCluster.tab\r\n",
      "DK0911v04ha1_refTEs.fa_blastclust.tab\r\n",
      "error.log\r\n"
     ]
    }
   ],
   "source": [
    "!ls {TE_postanalysis_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This needs to be updated here according to genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:35.949164Z",
     "start_time": "2019-04-07T06:58:35.902562Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this needs to be fixed up to pick the proper summary table\n",
    "#this reads in the REPET summary dataframe\n",
    "REPET_sdf = pd.read_csv(os.path.join(TE_postanalysis_dir,\\\n",
    "                    '%s_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE.tab' % genome_repet),\\\n",
    "                        names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n",
    "#this pulls out the TE classificaiton from the TE column\n",
    "REPET_sdf['Code'] = REPET_sdf['TE'].apply(lambda x: x.split('_')[0])\n",
    "code_keys = REPET_sdf['Code'].unique()\n",
    "code_keys.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:36.909280Z",
     "start_time": "2019-04-07T06:58:36.898311Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the previous code_dict from file in the repet database folder\n",
    "with open(os.path.join(repet_db_dir, 'code_dict.dict'), 'r') as file:\n",
    "    code_dict = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:37.673325Z",
     "start_time": "2019-04-07T06:58:37.647737Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now check if all code keys to long classifications are already in the dict\n",
    "#if this isn't the case get the missing keys\n",
    "execute_cell = False\n",
    "if set(code_keys).issubset(set(code_dict.keys()))  == False:\n",
    "    execute_cell = True\n",
    "    missing_keys = []\n",
    "    for x in code_keys:\n",
    "        if x not in code_dict.keys():\n",
    "            missing_keys.append(x)\n",
    "            print('Please add the following key value pair to the dictionary and save it out: %s'%x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:38.661144Z",
     "start_time": "2019-04-07T06:58:38.635706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing new\n"
     ]
    }
   ],
   "source": [
    "#now get some user input for the missing code: long namenclature pairing via a widget\n",
    "dict_parings = 'Nothing new'\n",
    "if execute_cell == True:\n",
    "    dict_parings = widgets.Text()\n",
    "    print('These are the new required additions to the dictionary\\n\\n')\n",
    "    print(missing_keys)\n",
    "    print('Please enter as key:value, key:value') #define how the widget should be filled\n",
    "    ##TO DO, write a test for this being entered correctly###\n",
    "    print('\\n\\n')\n",
    "    print(code_dict)\n",
    "else:\n",
    "    print(dict_parings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:40.345239Z",
     "start_time": "2019-04-07T06:58:40.311679Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now add the new key: value pair to the dictionary\n",
    "if dict_parings != 'Nothing new':\n",
    "    print(dict_parings.value)\n",
    "    keys = []\n",
    "    values = []\n",
    "    for element in dict_parings.value.split(','):\n",
    "        keys.append(element.split(':')[0].strip())\n",
    "        values.append(element.split(':')[1].strip())\n",
    "    code_dict.update(dict(zip(keys,values)))\n",
    "    print(\"Updating the code_dict\")\n",
    "    with open(os.path.join(repet_db_dir, 'code_dict.dict'), 'w') as file:\n",
    "        file.write(json.dumps(code_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:41.749184Z",
     "start_time": "2019-04-07T06:58:41.679659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick summary for each category based on the REPET summary dataframe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>copies</th>\n",
       "      <th>covg</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Code long</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DNA_transposon Helitron</th>\n",
       "      <td>1123</td>\n",
       "      <td>845310</td>\n",
       "      <td>6380.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon MITE</th>\n",
       "      <td>3765</td>\n",
       "      <td>944799</td>\n",
       "      <td>505.373016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon Maverick</th>\n",
       "      <td>273</td>\n",
       "      <td>339526</td>\n",
       "      <td>9420.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon TIR</th>\n",
       "      <td>11885</td>\n",
       "      <td>7214473</td>\n",
       "      <td>3525.890449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon noCat</th>\n",
       "      <td>3099</td>\n",
       "      <td>1056219</td>\n",
       "      <td>2274.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Potential Host Gene</th>\n",
       "      <td>618</td>\n",
       "      <td>417246</td>\n",
       "      <td>4390.378378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon DIRS</th>\n",
       "      <td>770</td>\n",
       "      <td>591535</td>\n",
       "      <td>8770.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon LARD</th>\n",
       "      <td>6353</td>\n",
       "      <td>2908933</td>\n",
       "      <td>5422.674074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon LINE</th>\n",
       "      <td>378</td>\n",
       "      <td>248262</td>\n",
       "      <td>4333.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon LTR</th>\n",
       "      <td>11016</td>\n",
       "      <td>9251050</td>\n",
       "      <td>6070.630923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon SINE</th>\n",
       "      <td>37</td>\n",
       "      <td>4618</td>\n",
       "      <td>221.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon TRIM</th>\n",
       "      <td>343</td>\n",
       "      <td>138611</td>\n",
       "      <td>1381.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon noCat</th>\n",
       "      <td>101</td>\n",
       "      <td>64828</td>\n",
       "      <td>5051.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noCat</th>\n",
       "      <td>1141</td>\n",
       "      <td>614285</td>\n",
       "      <td>1312.675676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         copies     covg       length\n",
       "Code long                                            \n",
       "DNA_transposon Helitron    1123   845310  6380.423077\n",
       "DNA_transposon MITE        3765   944799   505.373016\n",
       "DNA_transposon Maverick     273   339526  9420.000000\n",
       "DNA_transposon TIR        11885  7214473  3525.890449\n",
       "DNA_transposon noCat       3099  1056219  2274.097561\n",
       "Potential Host Gene         618   417246  4390.378378\n",
       "Retrotransposon DIRS        770   591535  8770.894737\n",
       "Retrotransposon LARD       6353  2908933  5422.674074\n",
       "Retrotransposon LINE        378   248262  4333.400000\n",
       "Retrotransposon LTR       11016  9251050  6070.630923\n",
       "Retrotransposon SINE         37     4618   221.500000\n",
       "Retrotransposon TRIM        343   138611  1381.666667\n",
       "Retrotransposon noCat       101    64828  5051.000000\n",
       "noCat                      1141   614285  1312.675676"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick summary for each category based on the REPET summary dataframe\n",
    "REPET_sdf['Code long'] = REPET_sdf['Code'].apply(lambda x: code_dict[x])\n",
    "REPET_sdf_sum_df = pd.pivot_table(REPET_sdf, values=['covg', 'copies'], index='Code long', aggfunc=np.sum)\n",
    "REPET_sdf_mean_df = pd.pivot_table(REPET_sdf, values='length', index='Code long', aggfunc=np.mean)\n",
    "print('quick summary for each category based on the REPET summary dataframe')\n",
    "pd.concat([REPET_sdf_sum_df,REPET_sdf_mean_df], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:58:46.621184Z",
     "start_time": "2019-04-07T06:58:44.471672Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now read in all actuall REPET GFF file\n",
    "REPET_gff_df = pd.read_csv(os.path.join(out_dir,'%s.%s.REPET.gff3' % (genome, Tenovodb))\\\n",
    "                           , sep='\\t', header = None)\n",
    "#filter out host genes\n",
    "REPET_gff_df = REPET_gff_df[~REPET_gff_df[8].str.contains(\"Potential\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:59:06.862537Z",
     "start_time": "2019-04-07T06:58:46.622950Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df['ID'] = REPET_gff_df.apply(lambda row: ID_filter_gff(row[1], row[8]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:59:07.393238Z",
     "start_time": "2019-04-07T06:59:06.864759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aas\n"
     ]
    }
   ],
   "source": [
    "code_keys_gff = REPET_gff_df[REPET_gff_df[1].str.contains('REPET_TE')]['ID'].unique()\n",
    "code_keys_gff = list({x.split('_')[0] for x in code_keys_gff})\n",
    "three_letter_code = list({x for x in code_keys_gff})\n",
    "three_letter_code.sort()\n",
    "three_letter_values = []\n",
    "for x in three_letter_code:\n",
    "    if 'MITE' in x:\n",
    "        _value = \"ClassII:MITE:?\"\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    if 'LARD' in x:\n",
    "        _value = 'ClassI:LARD:?'\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    if 'TRIM' in x:\n",
    "        _value = 'ClassI:TRIM:?'\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    _value =''\n",
    "    if x[0] == 'D':\n",
    "        _value = _value + 'ClassII:'\n",
    "    if x[0] == 'R':\n",
    "        _value = _value + 'ClassI:'\n",
    "    if x[0] != 'D' and x[0] != 'R':\n",
    "        _value = 'noCat'\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    if x[1] == 'T':\n",
    "        _value = _value + 'TIR:?'\n",
    "    if x[1] == 'H':\n",
    "        _value = _value + 'Helitron:?'\n",
    "    if x[1] == 'M':\n",
    "        _value = _value + 'Maverick:?'\n",
    "    if x[0:2] == 'DY':\n",
    "        _value = _value + ':Crypton:?'\n",
    "    if x[1] == 'X':\n",
    "        _value = _value + '?:?'\n",
    "    if x[1] == 'I':\n",
    "        _value = _value + 'LINE:?'\n",
    "    if x[1] == 'L':\n",
    "        _value = _value + 'LTR:?'\n",
    "    if x[1] == 'P':\n",
    "        _value = _value + 'Penelope:?'\n",
    "    if x[1] == 'S':\n",
    "        _value = _value + 'SINE:?'\n",
    "    if x[0:2] == 'RY':\n",
    "        _value = _value + 'DIRS:?'    \n",
    "    three_letter_values.append(_value)\n",
    "\n",
    "if len(three_letter_code) == len(three_letter_values):\n",
    "    print(\"Aas\")\n",
    "    three_letter_dict = dict(zip(three_letter_code, three_letter_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:59:07.417180Z",
     "start_time": "2019-04-07T06:59:07.395215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DHX-comp': 'ClassII:Helitron:?',\n",
       " 'DHX-comp-chim': 'ClassII:Helitron:?',\n",
       " 'DHX-incomp': 'ClassII:Helitron:?',\n",
       " 'DHX-incomp-chim': 'ClassII:Helitron:?',\n",
       " 'DMX-incomp': 'ClassII:Maverick:?',\n",
       " 'DTX-comp': 'ClassII:TIR:?',\n",
       " 'DTX-comp-chim': 'ClassII:TIR:?',\n",
       " 'DTX-incomp': 'ClassII:TIR:?',\n",
       " 'DTX-incomp-chim': 'ClassII:TIR:?',\n",
       " 'DXX': 'ClassII:?:?',\n",
       " 'DXX-MITE': 'ClassII:MITE:?',\n",
       " 'DXX-MITE-chim': 'ClassII:MITE:?',\n",
       " 'RIX-comp': 'ClassI:LINE:?',\n",
       " 'RIX-incomp': 'ClassI:LINE:?',\n",
       " 'RIX-incomp-chim': 'ClassI:LINE:?',\n",
       " 'RLX-comp': 'ClassI:LTR:?',\n",
       " 'RLX-comp-chim': 'ClassI:LTR:?',\n",
       " 'RLX-incomp': 'ClassI:LTR:?',\n",
       " 'RLX-incomp-chim': 'ClassI:LTR:?',\n",
       " 'RSX-incomp': 'ClassI:SINE:?',\n",
       " 'RXX': 'ClassI:?:?',\n",
       " 'RXX-LARD': 'ClassI:LARD:?',\n",
       " 'RXX-LARD-chim': 'ClassI:LARD:?',\n",
       " 'RXX-TRIM': 'ClassI:TRIM:?',\n",
       " 'RXX-TRIM-chim': 'ClassI:TRIM:?',\n",
       " 'RXX-chim': 'ClassI:?:?',\n",
       " 'RYX-comp': 'ClassI:DIRS:?',\n",
       " 'RYX-comp-chim': 'ClassI:DIRS:?',\n",
       " 'RYX-incomp': 'ClassI:DIRS:?',\n",
       " 'RYX-incomp-chim': 'ClassI:DIRS:?',\n",
       " 'noCat': 'noCat'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this three letter dict is required for the blast_hit_gff function to work and needs to be generated\n",
    "three_letter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:59:27.949428Z",
     "start_time": "2019-04-07T06:59:07.419009Z"
    }
   },
   "outputs": [],
   "source": [
    "REPET_gff_df['Class:Order:Superfamily'] = REPET_gff_df.apply(lambda row: blast_hit_gff(row[1], row[8], row['ID']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:59:47.761199Z",
     "start_time": "2019-04-07T06:59:46.407644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassII:?:Ginger2/TDD\n",
      "ClassII:?:Ginger2_TDD\n"
     ]
    }
   ],
   "source": [
    "#generate a dict that can be used to rename the Class:Order:Superfamily column \n",
    "#considering that partial matches ([2] == match_part) might contain different\n",
    "#IDs even though they are the same TE only partial.\n",
    "_tmp_subset = REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')].loc[:, 'ID':].sort_values(by=['ID','Class:Order:Superfamily'])\\\n",
    ".drop_duplicates(subset='ID', keep ='last')\n",
    "\n",
    "TE_COS_dict = dict(zip(_tmp_subset.loc[:, 'ID'], _tmp_subset.loc[:, 'Class:Order:Superfamily' ]))\n",
    "\n",
    "_tmp_subset = REPET_gff_df[REPET_gff_df[1].str.contains('SSR')].loc[:, 'ID':].sort_values(by=['ID','Class:Order:Superfamily'])\\\n",
    ".drop_duplicates(subset='ID', keep ='last')\n",
    "\n",
    "_tmp_dict = dict(zip(_tmp_subset.loc[:, 'ID'], _tmp_subset.loc[:, 'Class:Order:Superfamily' ]))\n",
    "\n",
    "TE_COS_dict.update(_tmp_dict)\n",
    "#remove all backslashes from the values as this will conflict with the output later on\n",
    "for x in TE_COS_dict.keys():\n",
    "    if '/' in TE_COS_dict[x]:\n",
    "        value = TE_COS_dict[x]\n",
    "        print(value)\n",
    "        TE_COS_dict[x] = value.replace('/','_')\n",
    "        print(TE_COS_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:59:58.749350Z",
     "start_time": "2019-04-07T06:59:53.911035Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df.to_csv(os.path.join(out_dir,'%s.%s.REPET.long.df' % (genome, Tenovodb)),\n",
    "                    sep='\\t', header = None, index=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:59:59.193435Z",
     "start_time": "2019-04-07T06:59:58.752015Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df['Class:Order:Superfamily'] = REPET_gff_df['ID'].apply(lambda x: TE_COS_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T06:59:59.269277Z",
     "start_time": "2019-04-07T06:59:59.195737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the unique Class:Order:Superfamily classifiers of this dataframe:\n",
      "['ClassII:TIR:PIF-Harbinger' 'ClassII:?:?' 'ClassII:TIR:MuDR'\n",
      " 'ClassI:LARD:?' 'ClassI:DIRS:DIRS' 'ClassII:TIR:?' 'ClassI:LTR:Copia'\n",
      " 'ClassII:Maverick:?' 'ClassII:TIR:hAT' 'ClassI:LTR:Gypsy' 'ClassII:MITE:?'\n",
      " 'ClassI:LTR:?' 'SSR' 'ClassII:TIR:CACTA' 'ClassII:Helitron:?'\n",
      " 'ClassII:TIR:Tc1-Mariner' 'ClassII:?:Academ' 'ClassI:DIRS:?'\n",
      " 'ClassII:Helitron:Helitron' 'noCat' 'ClassI:LINE:I' 'ClassII:TIR:P'\n",
      " 'ClassI:LTR:ERV' 'ClassI:TRIM:?' 'ClassI:SINE:?' 'ClassI:LTR:Bel-Pao'\n",
      " 'ClassI:LINE:RTE' 'ClassI:?:?' 'ClassII:?:Ginger1' 'ClassI:LTR:Retrovirus'\n",
      " 'ClassI:LINE:Jockey' 'ClassI:LINE:?' 'ClassII:Maverick:Maverick'\n",
      " 'ClassII:TIR:Transib' 'ClassI:PLE:Penelope' 'ClassII:?:Ginger2_TDD'\n",
      " 'ClassI:LINE:L1' 'ClassII:TIR:PiggyBac' 'ClassI:LINE:R2' 'ClassII:?:Sola'\n",
      " 'ClassII:Crypton:Crypton' 'ClassII:?:Kolobok']\n"
     ]
    }
   ],
   "source": [
    "print('These are the unique Class:Order:Superfamily classifiers of this dataframe:')\n",
    "print(REPET_gff_df['Class:Order:Superfamily'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:23.054447Z",
     "start_time": "2019-04-07T07:00:02.322542Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#have a rough summary of the coverage not considering overlaps.\n",
    "REPET_gff_df.drop_duplicates(subset=[3,4,'ID'], inplace =True) \n",
    "#this drops all duplicates in the df that completey overlap and have the same ID. Avoid double counting.\n",
    "REPET_gff_df['Length'] = REPET_gff_df[4] - REPET_gff_df[3]\n",
    "REPET_gff_df['Class'] = REPET_gff_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 0), axis=1)\n",
    "REPET_gff_df['Order'] = REPET_gff_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 1), axis=1)\n",
    "REPET_gff_df['Superfamily'] = REPET_gff_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 2), axis=1)\n",
    "REPET_gff_df_COS = REPET_gff_df.groupby(by=['Class','Order','Superfamily'])['Length'].sum()\n",
    "REPET_gff_df_S = REPET_gff_df.groupby(by=['Class:Order:Superfamily'])['Length'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:23.081169Z",
     "start_time": "2019-04-07T07:00:23.059858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the summary of overlapping coverage according to Class, Order, Superfamily\n",
      "Class            Order     Superfamily  \n",
      "DNA_transposon   Crypton   Crypton              1186\n",
      "                 Helitron  Helitron          1008339\n",
      "                           noCat              871632\n",
      "                 MITE      noCat             1185654\n",
      "                 Maverick  Maverick            19745\n",
      "                           noCat              432434\n",
      "                 TIR       CACTA              835182\n",
      "                           MuDR              2728228\n",
      "                           P                  191266\n",
      "                           PIF-Harbinger     2386491\n",
      "                           PiggyBac              345\n",
      "                           Tc1-Mariner       2222479\n",
      "                           Transib               699\n",
      "                           hAT               5341189\n",
      "                           noCat             3253909\n",
      "                 noCat     Academ            1110288\n",
      "                           Ginger1              2662\n",
      "                           Ginger2_TDD           350\n",
      "                           Kolobok               153\n",
      "                           Sola                14029\n",
      "                           noCat             4387099\n",
      "Retrotransposon  DIRS      DIRS               645510\n",
      "                           noCat              201793\n",
      "                 LARD      noCat             2054528\n",
      "                 LINE      I                  673351\n",
      "                           Jockey              32110\n",
      "                           L1                    452\n",
      "                           R2                   4074\n",
      "                           RTE                  1759\n",
      "                           noCat               86968\n",
      "                 LTR       Bel-Pao              3763\n",
      "                           Copia             7690482\n",
      "                           ERV                 60494\n",
      "                           Gypsy            15895061\n",
      "                           Retrovirus           2769\n",
      "                           noCat             1656695\n",
      "                 PLE       Penelope              760\n",
      "                 SINE      noCat                4581\n",
      "                 TRIM      noCat              120229\n",
      "                 noCat     noCat               59094\n",
      "SSR              SSR       SSR                636815\n",
      "noCat            noCat     noCat              806212\n",
      "Name: Length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the summary of overlapping coverage according to Class, Order, Superfamily\")\n",
    "print(REPET_gff_df_COS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:23.157227Z",
     "start_time": "2019-04-07T07:00:23.082973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the summary of unqiue TE insertions for each Class, Order, Superfamily\n",
      "Class            Order     Superfamily  \n",
      "DNA_transposon   Crypton   Crypton              7\n",
      "                 Helitron  Helitron          1904\n",
      "                           noCat             1184\n",
      "                 MITE      noCat             4113\n",
      "                 Maverick  Maverick            37\n",
      "                           noCat              304\n",
      "                 TIR       CACTA             1441\n",
      "                           MuDR              6098\n",
      "                           P                  595\n",
      "                           PIF-Harbinger     6036\n",
      "                           PiggyBac             3\n",
      "                           Tc1-Mariner       5511\n",
      "                           Transib              3\n",
      "                           hAT              12418\n",
      "                           noCat             4966\n",
      "                 noCat     Academ            1592\n",
      "                           Ginger1             29\n",
      "                           Ginger2_TDD          1\n",
      "                           Kolobok              2\n",
      "                           Sola                20\n",
      "                           noCat            16099\n",
      "Retrotransposon  DIRS      DIRS              1475\n",
      "                           noCat              252\n",
      "                 LARD      noCat             3248\n",
      "                 LINE      I                 1426\n",
      "                           Jockey             129\n",
      "                           L1                   7\n",
      "                           R2                  10\n",
      "                           RTE                 17\n",
      "                           noCat              138\n",
      "                 LTR       Bel-Pao             21\n",
      "                           Copia            20196\n",
      "                           ERV                697\n",
      "                           Gypsy            40599\n",
      "                           Retrovirus          36\n",
      "                           noCat             4439\n",
      "                 PLE       Penelope             6\n",
      "                 SINE      noCat               37\n",
      "                 TRIM      noCat              279\n",
      "                 noCat     noCat              111\n",
      "SSR              SSR       SSR              24114\n",
      "noCat            noCat     noCat             1369\n",
      "Name: Length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the summary of unqiue TE insertions for each Class, Order, Superfamily\")\n",
    "print(REPET_gff_df.groupby(by=['Class','Order','Superfamily'])['Length'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:23.173184Z",
     "start_time": "2019-04-07T07:00:23.159149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the summary of overlapping coverage according to Superfamily\n",
      "Class:Order:Superfamily\n",
      "ClassI:?:?                      59094\n",
      "ClassI:DIRS:?                  201793\n",
      "ClassI:DIRS:DIRS               645510\n",
      "ClassI:LARD:?                 2054528\n",
      "ClassI:LINE:?                   86968\n",
      "ClassI:LINE:I                  673351\n",
      "ClassI:LINE:Jockey              32110\n",
      "ClassI:LINE:L1                    452\n",
      "ClassI:LINE:R2                   4074\n",
      "ClassI:LINE:RTE                  1759\n",
      "ClassI:LTR:?                  1656695\n",
      "ClassI:LTR:Bel-Pao               3763\n",
      "ClassI:LTR:Copia              7690482\n",
      "ClassI:LTR:ERV                  60494\n",
      "ClassI:LTR:Gypsy             15895061\n",
      "ClassI:LTR:Retrovirus            2769\n",
      "ClassI:PLE:Penelope               760\n",
      "ClassI:SINE:?                    4581\n",
      "ClassI:TRIM:?                  120229\n",
      "ClassII:?:?                   4387099\n",
      "ClassII:?:Academ              1110288\n",
      "ClassII:?:Ginger1                2662\n",
      "ClassII:?:Ginger2_TDD             350\n",
      "ClassII:?:Kolobok                 153\n",
      "ClassII:?:Sola                  14029\n",
      "ClassII:Crypton:Crypton          1186\n",
      "ClassII:Helitron:?             871632\n",
      "ClassII:Helitron:Helitron     1008339\n",
      "ClassII:MITE:?                1185654\n",
      "ClassII:Maverick:?             432434\n",
      "ClassII:Maverick:Maverick       19745\n",
      "ClassII:TIR:?                 3253909\n",
      "ClassII:TIR:CACTA              835182\n",
      "ClassII:TIR:MuDR              2728228\n",
      "ClassII:TIR:P                  191266\n",
      "ClassII:TIR:PIF-Harbinger     2386491\n",
      "ClassII:TIR:PiggyBac              345\n",
      "ClassII:TIR:Tc1-Mariner       2222479\n",
      "ClassII:TIR:Transib               699\n",
      "ClassII:TIR:hAT               5341189\n",
      "SSR                            636815\n",
      "noCat                          806212\n",
      "Name: Length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the summary of overlapping coverage according to Superfamily\")\n",
    "print(REPET_gff_df_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:23.849153Z",
     "start_time": "2019-04-07T07:00:23.175208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of unique TEs: 10565\n",
      "This is the number of unique TE superfamilies: 41\n"
     ]
    }
   ],
   "source": [
    "num_unique_TEs = len(REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')]['ID'].unique())\n",
    "num_unique_TE_super = len(REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')]['Class:Order:Superfamily'].unique())\n",
    "\n",
    "print('This is the number of unique TEs: %i\\nThis is the number of unique TE superfamilies: %i' % (num_unique_TEs, num_unique_TE_super))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:23.909194Z",
     "start_time": "2019-04-07T07:00:23.850908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the count of unique TEs in each category\n",
      "Class:Order:Superfamily\n",
      "ClassI:?:?                     111\n",
      "ClassI:DIRS:?                  252\n",
      "ClassI:DIRS:DIRS              1475\n",
      "ClassI:LARD:?                 3248\n",
      "ClassI:LINE:?                  138\n",
      "ClassI:LINE:I                 1426\n",
      "ClassI:LINE:Jockey             129\n",
      "ClassI:LINE:L1                   7\n",
      "ClassI:LINE:R2                  10\n",
      "ClassI:LINE:RTE                 17\n",
      "ClassI:LTR:?                  4439\n",
      "ClassI:LTR:Bel-Pao              21\n",
      "ClassI:LTR:Copia             20196\n",
      "ClassI:LTR:ERV                 697\n",
      "ClassI:LTR:Gypsy             40599\n",
      "ClassI:LTR:Retrovirus           36\n",
      "ClassI:PLE:Penelope              6\n",
      "ClassI:SINE:?                   37\n",
      "ClassI:TRIM:?                  279\n",
      "ClassII:?:?                  16099\n",
      "ClassII:?:Academ              1592\n",
      "ClassII:?:Ginger1               29\n",
      "ClassII:?:Ginger2_TDD            1\n",
      "ClassII:?:Kolobok                2\n",
      "ClassII:?:Sola                  20\n",
      "ClassII:Crypton:Crypton          7\n",
      "ClassII:Helitron:?            1184\n",
      "ClassII:Helitron:Helitron     1904\n",
      "ClassII:MITE:?                4113\n",
      "ClassII:Maverick:?             304\n",
      "ClassII:Maverick:Maverick       37\n",
      "ClassII:TIR:?                 4966\n",
      "ClassII:TIR:CACTA             1441\n",
      "ClassII:TIR:MuDR              6098\n",
      "ClassII:TIR:P                  595\n",
      "ClassII:TIR:PIF-Harbinger     6036\n",
      "ClassII:TIR:PiggyBac             3\n",
      "ClassII:TIR:Tc1-Mariner       5511\n",
      "ClassII:TIR:Transib              3\n",
      "ClassII:TIR:hAT              12418\n",
      "SSR                          24114\n",
      "noCat                         1369\n",
      "Name: Length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('This is the count of unique TEs in each category')\n",
    "print(REPET_gff_df.groupby(by=['Class:Order:Superfamily'])['Length'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:24.289154Z",
     "start_time": "2019-04-07T07:00:23.926531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the relative number of identified element in each category\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Class:Order:Superfamily\n",
       "ClassI:?:?                    0.081108\n",
       "ClassI:DIRS:?                 0.184136\n",
       "ClassI:DIRS:DIRS              1.077783\n",
       "ClassI:LARD:?                 2.373315\n",
       "ClassI:LINE:?                 0.100837\n",
       "ClassI:LINE:I                 1.041979\n",
       "ClassI:LINE:Jockey            0.094260\n",
       "ClassI:LINE:L1                0.005115\n",
       "ClassI:LINE:R2                0.007307\n",
       "ClassI:LINE:RTE               0.012422\n",
       "ClassI:LTR:?                  3.243579\n",
       "ClassI:LTR:Bel-Pao            0.015345\n",
       "ClassI:LTR:Copia             14.757225\n",
       "ClassI:LTR:ERV                0.509298\n",
       "ClassI:LTR:Gypsy             29.665705\n",
       "ClassI:LTR:Retrovirus         0.026305\n",
       "ClassI:PLE:Penelope           0.004384\n",
       "ClassI:SINE:?                 0.027036\n",
       "ClassI:TRIM:?                 0.203865\n",
       "ClassII:?:?                  11.763545\n",
       "ClassII:?:Academ              1.163275\n",
       "ClassII:?:Ginger1             0.021190\n",
       "ClassII:?:Ginger2_TDD         0.000731\n",
       "ClassII:?:Kolobok             0.001461\n",
       "ClassII:?:Sola                0.014614\n",
       "ClassII:Crypton:Crypton       0.005115\n",
       "ClassII:Helitron:?            0.865149\n",
       "ClassII:Helitron:Helitron     1.391254\n",
       "ClassII:MITE:?                3.005371\n",
       "ClassII:Maverick:?            0.222133\n",
       "ClassII:Maverick:Maverick     0.027036\n",
       "ClassII:TIR:?                 3.628658\n",
       "ClassII:TIR:CACTA             1.052939\n",
       "ClassII:TIR:MuDR              4.455811\n",
       "ClassII:TIR:P                 0.434767\n",
       "ClassII:TIR:PIF-Harbinger     4.410507\n",
       "ClassII:TIR:PiggyBac          0.002192\n",
       "ClassII:TIR:Tc1-Mariner       4.026890\n",
       "ClassII:TIR:Transib           0.002192\n",
       "ClassII:TIR:hAT               9.073837\n",
       "noCat                         1.000329\n",
       "Name: Length, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPET_gff_wo_SSRs_df = REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')]\n",
    "print('This is the relative number of identified element in each category')\n",
    "REPET_gff_wo_SSRs_df.groupby(by=['Class:Order:Superfamily'])['Length'].count()/REPET_gff_wo_SSRs_df .groupby(by=['Class:Order:Superfamily'])['Length'].count().sum()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:27.365830Z",
     "start_time": "2019-04-07T07:00:24.290919Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df.to_csv(os.path.join(out_dir,'%s.%s.REPET.long_v2.df' % (genome, Tenovodb)),\\\n",
    "                    sep='\\t', header = None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:27.389131Z",
     "start_time": "2019-04-07T07:00:27.369301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/benjamin/genome_assembly/Warrior/TE_analysis'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:36.861225Z",
     "start_time": "2019-04-07T07:00:34.735942Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make new gff files where the ID column is the superfamily level\n",
    "REPET_gff_superfamily = REPET_gff_df.iloc[:,:]\n",
    "REPET_gff_superfamily[8] = REPET_gff_df['Class:Order:Superfamily']\n",
    "REPET_gff_superfamily.iloc[:,0:9].to_csv(\\\n",
    "    os.path.join(out_dir,'%s.%s.REPET.superfamily.gff' % (genome, Tenovodb)),\\\n",
    "                                         sep='\\t', header = None, index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:38.878308Z",
     "start_time": "2019-04-07T07:00:36.863596Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make new gff file where the ID column is the TE level\n",
    "REPET_gff_TE = REPET_gff_df.iloc[:,:]\n",
    "REPET_gff_TE[8] = REPET_gff_TE['ID']\n",
    "REPET_gff_TE.iloc[:,0:9].to_csv(\\\n",
    "    os.path.join(out_dir,'%s.%s.REPET.TE.gff' % (genome, Tenovodb)),\\\n",
    "    sep='\\t', header = None, index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:38.909130Z",
     "start_time": "2019-04-07T07:00:38.881114Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the directory structure to safe specific coverage files\n",
    "TE_types = ['Retrotransposon', 'DNA_transposon', 'noCat', 'SSR']\n",
    "TE_path = [os.path.join(out_dir, x) for x in TE_types]\n",
    "TE_path_dict = dict(zip(TE_types, TE_path))\n",
    "for TE_type in TE_types:\n",
    "    new_path = os.path.join(out_dir, TE_type)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:39.681277Z",
     "start_time": "2019-04-07T07:00:39.670321Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_sf_gff_fh = os.path.join(out_dir,'%s.%s.REPET.superfamily.gff' % (genome, Tenovodb))\n",
    "REPET_TE_gff_fh = os.path.join(out_dir,'%s.%s.REPET.TE.gff' % (genome, Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:40.337195Z",
     "start_time": "2019-04-07T07:00:40.286423Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define some prefixes used to aggregate coverages\n",
    "#and the genome file for bedtools\n",
    "repet_prefix_TE = '%s.%s.REPET.TE' % (genome, Tenovodb)\n",
    "repet_prefix_S =  '%s.%s.REPET.superfamily' % (genome, Tenovodb)\n",
    "genome_file_fh = os.path.join(source_dir, '%s.genome_file' % genome)\n",
    "genome_df = pd.read_csv(genome_file_fh, sep='\\t', header=None,names=['contig', 'length'])\n",
    "genome_size = genome_df['length'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:00:50.990960Z",
     "start_time": "2019-04-07T07:00:41.951990Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the bedobjects\n",
    "RE_TE_gff = pybedtools.BedTool(REPET_TE_gff_fh)\n",
    "g_TE = RE_TE_gff.remove_invalid().saveas(REPET_TE_gff_fh.replace('gff', 'bedobject'))\n",
    "#use the blast filtered dataframe as well\n",
    "RE_S_gff = pybedtools.BedTool(REPET_sf_gff_fh)\n",
    "g_S = RE_S_gff.remove_invalid().saveas(REPET_sf_gff_fh.replace('gff', 'bedobject'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:00:42.767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with callculating coverage of ClassII:TIR:PIF-Harbinger.\n",
      "Done with callculating coverage of ClassII:TIR:MuDR.\n",
      "Done with callculating coverage of ClassI:LARD:?.\n",
      "Done with callculating coverage of ClassI:DIRS:DIRS.\n",
      "Done with callculating coverage of ClassII:?:?.\n",
      "Done with callculating coverage of ClassII:Maverick:?.\n",
      "Done with callculating coverage of ClassII:TIR:?.\n",
      "Done with callculating coverage of ClassII:TIR:hAT.\n",
      "Done with callculating coverage of ClassII:MITE:?.\n",
      "Done with callculating coverage of ClassI:LTR:Copia.\n",
      "Done with callculating coverage of ClassI:LTR:?.\n",
      "Done with callculating coverage of ClassII:TIR:CACTA.\n",
      "Done with callculating coverage of SSR.\n",
      "Done with callculating coverage of ClassII:Helitron:?.\n",
      "Done with callculating coverage of ClassII:?:Academ.\n",
      "Done with callculating coverage of ClassII:TIR:Tc1-Mariner.\n",
      "Done with callculating coverage of ClassI:DIRS:?.\n",
      "Done with callculating coverage of ClassII:Helitron:Helitron.\n",
      "Done with callculating coverage of ClassI:LINE:I.\n",
      "Done with callculating coverage of noCat.\n",
      "Done with callculating coverage of ClassII:TIR:P.\n",
      "Done with callculating coverage of ClassI:LTR:ERV.\n",
      "Done with callculating coverage of ClassI:LTR:Gypsy.\n",
      "Done with callculating coverage of ClassI:TRIM:?.\n",
      "Done with callculating coverage of ClassI:SINE:?.\n",
      "Done with callculating coverage of ClassI:LTR:Bel-Pao.\n",
      "Done with callculating coverage of ClassI:LINE:RTE.\n",
      "Done with callculating coverage of ClassII:?:Ginger1.\n",
      "Done with callculating coverage of ClassI:?:?.\n",
      "Done with callculating coverage of ClassI:LTR:Retrovirus.\n",
      "Done with callculating coverage of ClassI:LINE:Jockey.\n",
      "Done with callculating coverage of ClassI:LINE:?.\n",
      "Done with callculating coverage of ClassII:Maverick:Maverick.\n",
      "Done with callculating coverage of ClassII:TIR:Transib.\n",
      "Done with callculating coverage of ClassI:PLE:Penelope.\n",
      "Done with callculating coverage of ClassII:?:Ginger2_TDD.\n",
      "Done with callculating coverage of ClassI:LINE:L1.\n",
      "Done with callculating coverage of ClassII:TIR:PiggyBac.\n",
      "Done with callculating coverage of ClassI:LINE:R2.\n",
      "Done with callculating coverage of ClassII:?:Sola.\n",
      "Done with callculating coverage of ClassII:Crypton:Crypton.\n",
      "Done with callculating coverage of ClassII:?:Kolobok.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use simple loop to loop over the bedcov genome coverage per classification. Keep track if everything is already done.\n",
    "jobs = []\n",
    "superfamily_bed_fh = REPET_sf_gff_fh.replace('gff', 'bedobject')\n",
    "superfamilies = REPET_gff_df['Class:Order:Superfamily'].unique()\n",
    "Parallel(n_jobs=threads)(delayed(subset_id)(ID, superfamily_bed_fh, repet_prefix_S, genome_file_fh)\\\n",
    "                      for ID in superfamilies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:00:47.265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassII:?:?\n",
      "ClassII:?:Academ\n",
      "ClassII:?:Ginger1\n",
      "ClassII:?:Ginger2_TDD\n",
      "ClassII:?:Kolobok\n",
      "ClassII:?:Sola\n",
      "ClassII:Crypton:Crypton\n",
      "ClassII:Helitron:?\n",
      "ClassII:Helitron:Helitron\n",
      "ClassII:MITE:?\n",
      "ClassII:Maverick:?\n",
      "ClassII:Maverick:Maverick\n",
      "ClassII:TIR:?\n",
      "ClassII:TIR:CACTA\n",
      "ClassII:TIR:MuDR\n",
      "ClassII:TIR:P\n",
      "ClassII:TIR:PIF-Harbinger\n",
      "ClassII:TIR:PiggyBac\n",
      "ClassII:TIR:Tc1-Mariner\n",
      "ClassII:TIR:Transib\n",
      "ClassII:TIR:hAT\n",
      "ClassII:?:?\n",
      "ClassII:?:Academ\n",
      "ClassII:?:Ginger1\n",
      "ClassII:?:Kolobok\n",
      "ClassII:?:Sola\n",
      "ClassII:Crypton:Crypton\n",
      "ClassII:Helitron:?\n",
      "ClassII:Helitron:Helitron\n",
      "ClassII:MITE:?\n",
      "ClassII:Maverick:?\n",
      "ClassII:Maverick:Maverick\n",
      "ClassII:TIR:?\n",
      "ClassII:TIR:CACTA\n",
      "ClassII:TIR:MuDR\n",
      "ClassII:TIR:P\n",
      "ClassII:TIR:PIF-Harbinger\n",
      "ClassII:TIR:PiggyBac\n",
      "ClassII:TIR:Tc1-Mariner\n",
      "ClassII:TIR:Transib\n",
      "ClassII:TIR:hAT\n",
      "ClassI:?:?\n",
      "ClassI:DIRS:?\n",
      "ClassI:DIRS:DIRS\n",
      "ClassI:LARD:?\n",
      "ClassI:LINE:?\n",
      "ClassI:LINE:I\n",
      "ClassI:LINE:Jockey\n",
      "ClassI:LINE:L1\n",
      "ClassI:LINE:R2\n",
      "ClassI:LINE:RTE\n",
      "ClassI:LTR:?\n",
      "ClassI:LTR:Bel-Pao\n",
      "ClassI:LTR:Copia\n",
      "ClassI:LTR:ERV\n",
      "ClassI:LTR:Gypsy\n",
      "ClassI:LTR:Retrovirus\n",
      "ClassI:PLE:Penelope\n",
      "ClassI:SINE:?\n",
      "ClassI:TRIM:?\n",
      "ClassI:?:?\n",
      "ClassI:DIRS:?\n",
      "ClassI:DIRS:DIRS\n",
      "ClassI:LARD:?\n",
      "ClassI:LINE:?\n",
      "ClassI:LINE:I\n",
      "ClassI:LINE:Jockey\n",
      "ClassI:LINE:L1\n",
      "ClassI:LINE:R2\n",
      "ClassI:LINE:RTE\n",
      "ClassI:LTR:?\n",
      "ClassI:LTR:Bel-Pao\n",
      "ClassI:LTR:Copia\n",
      "ClassI:LTR:ERV\n",
      "ClassI:LTR:Gypsy\n",
      "ClassI:LTR:Retrovirus\n",
      "ClassI:PLE:Penelope\n",
      "ClassI:Penelope:?\n",
      "ClassI:SINE:?\n",
      "ClassI:TRIM:?\n",
      "SSR\n",
      "SSR\n",
      "noCat\n",
      "noCat\n"
     ]
    }
   ],
   "source": [
    "class_cov_files = []\n",
    "for path in TE_path:\n",
    "    cov_files = [os.path.join(path, x) for x in os.listdir(path) if x.endswith('.cov')]\n",
    "    for file in cov_files:\n",
    "        class_cov_files.append(file)\n",
    "\n",
    "#make a large summary dataframe from all the cov files where the last \n",
    "df_list =[]\n",
    "class_cov_files.sort()\n",
    "for file in class_cov_files:\n",
    "    #print(file)\n",
    "    tmp_df = pd.read_csv(file, sep='\\t', header = None)\n",
    "    tmp_df[\"Class:Order:Superfamily\"] = file.split('.')[-2]\n",
    "    tmp_df.drop_duplicates(inplace=True) #drop all the duplicates meaning same position in the genome and same superfamily\n",
    "    df_list.append(tmp_df)\n",
    "    print(file.split('.')[-2])\n",
    "\n",
    "df_REPET_classification = pd.concat(df_list)\n",
    "df_REPET_classification.to_csv(out_dir+'/'+ repet_prefix_S +'.cov', sep='\\t', header =None, index=None)\n",
    "\n",
    "cov_per_superfamily = df_REPET_classification.pivot_table(values=1, columns= \"Class:Order:Superfamily\", aggfunc='count')\n",
    "#cov_per_contig_per_superfamily = df_REPET_classification.groupby([0, \"Class:Order:Superfamily\"])[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:00:49.377Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_all_TEs = df_REPET_classification.drop_duplicates([0,1]) #this gets ride of the overlap between different TE families and classes\n",
    "cov_all_TEs = len(cov_all_TEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:00:49.921Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make superfamily df and add columns for Class, order and superfamily\n",
    "cov_per_superfamily['cov_all_TEs'] = cov_all_TEs\n",
    "cov_per_superfamily_df = cov_per_superfamily.T\n",
    "cov_per_superfamily_df.rename(columns={1: 'bp'}, inplace=True)\n",
    "cov_per_superfamily_df['%'] = cov_per_superfamily_df['bp']/genome_size*100\n",
    "cov_per_superfamily_df['Class:Order:Superfamily'] = cov_per_superfamily_df.index\n",
    "\n",
    "cov_per_superfamily_df['Class'] = cov_per_superfamily_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 0), axis=1)\n",
    "cov_per_superfamily_df['Order'] = cov_per_superfamily_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 1), axis=1)\n",
    "cov_per_superfamily_df['Superfamily'] = cov_per_superfamily_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:00:50.721Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_superfamily_df.to_csv(out_dir+'/'+repet_prefix_S+'.tab', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:00:51.505Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for file in class_cov_files:\n",
    "    tmp_df = pd.read_csv(file, sep='\\t', header = None)\n",
    "    tmp_df[\"Class\"] = file.split('.')[-2].split(':')[0] #parse out the Class from the file name\n",
    "    tmp_df.drop_duplicates(inplace=True) #drop all the duplicates meaning same position in the genome and same Class\n",
    "    df_list.append(tmp_df)\n",
    "    #print(file.split('.')[-2].split(':')[0])\n",
    "\n",
    "df_REPET_classification_class = pd.concat(df_list)\n",
    "df_REPET_classification_class.drop_duplicates(inplace=True)\n",
    "df_REPET_classification_class.to_csv(out_dir+'/'+ repet_prefix_S.replace('superfamily', 'Class') +'.cov', sep='\\t', header =None, index=None)\n",
    "\n",
    "cov_per_class = df_REPET_classification_class.pivot_table(values=1, columns= \"Class\", aggfunc='count')\n",
    "#cov_per_contig_per_class = df_REPET_classification_class.groupby([0, \"Class\"])[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:00:52.901Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a large summary dataframe from all the cov files where the last \n",
    "df_list =[]\n",
    "class_cov_files.sort()\n",
    "for file in class_cov_files:\n",
    "    tmp_df = pd.read_csv(file, sep='\\t', header = None)\n",
    "    if ':' in file:\n",
    "        tmp_df[\"Order\"] = ':'.join(file.split('.')[-2].split(':')[0:2]) #parse out the order from the file name\n",
    "        #print(':'.join(file.split('.')[-2].split(':')[0:2]))\n",
    "    else:\n",
    "        tmp_df[\"Order\"] = file.split('.')[-2].split(':')[0]\n",
    "        #print(file.split('.')[-2].split(':')[0])\n",
    "    tmp_df.drop_duplicates(inplace=True) #drop all the duplicates meaning same position in the genome and same Order\n",
    "    df_list.append(tmp_df)\n",
    "\n",
    "df_REPET_orderification_order = pd.concat(df_list)\n",
    "df_REPET_orderification_order.drop_duplicates(inplace=True)\n",
    "df_REPET_orderification_order.to_csv(out_dir+'/'+ repet_prefix_S.replace('superfamily', 'Order') +'.cov', sep='\\t', header =None, index=None)\n",
    "\n",
    "cov_per_order = df_REPET_orderification_order.pivot_table(values=1, columns= \"Order\", aggfunc='count')\n",
    "#cov_per_contig_per_order = df_REPET_orderification_order.groupby([0, \"Order\"])[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:00:54.098Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_order['cov_all_TEs'] = cov_all_TEs\n",
    "cov_per_order_df = cov_per_order.T\n",
    "cov_per_order_df.rename(columns={1: 'bp'}, inplace=True)\n",
    "\n",
    "cov_per_order_df['%'] = round(cov_per_order_df['bp']/genome_size*100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:00:55.009Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_class['cov_all_TEs'] = cov_all_TEs\n",
    "cov_per_class_df = cov_per_class.T\n",
    "cov_per_class_df.rename(columns={1: 'bp'}, inplace=True)\n",
    "\n",
    "cov_per_class_df['%'] = round(cov_per_class_df['bp']/genome_size*100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:00:56.129Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_class_df.rename(index={'cov_all_TEs': 'Total RE coverage'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:00:57.969Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_class_df.sort_values('bp', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:05.874Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-talk')\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, ncols=1, figsize=(12,15))\n",
    "fig.suptitle(\"Repetitive elements in P. striformis f. sp. tritici %s\" % genome, fontsize=14, fontweight = 'bold')\n",
    "\n",
    "#color cycle from color blind people \n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "'#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "#plot the overall genome coverage by repetitive element category\n",
    "cov_per_class_df.plot(kind='barh', y='%', ax=ax0,  color='r')\n",
    "ax0.set_xlim([-5,60])\n",
    "ax0.legend().set_visible(False)\n",
    "ax0.set_yticklabels(list(cov_per_class_df.index),fontsize=10, fontweight='bold')\n",
    "ax0.set_ylabel(ylabel='RE categories', fontsize=14, fontweight='bold')\n",
    "\n",
    "#plot class I \n",
    "classI_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'Retrotransposon'].sort_values('%',\\\n",
    "                                                            ascending=True)\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classI_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classI_df['Order'].unique(), tmp_colors))\n",
    "classI_df['Color'] = classI_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "ax1.barh(np.arange(len(classI_df.index)), classI_df['%'],\n",
    "        color=classI_df['Color'], ecolor='black')\n",
    "ax1.set_yticks(np.arange(len(classI_df.index)))\n",
    "ax1.set_xlim([-2,25])\n",
    "ax1.set_yticklabels(list(classI_df.index),fontsize=10, fontweight='bold')\n",
    "ax1.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax1.set_title('ClassI: Retrotransposons', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax1.patches, classI_df['%']):\n",
    "    ax1.annotate('{0:.3f}'.format(value), (18,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "\n",
    "#plot class II\n",
    "classII_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'DNA_transposon'].sort_values('%',\\\n",
    "                                                                                        ascending=True)\n",
    "\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classII_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classII_df['Order'].unique(), tmp_colors))\n",
    "classII_df['Color'] = classII_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "\n",
    "#plot the class II out\n",
    "\n",
    "ax2.barh(np.arange(len(classII_df.index)), classII_df['%'],\n",
    "        color=classII_df['Color'], ecolor='black')\n",
    "\n",
    "ax2.set_xlim([-2,25])\n",
    "ax2.set_yticks(np.arange(len(classII_df.index)))\n",
    "\n",
    "ax2.set_yticklabels(list(classII_df.index),fontsize=10, fontweight='bold')\n",
    "ax2.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax2.set_title('ClassII: DNA transposons', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('% genome coverage', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax2.patches, classII_df['%']):\n",
    "    ax2.annotate('{0:.3f}'.format(value), (18 ,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "    \n",
    "fig.savefig(os.path.join(out_dir, genome+'.REPET_summary_pc.seaborn-talk.png'), dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:06.977Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-talk')\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, ncols=1, figsize=(12,15))\n",
    "fig.suptitle(\"Repetitive elements in P. striformis f. sp. tritici %s\" % genome, fontsize=14, fontweight = 'bold')\n",
    "\n",
    "#color cycle from color blind people \n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "'#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "#plot the overall genome coverage by repetitive element category\n",
    "cov_per_class_df.plot(kind='barh', y='bp', ax=ax0,  color='r')\n",
    "ax0.set_xlim([-5,50000000])\n",
    "ax0.legend().set_visible(False)\n",
    "ax0.set_yticklabels(list(cov_per_class_df.index),fontsize=10, fontweight='bold')\n",
    "ax0.set_ylabel(ylabel='RE categories', fontsize=14, fontweight='bold')\n",
    "\n",
    "#plot class I \n",
    "classI_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'Retrotransposon'].sort_values('%',\\\n",
    "                                                            ascending=True)\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classI_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classI_df['Order'].unique(), tmp_colors))\n",
    "classI_df['Color'] = classI_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "ax1.barh(np.arange(len(classI_df.index)), classI_df['bp'],\n",
    "        color=classI_df['Color'], ecolor='black')\n",
    "ax1.set_yticks(np.arange(len(classI_df.index)))\n",
    "ax1.set_xlim([-2,14000000])\n",
    "ax1.set_yticklabels(list(classI_df.index),fontsize=10, fontweight='bold')\n",
    "ax1.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax1.set_title('ClassI: Retrotransposons', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax1.patches, classI_df['bp']):\n",
    "    ax1.annotate('{0:.2E}'.format(value), (14000000,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "\n",
    "#plot class II\n",
    "classII_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'DNA_transposon'].sort_values('%',\\\n",
    "                                                                                        ascending=True)\n",
    "\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classII_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classII_df['Order'].unique(), tmp_colors))\n",
    "classII_df['Color'] = classII_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "\n",
    "#plot the class II out\n",
    "\n",
    "ax2.barh(np.arange(len(classII_df.index)), classII_df['bp'],\n",
    "        color=classII_df['Color'], ecolor='black')\n",
    "\n",
    "ax2.set_xlim([-2,14000000])\n",
    "ax2.set_yticks(np.arange(len(classII_df.index)))\n",
    "\n",
    "ax2.set_yticklabels(list(classII_df.index),fontsize=10, fontweight='bold')\n",
    "ax2.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax2.set_title('ClassII: DNA transposons', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('bp genome coverage', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax2.patches, classII_df['bp']):\n",
    "    ax2.annotate('{0:.2E}'.format(value), (14000000 ,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "    \n",
    "fig.savefig(os.path.join(out_dir, genome+'.REPET_summary_bpcov.seaborn-talk.png'), dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now some analysis of the divergence of the TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:12.483Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now get the summary of allTEs == TEs specificaly identified by TEdenovo from REPET\n",
    "REPET_denovoTEs_df = pd.read_csv(\\\n",
    "        os.path.join(TE_postanalysis_dir, '%s_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE.tab' % genome_repet),\\\n",
    "                                names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n",
    "\n",
    "#now get in the summary of all bankBLRx TEs == TEs identified by repbase20.05_ntSeq_cleaned_TE\n",
    "REPET_nt_repbase_df = pd.read_csv(\\\n",
    "    os.path.join(TE_postanalysis_dir, '%s_chr_bankBLRx_path.annotStatsPerTE.tab' % genome_repet) ,\\\n",
    "    names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n",
    "\n",
    "#now get in the summary of all bankBLRtx TEs == TEs identified by repbase20.05_aaSeq_cleaned_TE\n",
    "REPET_aa_repbase_df = pd.read_csv(\\\n",
    "    os.path.join(TE_postanalysis_dir, '%s_chr_bankBLRtx_path.annotStatsPerTE.tab' % genome_repet) ,\\\n",
    "    names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:13.392Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate a df that contains all TEs: TEdenovo, blastx, blastn\n",
    "REPET_all_TEs_df = pd.concat([REPET_denovoTEs_df ,REPET_nt_repbase_df,\\\n",
    "                                       REPET_aa_repbase_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:14.020Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_all_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.copies > 0]\n",
    "REPET_all_TEs_df = REPET_all_TEs_df[~REPET_all_TEs_df.TE.str.startswith(\"Potential\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:16.019Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#update the TE_COS_dict with missing values that come mostly from blastx and blastn searches.\n",
    "missing_TE_keys = list(set(REPET_all_TEs_df.TE.unique())- set(TE_COS_dict.keys()))\n",
    "missing_TE_values  = [x[x.find(':')+1:] for x in missing_TE_keys]\n",
    "TE_COS_dict.update(dict(zip(missing_TE_keys ,missing_TE_values )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:20.354Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the Class/order/superfamily column to the dataframe based on the TE_COS_dict\n",
    "REPET_all_TEs_df[\"COS\"] = REPET_all_TEs_df[\"TE\"].apply(lambda x: TE_COS_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:22.580Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using the formula T=D/t in arXiv:1209.0176 [q-bio] to approximate TE age\n",
    "# where D = (100-meanId)/100 and \n",
    "# t the substitution rate per site per year\n",
    "# generations per year are estimate at 15 10.1111/j.1365-294X.2007.03513.x\n",
    "# estimate of subsitution rate per year = 2 * 10-9 10.1093/oxfordjournals.molbev.a004056 and\n",
    "# 10.1016/j.fbr.2010.03.001\n",
    "REPET_all_TEs_df['TE_age_Mya'] = (((100-REPET_all_TEs_df.meanId)/100)\\\n",
    "                                        /(2*10**-9))/10**6\n",
    "REPET_all_TEs_df['TE_age'] = (((100-REPET_all_TEs_df.meanId)/100)\\\n",
    "                                        /(2*10**-9))\n",
    "REPET_all_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.copies > 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:23.216Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_ClassI_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.COS.str.startswith('ClassI:')]\n",
    "REPET_ClassII_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.COS.str.startswith('ClassII:')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:23.988Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 20}\n",
    "label_config_x = {'fontsize'            : 'large',\n",
    "      'verticalalignment'   : 'top',\n",
    "      'horizontalalignment' : 'center'\n",
    "      }\n",
    "label_config_y = {'fontsize'            : 'large',\n",
    "      'verticalalignment'   : 'bottom',\n",
    "      'horizontalalignment' : 'center'\n",
    "      }\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:25.297Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassI_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassI_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**4, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassI_age.png' % (genome, Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:30.946Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassI_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassI_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**6, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassI_age.png' % (genome, Tenovodb))\n",
    "f.savefig(out_fn, dpi=600,bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:33.235Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassII_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassII_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**6, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassII_age.png' % (genome, Tenovodb))\n",
    "f.savefig(out_fn, dpi=600,bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:33.844Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassII_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassII_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**4, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassII_age.png' % (genome, Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:35.253Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df_young_many = REPET_all_TEs_df[(REPET_all_TEs_df.copies > 50) &( REPET_all_TEs_df.TE_age_Mya < 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:35.809Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df_young_many_by_COS_sum = sub_df_young_many.groupby('COS').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:36.387Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df_young_many_by_COS_sum['Class'] = 'noCat'\n",
    "sub_df_young_many_by_COS_sum[\"Index\"] = sub_df_young_many_by_COS_sum.index\n",
    "sub_df_young_many_by_COS_sum['Order'] = 'noCat'\n",
    "sub_df_young_many_by_COS_sum['Class:Order'] = 'noCat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:37.490Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate Class column or noCat\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Class\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].Index.apply\\\n",
    "(lambda x: x.split(':')[0])\n",
    "\n",
    "#generate Order column or noCat\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Order\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].Index.apply\\\n",
    "(lambda x: x.split(':')[1])\n",
    "\n",
    "\n",
    "#generate Class order column\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Class:Order\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')]['Class']\\\n",
    "+ ':' +\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')]['Order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:38.867Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get color column sorted\n",
    "colors = sns.color_palette('cubehelix', n_colors=\\\n",
    "                           len(sub_df_young_many_by_COS_sum['Class:Order'].unique()))\n",
    "color_dict = dict(zip(sub_df_young_many_by_COS_sum['Class:Order'].unique(), colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:40.658Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df_young_many_by_COS_sum['color'] = sub_df_young_many_by_COS_sum['Class:Order'].apply(\\\n",
    "        lambda x: color_dict[x])\n",
    "color_index_dict = dict(zip(sub_df_young_many_by_COS_sum.Index, sub_df_young_many_by_COS_sum.color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:01:41.300Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "sns.barplot(sub_df_young_many_by_COS_sum.index, sub_df_young_many_by_COS_sum.covg/10**6,\\\n",
    "           palette=color_index_dict)\n",
    "\n",
    "plt.ylabel(\"Coverage [Mb]\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"\",fontsize = 12, weight= 'bold'\"\")\n",
    "sns.despine(trim=True)\n",
    "\n",
    "#change the colors of the legend\n",
    "key_list = list(color_dict.keys())\n",
    "key_list.sort()\n",
    "plt.legend(key_list, loc=(1, 0.1))\n",
    "leg = ax.get_legend()\n",
    "for (x,y) in zip(key_list, leg.legendHandles):\n",
    "    y.set_color(color_dict[x])\n",
    "    \n",
    "\n",
    "\n",
    "for l in ax.get_xticklabels():\n",
    "    l.set_rotation(90)\n",
    "\n",
    "out_fn = os.path.join(out_dir, '%s_%s_TEs_young_and_plenty.png'  % (genome, Tenovodb))\n",
    "f.savefig(out_fn, dpi=600, bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For haplotigs run up to here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now on to do the coverage analysis for the TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T08:17:26.686093Z",
     "start_time": "2018-04-05T08:17:26.102566Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_window_1k200_bed = BedTool().window_maker(g=genome_file_fh, w=window_size, s=slide_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T08:17:33.454769Z",
     "start_time": "2018-04-05T08:17:26.689198Z"
    }
   },
   "outputs": [],
   "source": [
    "#sort the TE gff file for easier handling with bedtools and convert some to bed files\n",
    "TE_gff_sorted_fh = TE_gff_fh.replace('.gff3', '.sorted.gff3')\n",
    "TE_gff_superfamily_fh = os.path.join(out_dir,'%s.%s.REPET.superfamily.gff' % (genome, Tenovodb))\n",
    "TE_gff_superfamily_sorted_fh = TE_gff_superfamily_fh.replace('.gff', '.sorted.bed')\n",
    "TE_gff_TEfamily_fh = os.path.join(out_dir,'%s.%s.REPET.TE.gff' % (genome, Tenovodb))\n",
    "TE_gff_TEfamily_sorted_fh = TE_gff_TEfamily_fh.replace('.gff', '.sorted.bed') \n",
    "\n",
    "gff3sort_pl = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/get_homologues/gff3sort/gff3sort.pl'\n",
    "cmd1 = 'perl %s %s > %s' %(gff3sort_pl, TE_gff_fh , TE_gff_sorted_fh)\n",
    "cmd2 = \"perl %s %s | awk -v OFS='\\t' '{print $1, $4, $5, $9, $8, $7 }' > %s \" % (gff3sort_pl, TE_gff_superfamily_fh,TE_gff_superfamily_sorted_fh )\n",
    "cmd3 = \"perl %s %s | awk -v OFS='\\t' '{print $1, $4, $5, $9, $8, $7 }' > %s \" % (gff3sort_pl, TE_gff_TEfamily_fh ,TE_gff_TEfamily_sorted_fh )\n",
    "\n",
    "\n",
    "subprocess.check_output(cmd1, shell=True, stderr=subprocess.STDOUT)\n",
    "subprocess.check_output(cmd2, shell=True, stderr=subprocess.STDOUT)\n",
    "subprocess.check_output(cmd3, shell=True, stderr=subprocess.STDOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T08:17:39.582159Z",
     "start_time": "2018-04-05T08:17:33.458399Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the bed objects that are windows that will be used for the coverage analysis\n",
    "TE_bed = BedTool(fn=TE_gff_sorted_fh)\n",
    "g_TE_1k200_bed = g_window_1k200_bed.intersect(TE_bed)\n",
    "g_noTE_1k200_bed = g_window_1k200_bed.subtract(TE_bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T08:17:39.600335Z",
     "start_time": "2018-04-05T08:17:39.586064Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now read in the bam files as beds\n",
    "pbam_bed = BedTool(fn=pbam_fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T08:17:39.627122Z",
     "start_time": "2018-04-05T08:17:39.602957Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define outfile names to write out the coverage files\n",
    "TE_cov_dir = os.path.join(out_dir, 'TE_COV')\n",
    "if not os.path.exists(TE_cov_dir):\n",
    "    os.mkdir(TE_cov_dir)\n",
    "#really we want to do samtools bedcov    \n",
    "g_TE_1k200_samcovfh = os.path.join(TE_cov_dir, '%s.%s.g_TE_%ik%i.samcov' % (genome, Tenovodb, window_size/1000, slide_size ))\n",
    "g_noTE_1k200_samcovfh = os.path.join(TE_cov_dir, '%s.%s.g_noTE_%ik%i.samcov' % (genome, Tenovodb, window_size/1000, slide_size ))\n",
    "g_window_1k200_samcovfh = os.path.join(TE_cov_dir, '%s.%s.g_window_%ik%i.samcov' % (genome, Tenovodb, window_size/1000, slide_size ))\n",
    "TE_gff_superfamily_samcovfh = os.path.join(TE_cov_dir, TE_gff_superfamily_sorted_fh.split('/')[-1].replace('.bed','.samcov'))\n",
    "TE_gff_TEfamily_samcovfh = os.path.join(TE_cov_dir,TE_gff_TEfamily_sorted_fh.split('/')[-1].replace('.bed','.samcov'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T08:17:41.063781Z",
     "start_time": "2018-04-05T08:17:39.629926Z"
    }
   },
   "outputs": [],
   "source": [
    "g_window_1k200_bed.saveas(g_window_1k200_samcovfh.replace('.samcov', '.bed'))\n",
    "g_TE_1k200_bed.saveas(g_TE_1k200_samcovfh.replace('.samcov', '.bed'))\n",
    "g_noTE_1k200_bed.saveas(g_noTE_1k200_samcovfh.replace('.samcov', '.bed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-05T08:01:30.159Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make the BUSCOs bed file\n",
    "busco_df = pd.read_csv(protein_busco_fh, comment='#', header=None, sep='\\t')\n",
    "single_buscos = busco_df[busco_df[1] == 'Complete'][2].tolist()\n",
    "gene_bed_fh = os.path.join(source_dir, 'DK_0911_v04LT_p_ctg.gene.bed')\n",
    "gene_bed_df = pd.read_csv(gene_bed_fh, sep='\\t', header=None)\n",
    "single_busco_bed_fh = os.path.join(out_dir, '%s.sBUSCO.bed'%genome)\n",
    "single_busco_samcov_fh = os.path.join(TE_cov_dir, single_busco_bed_fh.split('/')[-1].replace('bed', 'samcov'))\n",
    "gene_bed_df[gene_bed_df[3].isin(single_buscos)].to_csv(single_busco_bed_fh, sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-05T08:01:30.161Z"
    }
   },
   "outputs": [],
   "source": [
    "beds = [g_TE_1k200_samcovfh.replace('.samcov', '.bed'),\\\n",
    "        g_noTE_1k200_samcovfh.replace('.samcov', '.bed'),\\\n",
    "        g_window_1k200_samcovfh.replace('.samcov', '.bed') ,\\\n",
    "       single_busco_bed_fh,\\\n",
    "       TE_gff_superfamily_sorted_fh,\\\n",
    "        TE_gff_TEfamily_sorted_fh]\n",
    "outs = [g_TE_1k200_samcovfh, g_noTE_1k200_samcovfh, g_window_1k200_samcovfh,\\\n",
    "        single_busco_samcov_fh, TE_gff_superfamily_samcovfh,  TE_gff_TEfamily_samcovfh]\n",
    "Parallel(n_jobs=len(beds))(delayed(run_samtools_bedcov)(bed, pbam_fh, out)\\\n",
    "                      for bed, out in zip(beds, outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T02:54:14.104695Z",
     "start_time": "2018-04-06T02:54:14.088411Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now make the BUSCO dataframe\n",
    "sBUSCO_df = samcov_slurp( single_busco_samcov_fh, fil=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T02:54:14.986536Z",
     "start_time": "2018-04-06T02:54:14.975869Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sBUSCO_df['contig_number'] = [int(x[-1]) for x in sBUSCO_df.contig.str.split('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T02:54:16.135071Z",
     "start_time": "2018-04-06T02:54:15.759691Z"
    }
   },
   "outputs": [],
   "source": [
    "sBUSCO_df.plot(x='contig_number', y='norm_cov', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T02:54:31.722513Z",
     "start_time": "2018-04-06T02:54:31.217016Z"
    }
   },
   "outputs": [],
   "source": [
    "sBUSCO_df['norm_cov'].plot(kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T02:54:38.889006Z",
     "start_time": "2018-04-06T02:54:38.881243Z"
    }
   },
   "outputs": [],
   "source": [
    "sBUSCO_mean = sum(sBUSCO_df.total_cov)/sum(sBUSCO_df.interval_size)\n",
    "print('The single BUSCO mean coverage is %0.2f.' % sBUSCO_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T02:55:01.601627Z",
     "start_time": "2018-04-06T02:54:58.927412Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_TE_1k200_samcov_df = samcov_slurp(g_TE_1k200_samcovfh, mean=sBUSCO_mean ,fil=False)\n",
    "g_noTE_1k200_samcov_df = samcov_slurp(g_noTE_1k200_samcovfh,mean=sBUSCO_mean, fil=False)\n",
    "g_window_1k200_samcov_df = samcov_slurp(g_window_1k200_samcovfh,mean=sBUSCO_mean,fil=False)\n",
    "TE_gff_superfamily_samcov_df = samcov_slurp(TE_gff_superfamily_samcovfh,mean=sBUSCO_mean,fil=False)\n",
    "TE_gff_TEfamily_samcov_df = samcov_slurp(TE_gff_TEfamily_samcovfh,mean=sBUSCO_mean,fil=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T05:33:05.219363Z",
     "start_time": "2018-04-05T05:30:32.313775Z"
    }
   },
   "source": [
    "sBUSCO_df['norm_cov'].plot(kind='kde',color='k')\n",
    "g_TE_1k200_samcov_df['norm_cov'].plot(kind='kde',color='r')\n",
    "g_window_1k200_samcov_df['norm_cov'].plot(kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T02:59:48.859808Z",
     "start_time": "2018-04-06T02:59:48.300701Z"
    }
   },
   "outputs": [],
   "source": [
    "sBUSCO_df['norm_cov'].plot(kind='hist',color='k', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T02:59:48.876087Z",
     "start_time": "2018-04-06T02:59:48.861540Z"
    }
   },
   "outputs": [],
   "source": [
    "TE_gff_superfamily_samcov_df['log10_ncov'] = np.log10(TE_gff_superfamily_samcov_df['norm_cov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T03:53:18.514024Z",
     "start_time": "2018-04-06T03:53:16.712979Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,15))\n",
    "order = pd.concat([classI_df.sort_values('bp', ascending=False)['Class:Order:Superfamily'],  \\\n",
    "                   classII_df.sort_values('bp', ascending=False)['Class:Order:Superfamily']])\n",
    "sns.boxplot(x='ID', y='log10_ncov', data=TE_gff_superfamily_samcov_df, ax=ax, order=order)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T03:39:16.711665Z",
     "start_time": "2018-04-06T03:39:16.567413Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genome_size = pd.read_csv(genome_file_fh, sep='\\t',header=None)[1].sum()\n",
    "mean_genome = sum(g_window_1k200_samcov_df.total_cov)/sum(g_window_1k200_samcov_df.interval_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-10T05:23:59.825708Z",
     "start_time": "2018-04-10T05:23:59.813445Z"
    }
   },
   "outputs": [],
   "source": [
    "genome_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T03:39:17.578351Z",
     "start_time": "2018-04-06T03:39:17.570924Z"
    }
   },
   "outputs": [],
   "source": [
    "int(genome_size *(mean_genome/sBUSCO_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T03:39:29.942293Z",
     "start_time": "2018-04-06T03:39:29.121239Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_TEs = sum(g_TE_1k200_samcov_df.total_cov)/sum(g_TE_1k200_samcov_df.interval_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T03:39:30.017048Z",
     "start_time": "2018-04-06T03:39:29.945566Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_sfamily_TEs = sum(TE_gff_superfamily_samcov_df.total_cov)/sum(TE_gff_superfamily_samcov_df.interval_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T03:39:30.133623Z",
     "start_time": "2018-04-06T03:39:30.126502Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_sfamily_TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T03:39:31.127149Z",
     "start_time": "2018-04-06T03:39:31.119992Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T03:39:38.818165Z",
     "start_time": "2018-04-06T03:39:38.811277Z"
    }
   },
   "outputs": [],
   "source": [
    "sBUSCO_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T03:39:46.009523Z",
     "start_time": "2018-04-06T03:39:46.002211Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T03:39:50.838496Z",
     "start_time": "2018-04-06T03:39:50.665830Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(g_noTE_1k200_samcov_df.total_cov)/sum(g_noTE_1k200_samcov_df.interval_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T03:47:04.425911Z",
     "start_time": "2018-04-06T03:47:03.650779Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(g_TE_1k200_samcov_df.total_cov)/sum(g_TE_1k200_samcov_df.interval_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T03:47:23.495693Z",
     "start_time": "2018-04-06T03:47:23.369645Z"
    }
   },
   "outputs": [],
   "source": [
    "TE_gff_superfamily_samcov_df.pivot_table(values='norm_cov', columns='ID', aggfunc=[np.mean, np.count_nonzero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-05T08:01:30.329Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TE_gff_superfamily_samcov_df.groupby('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T02:53:59.043884Z",
     "start_time": "2018-04-06T02:53:59.014508Z"
    }
   },
   "outputs": [],
   "source": [
    "TE_gff_superfamily_samcov_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
