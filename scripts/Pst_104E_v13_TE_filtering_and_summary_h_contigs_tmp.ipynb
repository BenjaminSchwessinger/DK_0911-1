{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed at summarzing the REPET output at different levels of the nomenclature and to plot this out. Parts of it are really slow.\n",
    "\n",
    "\n",
    "This notebook was only designed for the purpose of analyzing the Pst-104E genome. No gurantees it works in any other situtation. It will have spelling errors due to the lack of autocorrection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:05:54.433452Z",
     "start_time": "2019-04-07T07:05:50.722404Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/Bio/SearchIO/__init__.py:211: BiopythonExperimentalWarning: Bio.SearchIO is an experimental submodule which may undergo significant changes prior to its future official release.\n",
      "  BiopythonExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SearchIO\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import multiprocessing\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:05:54.577167Z",
     "start_time": "2019-04-07T07:05:54.450074Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ID_filter_gff(_feature, _id):\n",
    "    \"\"\"\n",
    "    This filter parses out the top level id form the 9th gff column form a REPET gff file.\n",
    "    It has a specific search pattern for each feature type in column 2.\n",
    "    _type is defined by the feature '_'.join(feature.split(\"_\")[-2:])\n",
    "    This function expects that the variable genome either ends with p_ctg or h_ctg and adapts the\n",
    "    search pattern accordingly.\n",
    "    \"\"\"\n",
    "    _type = '_'.join(_feature.split(\"_\")[-2:])\n",
    "    if _type == 'REPET_TEs':\n",
    "        if genome.endswith('p_ctg'):\n",
    "            TE_pattern = r'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_([^;| ]*)'\n",
    "        elif genome.endswith('h_ctg'):\n",
    "            TE_pattern = r'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_[0-9]*_([^;| ]*)'\n",
    "        TE_prog = re.compile(TE_pattern)\n",
    "        TE_match = TE_prog.search(_id)\n",
    "\n",
    "        try:\n",
    "            return TE_match.group(1)\n",
    "        except AttributeError:\n",
    "            print(_id)\n",
    "\n",
    "    if _type == 'REPET_SSRs':\n",
    "        if genome.endswith('p_ctg'):\n",
    "            SSR_pattern = 'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_([A-Z,a-z,0-9,-]*)'\n",
    "        elif genome.endswith('h_ctg'):\n",
    "            SSR_pattern = 'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_[0-9]*_([A-Z,a-z,0-9,-]*)'\n",
    "        SSR_prog = re.compile(SSR_pattern)\n",
    "        SSR_match = SSR_prog.search(_id)\n",
    "        return SSR_match.group(1)\n",
    "    if _type == 'REPET_tblastx' or _type == 'REPET_blastx':\n",
    "        if genome.endswith('p_ctg'):\n",
    "            blast_prog = re.compile(r'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_([^;| ]*)')\n",
    "        elif genome.endswith('h_ctg'):\n",
    "             blast_prog = re.compile(r'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_[0-9]*_[0-9]*_([^;| ]*)')\n",
    "        #blast_prog = re.compile(blast_pattern)\n",
    "        blast_match = blast_prog.search(_id)\n",
    "        return blast_match.group(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:05:54.681208Z",
     "start_time": "2019-04-07T07:05:54.578874Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blast_hit_gff(_feature, _row8, _id):\n",
    "    \"\"\"\n",
    "    This filter parses the blast hit for REPET_TEs from the new 'ID' column. If no blast hit available returns Pastec ids.\n",
    "    If the result is blast already the value is simple parse the blast hit.\n",
    "    SSRs also get SSR\n",
    "    !!!Requires the three_letter_dict to be defined previously.!!!\n",
    "    _type is defined by the feature '_'.join(feature.split(\"_\")[-2:])\n",
    "    \"\"\"\n",
    "    _type = '_'.join(_feature.split(\"_\")[-2:])\n",
    "    if _type == 'REPET_TEs':\n",
    "        #split the pastec_cat into the first three letter code\n",
    "        #the spliting of the 'ID' column needs to be done differently depending on the h or p contigs.\n",
    "        #h contigs contain one additional '_' in the contig id\n",
    "\n",
    "        pastec_cat = _id.split('_')[0]\n",
    "        if 'TE_BLR' in _row8:\n",
    "            #hit_list = [x.split(';')[3] for x in _row8]\n",
    "            blast_hit_pattern = r'TE_BLR\\w*: (\\S*)[ |;]'\n",
    "            blast_hit_prog = re.compile(blast_hit_pattern)\n",
    "            TE_match = blast_hit_prog.findall(_row8)\n",
    "            first_sub_class = ':'.join(TE_match[0][:-1].split(':')[1:])\n",
    "            if len([x for x in TE_match if first_sub_class in x]) == len(TE_match):\n",
    "                if ';' in first_sub_class:\n",
    "                    return first_sub_class.split(';')[0]\n",
    "                else:\n",
    "                    return first_sub_class\n",
    "#fix this here to include the there letter code of the first bit of the ID similar to the blast hits\n",
    "#e.g. ClassI:?:? and so on. a dict might be the easiest here.\n",
    "            \n",
    "            else:\n",
    "                return three_letter_dict[pastec_cat]\n",
    "        else:\n",
    "            return three_letter_dict[pastec_cat]\n",
    "    if _type == 'REPET_SSRs':\n",
    "        return 'SSR'\n",
    "        \n",
    "\n",
    "        return SSR_match.group(1)\n",
    "    if _type == 'REPET_tblastx' or _type == 'REPET_blastx':\n",
    "        return ':'.join(_id.split(':')[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:05:54.765196Z",
     "start_time": "2019-04-07T07:05:54.682993Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TE_classification_filter(_id, level = 0):\n",
    "    \"\"\"\n",
    "    This function pulls out the class == level1, Order == level2, Superfamily == leve3.\n",
    "    If SSR or noCat return these values.\n",
    "    \n",
    "    \"\"\"\n",
    "    if len(_id.split(':')) == 1:\n",
    "        return _id\n",
    "    if level == 0:\n",
    "        _class = _id.split(':')[0]\n",
    "        if _class == 'ClassI':\n",
    "            return 'Retrotransposon'\n",
    "        if _class == 'ClassII':\n",
    "            return 'DNA_transposon'\n",
    "    elif level == 1:\n",
    "        _order = _id.split(':')[1]\n",
    "        if _order == '?':\n",
    "            return 'noCat'\n",
    "        else:\n",
    "            return _order\n",
    "    elif level == 2:\n",
    "        _superfamily = _id.split(':')[2]\n",
    "        if _superfamily == '?':\n",
    "            return 'noCat'\n",
    "        else:\n",
    "            return _superfamily\n",
    "    else:\n",
    "        print('Something wrong! Check if level is 0, 1 or 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:05:54.929176Z",
     "start_time": "2019-04-07T07:05:54.879881Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset the id and safe in specific folder\n",
    "# return the subsetted file as bedtool\n",
    "def subset_id(_id, bed_fh, repet_prefix, genome_file_fh):\n",
    "    '''A function that takes the a ID, e.g. from the ID column 9 of a gff,\n",
    "    a bed file handle, e.g. the gff frame, a certain file prefix, and a genome_file handle.\n",
    "    It saves out the coverage file and the gff file for the specific ID.'''\n",
    "    #ClassI are retrotransposon form blast\n",
    "    if 'ClassI:' in _id:\n",
    "        out_path = TE_path_dict['Retrotransposon']   \n",
    "    #ClassII are DNA_transponson\n",
    "    elif 'ClassII' in _id:\n",
    "        out_path = TE_path_dict['DNA_transposon'] \n",
    "    #The rest with '_' should be REPET_TEs\n",
    "    elif _id == 'noCat':\n",
    "        out_path = TE_path_dict['noCat']\n",
    "    #everything without '_' at the end should be SSR\n",
    "    elif _id == 'SSR':\n",
    "        out_path = TE_path_dict['SSR']\n",
    "    cov_fh = os.path.join(out_path,'%s.%s.cov' %(repet_prefix,_id))\n",
    "    gff_fh = cov_fh.replace('.cov', '.gff')\n",
    "    result = pybedtools.BedTool(bed_fh).filter(id_filter, _id).saveas(gff_fh)\n",
    "    result.genome_coverage(dz=True,g=genome_file_fh).saveas(cov_fh)\n",
    "    print('Done with callculating coverage of %s.'% _id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:05:57.009175Z",
     "start_time": "2019-04-07T07:05:56.991923Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next, we create a function to pass only features for a particular\n",
    "# featuretype.  This is similar to a \"grep\" operation when applied to every\n",
    "# feature in a BedTool\n",
    "def id_filter(feature, _id):\n",
    "    if feature[8] == _id:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:05:57.773157Z",
     "start_time": "2019-04-07T07:05:57.647807Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def samcov_slurp(file_name, mean=False, fil=True):\n",
    "    \"\"\"\n",
    "    Function that slurps in the the file via the file_name and tests if looks a samcov file.\n",
    "    If this is the case it makes a dataframe out of the samcov file and calculates the following values.\n",
    "    Ave_cov per window, which is the average coverage for each genomic interval. \n",
    "    Norm_cov per window, is the normalized coverage for each genomic interavl. This\n",
    "    can be either calculated by via the mean coverage of the dataframe or via a provided mean.\n",
    "    \"\"\"\n",
    "    if file_name.endswith('.samcov') == False:\n",
    "        print(\"%s Might not be a samcov file. Please check\" % file_name)\n",
    "        return False\n",
    "        \n",
    "    samcov_header_bed_3 = ['contig', 'start', 'stop', 'total_cov']\n",
    "    samcov_header_bed_6 = ['contig', 'start', 'stop', 'ID', 'score', 'strand','total_cov']\n",
    "    df = pd.read_csv(file_name, sep='\\t', header=None)\n",
    "    if len(df.columns) == 4:\n",
    "        df.rename(columns=dict(zip(df.columns, samcov_header_bed_3)), inplace=True)\n",
    "    elif len(df.columns) == 7:\n",
    "        df.rename(columns=dict(zip(df.columns, samcov_header_bed_6)), inplace=True)\n",
    "    else:\n",
    "        print(\"%s Might not be a samcov file. Please check\" % file_name)\n",
    "        return False\n",
    "    \n",
    "    df['interval_size'] = (df.stop-df.start)\n",
    "    df['ave_cov'] = df.total_cov/df['interval_size']\n",
    "    if mean == False:\n",
    "        df_mean = sum(df.total_cov)/sum(df.interval_size)\n",
    "        df['norm_cov'] = df['ave_cov']/df_mean\n",
    "    else:\n",
    "        df['norm_cov'] = df['ave_cov']/mean\n",
    "    #rounder = pd.Series([0,0,0,0,2], index = df.columns)\n",
    "    df.ave_cov = df.ave_cov.round()\n",
    "    if fil == True:\n",
    "        low = 0 #these were defined empirical based on the iqr caculations using 0.01 \n",
    "        high = 400 #and 0.99 as cut off.\n",
    "        df = df[(df.ave_cov >= low) & (df.ave_cov <= high)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:05:58.565174Z",
     "start_time": "2019-04-07T07:05:58.547828Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_samtools_bedcov(window_bed_fn, bam_fn, output_fh):\n",
    "    \"\"\"Runs samtools bedcov as a subprocess so we can paralize the different runs saving some time.\n",
    "    Input: \n",
    "    The window_bed fn for which the samtools bedcov should be calculated.\n",
    "    The bam_fn file that contains the read mapping.\n",
    "    The output_fn where the output is saved to.\n",
    "    These should be absolute path\"\"\"\n",
    "    cmd = r'samtools bedcov %s %s > %s' % (window_bed_fn, bam_fn,output_fh)\n",
    "    stderr = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)\n",
    "    print('Done with %s' % cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "TO-DO   \n",
    "This notebook runs on DK0911v03/4 which are the same as the pwoh to h re-assignment has already been completed. \n",
    "REPET was run in the two round annotation mode (see /home/benjamin/genome_assembly/Warrior/REPET/TEanno/primary/TEanno01_finish.sh) for details. The repeat database was 104Ep_DK0911p/104Ep_DK0911p_withoutRedundancy.fa which was produced by combining newly discovered REPEATs from DK0911 and Pst104Ep. The classif_table in the SQL was 104Ep_DK0911p_classif.\n",
    "All REPET gff files got combined as follows using the the naming convention GENOME.DENOVODATABASE.REPET.gff.\n",
    "\n",
    "DK_0911_v04_p_ctg.104Ep_DK0911p.REPET.gff3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change following input here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:08:46.413225Z",
     "start_time": "2019-04-07T07:08:46.387948Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_dir = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/092017_assembly'\n",
    "genome = 'Pst_104E_v13_h_ctg'\n",
    "#in case the genome version for the REPET run had a different ID.\n",
    "genome_repet = 'Pst104Eh_a1'\n",
    "Tenovodb = '104Ep_DK0911p'\n",
    "out_dir = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/Warrior_comp_runs/REPET/TE_analysis'\n",
    "repet_db_dir = '/home/benjamin/databases/REPET'\n",
    "#This needs to be updated here according to genome\n",
    "TE_postanalysis_dir = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/Warrior_comp_runs/REPET/04032019/TEanno_full/postanalysis'\n",
    "#threads to use for multithreading\n",
    "threads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:08:49.691492Z",
     "start_time": "2019-04-07T07:08:49.677494Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:05:16.149170Z",
     "start_time": "2019-04-07T07:05:16.122694Z"
    },
    "collapsed": true
   },
   "source": [
    "###here are some input files for the mapping rate coverage analysis using SRM\n",
    "SRM_dir = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/Warrior_comp_runs/SRM'\n",
    "pbam_fh = os.path.join(SRM_dir, 'Pst_104E_v13_p_ctg.bwamem.Pst79_folder5.bam')\n",
    "genome_fh = os.path.join(source_dir, '%s.fa' %genome)\n",
    "genome_file_fh = os.path.join(source_dir, '%s.genome_file' %genome)\n",
    "TE_gff_fh = os.path.join(out_dir,'%s.%s.REPET.gff3' % (genome, Tenovodb))\n",
    "protein_busco_fh = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/Warrior_comp_runs/busco3/run_Pst_104E_v13_p_ctg.protein/full_table_Pst_104E_v13_p_ctg.protein.tsv'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:05:16.173174Z",
     "start_time": "2019-04-07T07:05:16.150849Z"
    },
    "collapsed": true
   },
   "source": [
    "#the window size for downstream coverage analysis\n",
    "window_size = 5000\n",
    "slide_size = 1000\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:05:16.193158Z",
     "start_time": "2019-04-07T07:05:16.174909Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "source": [
    "#now generate the genmoe files if not present yet\n",
    "if not os.path.exists(genome_file_fh):\n",
    "    !samtools faidx {genome_fh}\n",
    "    !cat {genome_fh}.fai | sort -k1,1n | cut -f 1,2 > {genome_file_fh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:09:04.549276Z",
     "start_time": "2019-04-07T07:09:03.845722Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove all commenting lines from the initial repet file\n",
    "!grep -v \"^#\" {source_dir}/{genome}.{Tenovodb}.REPET.gff3 > {out_dir}/{genome}.{Tenovodb}.REPET.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:09:10.716383Z",
     "start_time": "2019-04-07T07:09:06.565929Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in repet_gff file\n",
    "repet_gff = pd.read_csv(os.path.join(out_dir, '%s.%s.REPET.gff3'%(genome,Tenovodb)), sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:09:10.909252Z",
     "start_time": "2019-04-07T07:09:10.894827Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TE_post_analysis_p_header = 'TE      length  covg    frags   fullLgthFrags   copies  fullLgthCopies  meanId  sdId    minId   q25Id   medId   q75Id   maxId   meanLgth        sdLgth  minLgth q25Lgth medLgth q75Lgth maxLgth meanLgthPerc    sdLgthPerc      minLgthPerc  q25LgthPerc     medLgthPerc     q75LgthPerc     maxLgthPerc'.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:09:12.401148Z",
     "start_time": "2019-04-07T07:09:12.388034Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TE_post_analysis_p_header = [x for x in TE_post_analysis_p_header if x != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:09:15.305280Z",
     "start_time": "2019-04-07T07:09:15.103810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blastclust.log\r\n",
      "error.log\r\n",
      "Pst104Eh_a1_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_FullLengthCopy.fa\r\n",
      "Pst104Eh_a1_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_FullLengthCopy.txt\r\n",
      "Pst104Eh_a1_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_FullLengthFrag.fa\r\n",
      "Pst104Eh_a1_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_FullLengthFrag.txt\r\n",
      "Pst104Eh_a1_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_OneCopyAndMore.fa\r\n",
      "Pst104Eh_a1_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_OneCopyAndMore.txt\r\n",
      "Pst104Eh_a1_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE.tab\r\n",
      "Pst104Eh_a1_chr_allTEs_nr_noSSR_join_path.globalAnnotStatsPerTE.txt\r\n",
      "Pst104Eh_a1_chr_allTEs_path.annotStatsPerTE_FullLengthCopy.fa\r\n",
      "Pst104Eh_a1_chr_allTEs_path.annotStatsPerTE_FullLengthCopy.txt\r\n",
      "Pst104Eh_a1_chr_allTEs_path.annotStatsPerTE_FullLengthFrag.fa\r\n",
      "Pst104Eh_a1_chr_allTEs_path.annotStatsPerTE_FullLengthFrag.txt\r\n",
      "Pst104Eh_a1_chr_allTEs_path.annotStatsPerTE_OneCopyAndMore.fa\r\n",
      "Pst104Eh_a1_chr_allTEs_path.annotStatsPerTE_OneCopyAndMore.txt\r\n",
      "Pst104Eh_a1_chr_allTEs_path.annotStatsPerTE.tab\r\n",
      "Pst104Eh_a1_chr_allTEs_path.globalAnnotStatsPerTE.txt\r\n",
      "Pst104Eh_a1_chr_bankBLRtx_path.annotStatsPerTE_FullLengthCopy.fa\r\n",
      "Pst104Eh_a1_chr_bankBLRtx_path.annotStatsPerTE_FullLengthCopy.txt\r\n",
      "Pst104Eh_a1_chr_bankBLRtx_path.annotStatsPerTE_FullLengthFrag.fa\r\n",
      "Pst104Eh_a1_chr_bankBLRtx_path.annotStatsPerTE_FullLengthFrag.txt\r\n",
      "Pst104Eh_a1_chr_bankBLRtx_path.annotStatsPerTE_OneCopyAndMore.fa\r\n",
      "Pst104Eh_a1_chr_bankBLRtx_path.annotStatsPerTE_OneCopyAndMore.txt\r\n",
      "Pst104Eh_a1_chr_bankBLRtx_path.annotStatsPerTE.tab\r\n",
      "Pst104Eh_a1_chr_bankBLRtx_path.globalAnnotStatsPerTE.txt\r\n",
      "Pst104Eh_a1_chr_bankBLRx_path.annotStatsPerTE_FullLengthCopy.fa\r\n",
      "Pst104Eh_a1_chr_bankBLRx_path.annotStatsPerTE_FullLengthCopy.txt\r\n",
      "Pst104Eh_a1_chr_bankBLRx_path.annotStatsPerTE_FullLengthFrag.fa\r\n",
      "Pst104Eh_a1_chr_bankBLRx_path.annotStatsPerTE_FullLengthFrag.txt\r\n",
      "Pst104Eh_a1_chr_bankBLRx_path.annotStatsPerTE_OneCopyAndMore.fa\r\n",
      "Pst104Eh_a1_chr_bankBLRx_path.annotStatsPerTE_OneCopyAndMore.txt\r\n",
      "Pst104Eh_a1_chr_bankBLRx_path.annotStatsPerTE.tab\r\n",
      "Pst104Eh_a1_chr_bankBLRx_path.globalAnnotStatsPerTE.txt\r\n",
      "Pst104Eh_a1_refTEs.fa\r\n",
      "Pst104Eh_a1_refTEs.fa_blastclust.classifStatsPerCluster.tab\r\n",
      "Pst104Eh_a1_refTEs.fa_blastclust.globalStatsPerCluster.txt\r\n",
      "Pst104Eh_a1_refTEs.fa_blastclust.statsPerCluster.tab\r\n",
      "Pst104Eh_a1_refTEs.fa_blastclust.tab\r\n"
     ]
    }
   ],
   "source": [
    "!ls {TE_postanalysis_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This needs to be updated here according to genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:09:21.169366Z",
     "start_time": "2019-04-07T07:09:21.106887Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this needs to be fixed up to pick the proper summary table\n",
    "#this reads in the REPET summary dataframe\n",
    "REPET_sdf = pd.read_csv(os.path.join(TE_postanalysis_dir,\\\n",
    "                    '%s_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE.tab' % genome_repet),\\\n",
    "                        names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n",
    "#this pulls out the TE classificaiton from the TE column\n",
    "REPET_sdf['Code'] = REPET_sdf['TE'].apply(lambda x: x.split('_')[0])\n",
    "code_keys = REPET_sdf['Code'].unique()\n",
    "code_keys.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:09:21.809264Z",
     "start_time": "2019-04-07T07:09:21.794623Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the previous code_dict from file in the repet database folder\n",
    "with open(os.path.join(repet_db_dir, 'code_dict.dict'), 'r') as file:\n",
    "    code_dict = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:09:22.323356Z",
     "start_time": "2019-04-07T07:09:22.302719Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now check if all code keys to long classifications are already in the dict\n",
    "#if this isn't the case get the missing keys\n",
    "execute_cell = False\n",
    "if set(code_keys).issubset(set(code_dict.keys()))  == False:\n",
    "    execute_cell = True\n",
    "    missing_keys = []\n",
    "    for x in code_keys:\n",
    "        if x not in code_dict.keys():\n",
    "            missing_keys.append(x)\n",
    "            print('Please add the following key value pair to the dictionary and save it out: %s'%x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:09:22.891237Z",
     "start_time": "2019-04-07T07:09:22.863947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing new\n"
     ]
    }
   ],
   "source": [
    "#now get some user input for the missing code: long namenclature pairing via a widget\n",
    "dict_parings = 'Nothing new'\n",
    "if execute_cell == True:\n",
    "    dict_parings = widgets.Text()\n",
    "    print('These are the new required additions to the dictionary\\n\\n')\n",
    "    print(missing_keys)\n",
    "    print('Please enter as key:value, key:value') #define how the widget should be filled\n",
    "    ##TO DO, write a test for this being entered correctly###\n",
    "    print('\\n\\n')\n",
    "    print(code_dict)\n",
    "else:\n",
    "    print(dict_parings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:09:23.593088Z",
     "start_time": "2019-04-07T07:09:23.562230Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now add the new key: value pair to the dictionary\n",
    "if dict_parings != 'Nothing new':\n",
    "    print(dict_parings.value)\n",
    "    keys = []\n",
    "    values = []\n",
    "    for element in dict_parings.value.split(','):\n",
    "        keys.append(element.split(':')[0].strip())\n",
    "        values.append(element.split(':')[1].strip())\n",
    "    code_dict.update(dict(zip(keys,values)))\n",
    "    print(\"Updating the code_dict\")\n",
    "    with open(os.path.join(repet_db_dir, 'code_dict.dict'), 'w') as file:\n",
    "        file.write(json.dumps(code_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:09:24.253181Z",
     "start_time": "2019-04-07T07:09:24.139893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick summary for each category based on the REPET summary dataframe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>copies</th>\n",
       "      <th>covg</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Code long</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DNA_transposon Helitron</th>\n",
       "      <td>1529</td>\n",
       "      <td>1042560</td>\n",
       "      <td>5552.413793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon MITE</th>\n",
       "      <td>5118</td>\n",
       "      <td>1241858</td>\n",
       "      <td>485.407143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon Maverick</th>\n",
       "      <td>229</td>\n",
       "      <td>419591</td>\n",
       "      <td>10042.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon TIR</th>\n",
       "      <td>16125</td>\n",
       "      <td>9828369</td>\n",
       "      <td>3619.958838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon noCat</th>\n",
       "      <td>3887</td>\n",
       "      <td>1446074</td>\n",
       "      <td>2060.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Potential Host Gene</th>\n",
       "      <td>580</td>\n",
       "      <td>316560</td>\n",
       "      <td>3693.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon DIRS</th>\n",
       "      <td>873</td>\n",
       "      <td>810954</td>\n",
       "      <td>7512.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon LARD</th>\n",
       "      <td>9320</td>\n",
       "      <td>4081053</td>\n",
       "      <td>5628.323699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon LINE</th>\n",
       "      <td>338</td>\n",
       "      <td>212743</td>\n",
       "      <td>4159.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon LTR</th>\n",
       "      <td>16793</td>\n",
       "      <td>13997582</td>\n",
       "      <td>6383.302103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon SINE</th>\n",
       "      <td>89</td>\n",
       "      <td>16308</td>\n",
       "      <td>275.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon TRIM</th>\n",
       "      <td>545</td>\n",
       "      <td>168710</td>\n",
       "      <td>1428.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon noCat</th>\n",
       "      <td>113</td>\n",
       "      <td>82095</td>\n",
       "      <td>5940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noCat</th>\n",
       "      <td>1181</td>\n",
       "      <td>720451</td>\n",
       "      <td>1546.275000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         copies      covg        length\n",
       "Code long                                              \n",
       "DNA_transposon Helitron    1529   1042560   5552.413793\n",
       "DNA_transposon MITE        5118   1241858    485.407143\n",
       "DNA_transposon Maverick     229    419591  10042.875000\n",
       "DNA_transposon TIR        16125   9828369   3619.958838\n",
       "DNA_transposon noCat       3887   1446074   2060.820000\n",
       "Potential Host Gene         580    316560   3693.352941\n",
       "Retrotransposon DIRS        873    810954   7512.192308\n",
       "Retrotransposon LARD       9320   4081053   5628.323699\n",
       "Retrotransposon LINE        338    212743   4159.000000\n",
       "Retrotransposon LTR       16793  13997582   6383.302103\n",
       "Retrotransposon SINE         89     16308    275.500000\n",
       "Retrotransposon TRIM        545    168710   1428.611111\n",
       "Retrotransposon noCat       113     82095   5940.000000\n",
       "noCat                      1181    720451   1546.275000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick summary for each category based on the REPET summary dataframe\n",
    "REPET_sdf['Code long'] = REPET_sdf['Code'].apply(lambda x: code_dict[x])\n",
    "REPET_sdf_sum_df = pd.pivot_table(REPET_sdf, values=['covg', 'copies'], index='Code long', aggfunc=np.sum)\n",
    "REPET_sdf_mean_df = pd.pivot_table(REPET_sdf, values='length', index='Code long', aggfunc=np.mean)\n",
    "print('quick summary for each category based on the REPET summary dataframe')\n",
    "pd.concat([REPET_sdf_sum_df,REPET_sdf_mean_df], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:09:30.681325Z",
     "start_time": "2019-04-07T07:09:24.748264Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now read in all actuall REPET GFF file\n",
    "REPET_gff_df = pd.read_csv(os.path.join(out_dir,'%s.%s.REPET.gff3' % (genome, Tenovodb))\\\n",
    "                           , sep='\\t', header = None)\n",
    "#filter out host genes\n",
    "REPET_gff_df = REPET_gff_df[~REPET_gff_df[8].str.contains(\"Potential\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:09:59.353193Z",
     "start_time": "2019-04-07T07:09:30.683505Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df['ID'] = REPET_gff_df.apply(lambda row: ID_filter_gff(row[1], row[8]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:10:00.621175Z",
     "start_time": "2019-04-07T07:09:59.355105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aas\n"
     ]
    }
   ],
   "source": [
    "code_keys_gff = REPET_gff_df[REPET_gff_df[1].str.contains('REPET_TE')]['ID'].unique()\n",
    "code_keys_gff = list({x.split('_')[0] for x in code_keys_gff})\n",
    "three_letter_code = list({x for x in code_keys_gff})\n",
    "three_letter_code.sort()\n",
    "three_letter_values = []\n",
    "for x in three_letter_code:\n",
    "    if 'MITE' in x:\n",
    "        _value = \"ClassII:MITE:?\"\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    if 'LARD' in x:\n",
    "        _value = 'ClassI:LARD:?'\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    if 'TRIM' in x:\n",
    "        _value = 'ClassI:TRIM:?'\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    _value =''\n",
    "    if x[0] == 'D':\n",
    "        _value = _value + 'ClassII:'\n",
    "    if x[0] == 'R':\n",
    "        _value = _value + 'ClassI:'\n",
    "    if x[0] != 'D' and x[0] != 'R':\n",
    "        _value = 'noCat'\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    if x[1] == 'T':\n",
    "        _value = _value + 'TIR:?'\n",
    "    if x[1] == 'H':\n",
    "        _value = _value + 'Helitron:?'\n",
    "    if x[1] == 'M':\n",
    "        _value = _value + 'Maverick:?'\n",
    "    if x[0:2] == 'DY':\n",
    "        _value = _value + ':Crypton:?'\n",
    "    if x[1] == 'X':\n",
    "        _value = _value + '?:?'\n",
    "    if x[1] == 'I':\n",
    "        _value = _value + 'LINE:?'\n",
    "    if x[1] == 'L':\n",
    "        _value = _value + 'LTR:?'\n",
    "    if x[1] == 'P':\n",
    "        _value = _value + 'Penelope:?'\n",
    "    if x[1] == 'S':\n",
    "        _value = _value + 'SINE:?'\n",
    "    if x[0:2] == 'RY':\n",
    "        _value = _value + 'DIRS:?'    \n",
    "    three_letter_values.append(_value)\n",
    "\n",
    "if len(three_letter_code) == len(three_letter_values):\n",
    "    print(\"Aas\")\n",
    "    three_letter_dict = dict(zip(three_letter_code, three_letter_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:10:00.641151Z",
     "start_time": "2019-04-07T07:10:00.622970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DHX-comp': 'ClassII:Helitron:?',\n",
       " 'DHX-incomp': 'ClassII:Helitron:?',\n",
       " 'DHX-incomp-chim': 'ClassII:Helitron:?',\n",
       " 'DMX-incomp': 'ClassII:Maverick:?',\n",
       " 'DTX-comp': 'ClassII:TIR:?',\n",
       " 'DTX-comp-chim': 'ClassII:TIR:?',\n",
       " 'DTX-incomp': 'ClassII:TIR:?',\n",
       " 'DTX-incomp-chim': 'ClassII:TIR:?',\n",
       " 'DXX': 'ClassII:?:?',\n",
       " 'DXX-MITE': 'ClassII:MITE:?',\n",
       " 'DXX-MITE-chim': 'ClassII:MITE:?',\n",
       " 'RIX-comp': 'ClassI:LINE:?',\n",
       " 'RIX-incomp': 'ClassI:LINE:?',\n",
       " 'RIX-incomp-chim': 'ClassI:LINE:?',\n",
       " 'RLX-comp': 'ClassI:LTR:?',\n",
       " 'RLX-comp-chim': 'ClassI:LTR:?',\n",
       " 'RLX-incomp': 'ClassI:LTR:?',\n",
       " 'RLX-incomp-chim': 'ClassI:LTR:?',\n",
       " 'RSX-incomp': 'ClassI:SINE:?',\n",
       " 'RSX-incomp-chim': 'ClassI:SINE:?',\n",
       " 'RXX': 'ClassI:?:?',\n",
       " 'RXX-LARD': 'ClassI:LARD:?',\n",
       " 'RXX-LARD-chim': 'ClassI:LARD:?',\n",
       " 'RXX-TRIM': 'ClassI:TRIM:?',\n",
       " 'RXX-TRIM-chim': 'ClassI:TRIM:?',\n",
       " 'RXX-chim': 'ClassI:?:?',\n",
       " 'RYX-comp': 'ClassI:DIRS:?',\n",
       " 'RYX-comp-chim': 'ClassI:DIRS:?',\n",
       " 'RYX-incomp': 'ClassI:DIRS:?',\n",
       " 'RYX-incomp-chim': 'ClassI:DIRS:?',\n",
       " 'noCat': 'noCat'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this three letter dict is required for the blast_hit_gff function to work and needs to be generated\n",
    "three_letter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:10:29.762079Z",
     "start_time": "2019-04-07T07:10:00.645765Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df['Class:Order:Superfamily'] = REPET_gff_df.apply(lambda row: blast_hit_gff(row[1], row[8], row['ID']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:10:32.233217Z",
     "start_time": "2019-04-07T07:10:29.770654Z"
    }
   },
   "outputs": [],
   "source": [
    "#generate a dict that can be used to rename the Class:Order:Superfamily column \n",
    "#considering that partial matches ([2] == match_part) might contain different\n",
    "#IDs even though they are the same TE only partial.\n",
    "_tmp_subset = REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')].loc[:, 'ID':].sort_values(by=['ID','Class:Order:Superfamily'])\\\n",
    ".drop_duplicates(subset='ID', keep ='last')\n",
    "\n",
    "TE_COS_dict = dict(zip(_tmp_subset.loc[:, 'ID'], _tmp_subset.loc[:, 'Class:Order:Superfamily' ]))\n",
    "\n",
    "_tmp_subset = REPET_gff_df[REPET_gff_df[1].str.contains('SSR')].loc[:, 'ID':].sort_values(by=['ID','Class:Order:Superfamily'])\\\n",
    ".drop_duplicates(subset='ID', keep ='last')\n",
    "\n",
    "_tmp_dict = dict(zip(_tmp_subset.loc[:, 'ID'], _tmp_subset.loc[:, 'Class:Order:Superfamily' ]))\n",
    "\n",
    "TE_COS_dict.update(_tmp_dict)\n",
    "#remove all backslashes from the values as this will conflict with the output later on\n",
    "for x in TE_COS_dict.keys():\n",
    "    if '/' in TE_COS_dict[x]:\n",
    "        value = TE_COS_dict[x]\n",
    "        print(value)\n",
    "        TE_COS_dict[x] = value.replace('/','_')\n",
    "        print(TE_COS_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:10:42.317355Z",
     "start_time": "2019-04-07T07:10:32.235219Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df.to_csv(os.path.join(out_dir,'%s.%s.REPET.long.df' % (genome, Tenovodb)),\n",
    "                    sep='\\t', header = None, index=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:10:42.749174Z",
     "start_time": "2019-04-07T07:10:42.319816Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df['Class:Order:Superfamily'] = REPET_gff_df['ID'].apply(lambda x: TE_COS_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:10:42.817162Z",
     "start_time": "2019-04-07T07:10:42.750933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the unique Class:Order:Superfamily classifiers of this dataframe:\n",
      "['ClassI:LTR:Gypsy' 'ClassII:TIR:?' 'ClassI:LTR:?'\n",
      " 'ClassII:TIR:PIF-Harbinger' 'ClassII:TIR:hAT' 'ClassI:LARD:?'\n",
      " 'ClassII:TIR:Tc1-Mariner' 'ClassII:?:?' 'ClassII:MITE:?'\n",
      " 'ClassII:TIR:MuDR' 'noCat' 'ClassI:DIRS:?' 'ClassII:TIR:CACTA'\n",
      " 'ClassI:LTR:Copia' 'ClassII:?:Academ' 'ClassI:DIRS:DIRS' 'ClassI:TRIM:?'\n",
      " 'ClassII:Helitron:?' 'ClassI:LINE:I' 'ClassI:LINE:Jockey' 'ClassI:LINE:?'\n",
      " 'ClassII:TIR:P' 'ClassII:Helitron:Helitron' 'ClassI:LTR:Retrovirus'\n",
      " 'ClassII:Maverick:?' 'ClassI:SINE:?' 'ClassII:Maverick:Maverick' 'SSR'\n",
      " 'ClassI:LTR:ERV' 'ClassI:?:?' 'ClassII:?:Sola' 'ClassI:LINE:L1'\n",
      " 'ClassI:LINE:RTE' 'ClassII:?:Ginger1' 'ClassII:TIR:Transib'\n",
      " 'ClassI:LTR:Bel-Pao' 'ClassI:LINE:R2' 'ClassII:?:Kolobok'\n",
      " 'ClassI:PLE:Penelope' 'ClassII:Crypton:Crypton' 'ClassII:TIR:PiggyBac']\n"
     ]
    }
   ],
   "source": [
    "print('These are the unique Class:Order:Superfamily classifiers of this dataframe:')\n",
    "print(REPET_gff_df['Class:Order:Superfamily'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:06.161623Z",
     "start_time": "2019-04-07T07:10:42.818881Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#have a rough summary of the coverage not considering overlaps.\n",
    "REPET_gff_df.drop_duplicates(subset=[3,4,'ID'], inplace =True) \n",
    "#this drops all duplicates in the df that completey overlap and have the same ID. Avoid double counting.\n",
    "REPET_gff_df['Length'] = REPET_gff_df[4] - REPET_gff_df[3]\n",
    "REPET_gff_df['Class'] = REPET_gff_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 0), axis=1)\n",
    "REPET_gff_df['Order'] = REPET_gff_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 1), axis=1)\n",
    "REPET_gff_df['Superfamily'] = REPET_gff_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 2), axis=1)\n",
    "REPET_gff_df_COS = REPET_gff_df.groupby(by=['Class','Order','Superfamily'])['Length'].sum()\n",
    "REPET_gff_df_S = REPET_gff_df.groupby(by=['Class:Order:Superfamily'])['Length'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:06.189148Z",
     "start_time": "2019-04-07T07:11:06.166836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the summary of overlapping coverage according to Class, Order, Superfamily\n",
      "Class            Order     Superfamily  \n",
      "DNA_transposon   Crypton   Crypton               441\n",
      "                 Helitron  Helitron          1432515\n",
      "                           noCat             1121863\n",
      "                 MITE      noCat             1525589\n",
      "                 Maverick  Maverick            24863\n",
      "                           noCat              500604\n",
      "                 TIR       CACTA             1881411\n",
      "                           MuDR              3828102\n",
      "                           P                  216121\n",
      "                           PIF-Harbinger     3136647\n",
      "                           PiggyBac              345\n",
      "                           Tc1-Mariner       3016065\n",
      "                           Transib               755\n",
      "                           hAT               6995497\n",
      "                           noCat             4263975\n",
      "                 noCat     Academ            1812746\n",
      "                           Ginger1              3141\n",
      "                           Kolobok              1238\n",
      "                           Sola                 5416\n",
      "                           noCat             5965052\n",
      "Retrotransposon  DIRS      DIRS               884441\n",
      "                           noCat              213206\n",
      "                 LARD      noCat             2721250\n",
      "                 LINE      I                  664303\n",
      "                           Jockey              72622\n",
      "                           L1                   1303\n",
      "                           R2                   4172\n",
      "                           RTE                  2067\n",
      "                           noCat               41909\n",
      "                 LTR       Bel-Pao              5474\n",
      "                           Copia            10926613\n",
      "                           ERV                108112\n",
      "                           Gypsy            24207344\n",
      "                           Retrovirus          25916\n",
      "                           noCat             2887550\n",
      "                 PLE       Penelope             5944\n",
      "                 SINE      noCat               16219\n",
      "                 TRIM      noCat              163951\n",
      "                 noCat     noCat               60554\n",
      "SSR              SSR       SSR               1516937\n",
      "noCat            noCat     noCat              969897\n",
      "Name: Length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the summary of overlapping coverage according to Class, Order, Superfamily\")\n",
    "print(REPET_gff_df_COS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:06.325165Z",
     "start_time": "2019-04-07T07:11:06.190730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the summary of unqiue TE insertions for each Class, Order, Superfamily\n",
      "Class            Order     Superfamily  \n",
      "DNA_transposon   Crypton   Crypton              3\n",
      "                 Helitron  Helitron          2795\n",
      "                           noCat             1578\n",
      "                 MITE      noCat             5625\n",
      "                 Maverick  Maverick            40\n",
      "                           noCat              238\n",
      "                 TIR       CACTA             3186\n",
      "                           MuDR              8114\n",
      "                           P                  853\n",
      "                           PIF-Harbinger     8224\n",
      "                           PiggyBac             3\n",
      "                           Tc1-Mariner       7828\n",
      "                           Transib              4\n",
      "                           hAT              16914\n",
      "                           noCat             6559\n",
      "                 noCat     Academ            2576\n",
      "                           Ginger1             36\n",
      "                           Kolobok              1\n",
      "                           Sola                14\n",
      "                           noCat            20907\n",
      "Retrotransposon  DIRS      DIRS              2158\n",
      "                           noCat              207\n",
      "                 LARD      noCat             4801\n",
      "                 LINE      I                 1454\n",
      "                           Jockey             318\n",
      "                           L1                  14\n",
      "                           R2                  11\n",
      "                           RTE                 22\n",
      "                           noCat               76\n",
      "                 LTR       Bel-Pao             33\n",
      "                           Copia            28901\n",
      "                           ERV               1198\n",
      "                           Gypsy            62146\n",
      "                           Retrovirus          71\n",
      "                           noCat             6375\n",
      "                 PLE       Penelope            27\n",
      "                 SINE      noCat               89\n",
      "                 TRIM      noCat              376\n",
      "                 noCat     noCat              141\n",
      "SSR              SSR       SSR              57765\n",
      "noCat            noCat     noCat             1413\n",
      "Name: Length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the summary of unqiue TE insertions for each Class, Order, Superfamily\")\n",
    "print(REPET_gff_df.groupby(by=['Class','Order','Superfamily'])['Length'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:06.357170Z",
     "start_time": "2019-04-07T07:11:06.326934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the summary of overlapping coverage according to Superfamily\n",
      "Class:Order:Superfamily\n",
      "ClassI:?:?                      60554\n",
      "ClassI:DIRS:?                  213206\n",
      "ClassI:DIRS:DIRS               884441\n",
      "ClassI:LARD:?                 2721250\n",
      "ClassI:LINE:?                   41909\n",
      "ClassI:LINE:I                  664303\n",
      "ClassI:LINE:Jockey              72622\n",
      "ClassI:LINE:L1                   1303\n",
      "ClassI:LINE:R2                   4172\n",
      "ClassI:LINE:RTE                  2067\n",
      "ClassI:LTR:?                  2887550\n",
      "ClassI:LTR:Bel-Pao               5474\n",
      "ClassI:LTR:Copia             10926613\n",
      "ClassI:LTR:ERV                 108112\n",
      "ClassI:LTR:Gypsy             24207344\n",
      "ClassI:LTR:Retrovirus           25916\n",
      "ClassI:PLE:Penelope              5944\n",
      "ClassI:SINE:?                   16219\n",
      "ClassI:TRIM:?                  163951\n",
      "ClassII:?:?                   5965052\n",
      "ClassII:?:Academ              1812746\n",
      "ClassII:?:Ginger1                3141\n",
      "ClassII:?:Kolobok                1238\n",
      "ClassII:?:Sola                   5416\n",
      "ClassII:Crypton:Crypton           441\n",
      "ClassII:Helitron:?            1121863\n",
      "ClassII:Helitron:Helitron     1432515\n",
      "ClassII:MITE:?                1525589\n",
      "ClassII:Maverick:?             500604\n",
      "ClassII:Maverick:Maverick       24863\n",
      "ClassII:TIR:?                 4263975\n",
      "ClassII:TIR:CACTA             1881411\n",
      "ClassII:TIR:MuDR              3828102\n",
      "ClassII:TIR:P                  216121\n",
      "ClassII:TIR:PIF-Harbinger     3136647\n",
      "ClassII:TIR:PiggyBac              345\n",
      "ClassII:TIR:Tc1-Mariner       3016065\n",
      "ClassII:TIR:Transib               755\n",
      "ClassII:TIR:hAT               6995497\n",
      "SSR                           1516937\n",
      "noCat                          969897\n",
      "Name: Length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the summary of overlapping coverage according to Superfamily\")\n",
    "print(REPET_gff_df_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:07.345193Z",
     "start_time": "2019-04-07T07:11:06.358811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of unique TEs: 11651\n",
      "This is the number of unique TE superfamilies: 40\n"
     ]
    }
   ],
   "source": [
    "num_unique_TEs = len(REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')]['ID'].unique())\n",
    "num_unique_TE_super = len(REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')]['Class:Order:Superfamily'].unique())\n",
    "\n",
    "print('This is the number of unique TEs: %i\\nThis is the number of unique TE superfamilies: %i' % (num_unique_TEs, num_unique_TE_super))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:07.405170Z",
     "start_time": "2019-04-07T07:11:07.347034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the count of unique TEs in each category\n",
      "Class:Order:Superfamily\n",
      "ClassI:?:?                     141\n",
      "ClassI:DIRS:?                  207\n",
      "ClassI:DIRS:DIRS              2158\n",
      "ClassI:LARD:?                 4801\n",
      "ClassI:LINE:?                   76\n",
      "ClassI:LINE:I                 1454\n",
      "ClassI:LINE:Jockey             318\n",
      "ClassI:LINE:L1                  14\n",
      "ClassI:LINE:R2                  11\n",
      "ClassI:LINE:RTE                 22\n",
      "ClassI:LTR:?                  6375\n",
      "ClassI:LTR:Bel-Pao              33\n",
      "ClassI:LTR:Copia             28901\n",
      "ClassI:LTR:ERV                1198\n",
      "ClassI:LTR:Gypsy             62146\n",
      "ClassI:LTR:Retrovirus           71\n",
      "ClassI:PLE:Penelope             27\n",
      "ClassI:SINE:?                   89\n",
      "ClassI:TRIM:?                  376\n",
      "ClassII:?:?                  20907\n",
      "ClassII:?:Academ              2576\n",
      "ClassII:?:Ginger1               36\n",
      "ClassII:?:Kolobok                1\n",
      "ClassII:?:Sola                  14\n",
      "ClassII:Crypton:Crypton          3\n",
      "ClassII:Helitron:?            1578\n",
      "ClassII:Helitron:Helitron     2795\n",
      "ClassII:MITE:?                5625\n",
      "ClassII:Maverick:?             238\n",
      "ClassII:Maverick:Maverick       40\n",
      "ClassII:TIR:?                 6559\n",
      "ClassII:TIR:CACTA             3186\n",
      "ClassII:TIR:MuDR              8114\n",
      "ClassII:TIR:P                  853\n",
      "ClassII:TIR:PIF-Harbinger     8224\n",
      "ClassII:TIR:PiggyBac             3\n",
      "ClassII:TIR:Tc1-Mariner       7828\n",
      "ClassII:TIR:Transib              4\n",
      "ClassII:TIR:hAT              16914\n",
      "SSR                          57765\n",
      "noCat                         1413\n",
      "Name: Length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('This is the count of unique TEs in each category')\n",
    "print(REPET_gff_df.groupby(by=['Class:Order:Superfamily'])['Length'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:07.801181Z",
     "start_time": "2019-04-07T07:11:07.406987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the relative number of identified element in each category\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Class:Order:Superfamily\n",
       "ClassI:?:?                    0.072186\n",
       "ClassI:DIRS:?                 0.105975\n",
       "ClassI:DIRS:DIRS              1.104803\n",
       "ClassI:LARD:?                 2.457904\n",
       "ClassI:LINE:?                 0.038909\n",
       "ClassI:LINE:I                 0.744385\n",
       "ClassI:LINE:Jockey            0.162802\n",
       "ClassI:LINE:L1                0.007167\n",
       "ClassI:LINE:R2                0.005632\n",
       "ClassI:LINE:RTE               0.011263\n",
       "ClassI:LTR:?                  3.263724\n",
       "ClassI:LTR:Bel-Pao            0.016895\n",
       "ClassI:LTR:Copia             14.796062\n",
       "ClassI:LTR:ERV                0.613324\n",
       "ClassI:LTR:Gypsy             31.816064\n",
       "ClassI:LTR:Retrovirus         0.036349\n",
       "ClassI:PLE:Penelope           0.013823\n",
       "ClassI:SINE:?                 0.045564\n",
       "ClassI:TRIM:?                 0.192496\n",
       "ClassII:?:?                  10.703480\n",
       "ClassII:?:Academ              1.318801\n",
       "ClassII:?:Ginger1             0.018430\n",
       "ClassII:?:Kolobok             0.000512\n",
       "ClassII:?:Sola                0.007167\n",
       "ClassII:Crypton:Crypton       0.001536\n",
       "ClassII:Helitron:?            0.807868\n",
       "ClassII:Helitron:Helitron     1.430919\n",
       "ClassII:MITE:?                2.879757\n",
       "ClassII:Maverick:?            0.121846\n",
       "ClassII:Maverick:Maverick     0.020478\n",
       "ClassII:TIR:?                 3.357924\n",
       "ClassII:TIR:CACTA             1.631094\n",
       "ClassII:TIR:MuDR              4.154017\n",
       "ClassII:TIR:P                 0.436699\n",
       "ClassII:TIR:PIF-Harbinger     4.210332\n",
       "ClassII:TIR:PiggyBac          0.001536\n",
       "ClassII:TIR:Tc1-Mariner       4.007597\n",
       "ClassII:TIR:Transib           0.002048\n",
       "ClassII:TIR:hAT               8.659236\n",
       "noCat                         0.723395\n",
       "Name: Length, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPET_gff_wo_SSRs_df = REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')]\n",
    "print('This is the relative number of identified element in each category')\n",
    "REPET_gff_wo_SSRs_df.groupby(by=['Class:Order:Superfamily'])['Length'].count()/REPET_gff_wo_SSRs_df .groupby(by=['Class:Order:Superfamily'])['Length'].count().sum()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:12.633410Z",
     "start_time": "2019-04-07T07:11:07.802954Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df.to_csv(os.path.join(out_dir,'%s.%s.REPET.long_v2.df' % (genome, Tenovodb)),\\\n",
    "                    sep='\\t', header = None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:12.646020Z",
     "start_time": "2019-04-07T07:11:12.635483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/Warrior_comp_runs/REPET/TE_analysis'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:14.461171Z",
     "start_time": "2019-04-07T07:11:12.647582Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make new gff files where the ID column is the superfamily level\n",
    "REPET_gff_superfamily = REPET_gff_df.iloc[:,:]\n",
    "REPET_gff_superfamily[8] = REPET_gff_df['Class:Order:Superfamily']\n",
    "REPET_gff_superfamily.iloc[:,0:9].to_csv(\\\n",
    "    os.path.join(out_dir,'%s.%s.REPET.superfamily.gff' % (genome, Tenovodb)),\\\n",
    "                                         sep='\\t', header = None, index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:17.001204Z",
     "start_time": "2019-04-07T07:11:14.462887Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make new gff file where the ID column is the TE level\n",
    "REPET_gff_TE = REPET_gff_df.iloc[:,:]\n",
    "REPET_gff_TE[8] = REPET_gff_TE['ID']\n",
    "REPET_gff_TE.iloc[:,0:9].to_csv(\\\n",
    "    os.path.join(out_dir,'%s.%s.REPET.TE.gff' % (genome, Tenovodb)),\\\n",
    "    sep='\\t', header = None, index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:17.029154Z",
     "start_time": "2019-04-07T07:11:17.003109Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the directory structure to safe specific coverage files\n",
    "TE_types = ['Retrotransposon', 'DNA_transposon', 'noCat', 'SSR']\n",
    "TE_path = [os.path.join(out_dir, x) for x in TE_types]\n",
    "TE_path_dict = dict(zip(TE_types, TE_path))\n",
    "for TE_type in TE_types:\n",
    "    new_path = os.path.join(out_dir, TE_type)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:17.037632Z",
     "start_time": "2019-04-07T07:11:17.030789Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_sf_gff_fh = os.path.join(out_dir,'%s.%s.REPET.superfamily.gff' % (genome, Tenovodb))\n",
    "REPET_TE_gff_fh = os.path.join(out_dir,'%s.%s.REPET.TE.gff' % (genome, Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:17.093187Z",
     "start_time": "2019-04-07T07:11:17.039097Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define some prefixes used to aggregate coverages\n",
    "#and the genome file for bedtools\n",
    "repet_prefix_TE = '%s.%s.REPET.TE' % (genome, Tenovodb)\n",
    "repet_prefix_S =  '%s.%s.REPET.superfamily' % (genome, Tenovodb)\n",
    "genome_file_fh = os.path.join(source_dir, '%s.genome_file' % genome)\n",
    "genome_df = pd.read_csv(genome_file_fh, sep='\\t', header=None,names=['contig', 'length'])\n",
    "genome_size = genome_df['length'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-07T07:11:31.057212Z",
     "start_time": "2019-04-07T07:11:17.094903Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the bedobjects\n",
    "RE_TE_gff = pybedtools.BedTool(REPET_TE_gff_fh)\n",
    "g_TE = RE_TE_gff.remove_invalid().saveas(REPET_TE_gff_fh.replace('gff', 'bedobject'))\n",
    "#use the blast filtered dataframe as well\n",
    "RE_S_gff = pybedtools.BedTool(REPET_sf_gff_fh)\n",
    "g_S = RE_S_gff.remove_invalid().saveas(REPET_sf_gff_fh.replace('gff', 'bedobject'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:30.604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with callculating coverage of ClassI:LARD:?.\n",
      "Done with callculating coverage of ClassII:TIR:PIF-Harbinger.\n",
      "Done with callculating coverage of ClassII:TIR:Tc1-Mariner.\n",
      "Done with callculating coverage of ClassI:LTR:?.\n",
      "Done with callculating coverage of ClassII:?:?.\n",
      "Done with callculating coverage of ClassI:DIRS:?.\n",
      "Done with callculating coverage of ClassII:TIR:hAT.\n",
      "Done with callculating coverage of ClassII:MITE:?.\n",
      "Done with callculating coverage of ClassII:TIR:?.\n",
      "Done with callculating coverage of noCat.\n",
      "Done with callculating coverage of ClassII:TIR:CACTA.\n",
      "Done with callculating coverage of ClassII:TIR:MuDR.\n",
      "Done with callculating coverage of ClassI:LINE:Jockey.\n",
      "Done with callculating coverage of ClassI:DIRS:DIRS.\n",
      "Done with callculating coverage of ClassII:?:Academ.\n",
      "Done with callculating coverage of ClassI:TRIM:?.\n",
      "Done with callculating coverage of ClassI:LINE:I.\n",
      "Done with callculating coverage of ClassII:Helitron:?.\n",
      "Done with callculating coverage of ClassI:LINE:?.\n",
      "Done with callculating coverage of ClassI:LTR:Retrovirus.\n",
      "Done with callculating coverage of ClassII:Helitron:Helitron.\n",
      "Done with callculating coverage of ClassII:TIR:P.\n",
      "Done with callculating coverage of ClassII:Maverick:?.\n",
      "Done with callculating coverage of ClassII:Maverick:Maverick.\n",
      "Done with callculating coverage of ClassI:SINE:?.\n",
      "Done with callculating coverage of ClassI:?:?.\n",
      "Done with callculating coverage of ClassI:LTR:ERV.\n",
      "Done with callculating coverage of ClassII:?:Sola.\n",
      "Done with callculating coverage of ClassI:LINE:L1.\n",
      "Done with callculating coverage of SSR.\n",
      "Done with callculating coverage of ClassI:LTR:Copia.\n",
      "Done with callculating coverage of ClassII:TIR:Transib.\n",
      "Done with callculating coverage of ClassI:LINE:RTE.\n",
      "Done with callculating coverage of ClassII:?:Ginger1.\n",
      "Done with callculating coverage of ClassI:LINE:R2.\n",
      "Done with callculating coverage of ClassI:LTR:Bel-Pao.\n",
      "Done with callculating coverage of ClassII:?:Kolobok.\n",
      "Done with callculating coverage of ClassII:Crypton:Crypton.\n",
      "Done with callculating coverage of ClassI:PLE:Penelope.\n",
      "Done with callculating coverage of ClassI:LTR:Gypsy.\n",
      "Done with callculating coverage of ClassII:TIR:PiggyBac.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use simple loop to loop over the bedcov genome coverage per classification. Keep track if everything is already done.\n",
    "jobs = []\n",
    "superfamily_bed_fh = REPET_sf_gff_fh.replace('gff', 'bedobject')\n",
    "superfamilies = REPET_gff_df['Class:Order:Superfamily'].unique()\n",
    "Parallel(n_jobs=threads)(delayed(subset_id)(ID, superfamily_bed_fh, repet_prefix_S, genome_file_fh)\\\n",
    "                      for ID in superfamilies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:30.847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassII:?:?\n",
      "ClassII:?:Academ\n",
      "ClassII:?:Ginger1\n",
      "ClassII:?:Kolobok\n",
      "ClassII:?:Sola\n",
      "ClassII:Crypton:Crypton\n",
      "ClassII:Helitron:?\n",
      "ClassII:Helitron:Helitron\n",
      "ClassII:MITE:?\n",
      "ClassII:Maverick:?\n",
      "ClassII:Maverick:Maverick\n"
     ]
    }
   ],
   "source": [
    "class_cov_files = []\n",
    "for path in TE_path:\n",
    "    cov_files = [os.path.join(path, x) for x in os.listdir(path) if x.endswith('.cov')]\n",
    "    for file in cov_files:\n",
    "        class_cov_files.append(file)\n",
    "\n",
    "#make a large summary dataframe from all the cov files where the last \n",
    "df_list =[]\n",
    "class_cov_files.sort()\n",
    "for file in class_cov_files:\n",
    "    #print(file)\n",
    "    tmp_df = pd.read_csv(file, sep='\\t', header = None)\n",
    "    tmp_df[\"Class:Order:Superfamily\"] = file.split('.')[-2]\n",
    "    tmp_df.drop_duplicates(inplace=True) #drop all the duplicates meaning same position in the genome and same superfamily\n",
    "    df_list.append(tmp_df)\n",
    "    print(file.split('.')[-2])\n",
    "\n",
    "df_REPET_classification = pd.concat(df_list)\n",
    "df_REPET_classification.to_csv(out_dir+'/'+ repet_prefix_S +'.cov', sep='\\t', header =None, index=None)\n",
    "\n",
    "cov_per_superfamily = df_REPET_classification.pivot_table(values=1, columns= \"Class:Order:Superfamily\", aggfunc='count')\n",
    "#cov_per_contig_per_superfamily = df_REPET_classification.groupby([0, \"Class:Order:Superfamily\"])[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:31.089Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_all_TEs = df_REPET_classification.drop_duplicates([0,1]) #this gets ride of the overlap between different TE families and classes\n",
    "cov_all_TEs = len(cov_all_TEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:31.248Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make superfamily df and add columns for Class, order and superfamily\n",
    "cov_per_superfamily['cov_all_TEs'] = cov_all_TEs\n",
    "cov_per_superfamily_df = cov_per_superfamily.T\n",
    "cov_per_superfamily_df.rename(columns={1: 'bp'}, inplace=True)\n",
    "cov_per_superfamily_df['%'] = cov_per_superfamily_df['bp']/genome_size*100\n",
    "cov_per_superfamily_df['Class:Order:Superfamily'] = cov_per_superfamily_df.index\n",
    "\n",
    "cov_per_superfamily_df['Class'] = cov_per_superfamily_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 0), axis=1)\n",
    "cov_per_superfamily_df['Order'] = cov_per_superfamily_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 1), axis=1)\n",
    "cov_per_superfamily_df['Superfamily'] = cov_per_superfamily_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:31.421Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_superfamily_df.to_csv(out_dir+'/'+repet_prefix_S+'.tab', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:31.822Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for file in class_cov_files:\n",
    "    tmp_df = pd.read_csv(file, sep='\\t', header = None)\n",
    "    tmp_df[\"Class\"] = file.split('.')[-2].split(':')[0] #parse out the Class from the file name\n",
    "    tmp_df.drop_duplicates(inplace=True) #drop all the duplicates meaning same position in the genome and same Class\n",
    "    df_list.append(tmp_df)\n",
    "    #print(file.split('.')[-2].split(':')[0])\n",
    "\n",
    "df_REPET_classification_class = pd.concat(df_list)\n",
    "df_REPET_classification_class.drop_duplicates(inplace=True)\n",
    "df_REPET_classification_class.to_csv(out_dir+'/'+ repet_prefix_S.replace('superfamily', 'Class') +'.cov', sep='\\t', header =None, index=None)\n",
    "\n",
    "cov_per_class = df_REPET_classification_class.pivot_table(values=1, columns= \"Class\", aggfunc='count')\n",
    "#cov_per_contig_per_class = df_REPET_classification_class.groupby([0, \"Class\"])[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:32.065Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a large summary dataframe from all the cov files where the last \n",
    "df_list =[]\n",
    "class_cov_files.sort()\n",
    "for file in class_cov_files:\n",
    "    tmp_df = pd.read_csv(file, sep='\\t', header = None)\n",
    "    if ':' in file:\n",
    "        tmp_df[\"Order\"] = ':'.join(file.split('.')[-2].split(':')[0:2]) #parse out the order from the file name\n",
    "        #print(':'.join(file.split('.')[-2].split(':')[0:2]))\n",
    "    else:\n",
    "        tmp_df[\"Order\"] = file.split('.')[-2].split(':')[0]\n",
    "        #print(file.split('.')[-2].split(':')[0])\n",
    "    tmp_df.drop_duplicates(inplace=True) #drop all the duplicates meaning same position in the genome and same Order\n",
    "    df_list.append(tmp_df)\n",
    "\n",
    "df_REPET_orderification_order = pd.concat(df_list)\n",
    "df_REPET_orderification_order.drop_duplicates(inplace=True)\n",
    "df_REPET_orderification_order.to_csv(out_dir+'/'+ repet_prefix_S.replace('superfamily', 'Order') +'.cov', sep='\\t', header =None, index=None)\n",
    "\n",
    "cov_per_order = df_REPET_orderification_order.pivot_table(values=1, columns= \"Order\", aggfunc='count')\n",
    "#cov_per_contig_per_order = df_REPET_orderification_order.groupby([0, \"Order\"])[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:33.432Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_order['cov_all_TEs'] = cov_all_TEs\n",
    "cov_per_order_df = cov_per_order.T\n",
    "cov_per_order_df.rename(columns={1: 'bp'}, inplace=True)\n",
    "\n",
    "cov_per_order_df['%'] = round(cov_per_order_df['bp']/genome_size*100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:33.663Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_class['cov_all_TEs'] = cov_all_TEs\n",
    "cov_per_class_df = cov_per_class.T\n",
    "cov_per_class_df.rename(columns={1: 'bp'}, inplace=True)\n",
    "\n",
    "cov_per_class_df['%'] = round(cov_per_class_df['bp']/genome_size*100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:33.863Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_class_df.rename(index={'cov_all_TEs': 'Total RE coverage'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:34.104Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_class_df.sort_values('bp', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:34.295Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-talk')\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, ncols=1, figsize=(12,15))\n",
    "fig.suptitle(\"Repetitive elements in P. striformis f. sp. tritici %s\" % genome, fontsize=14, fontweight = 'bold')\n",
    "\n",
    "#color cycle from color blind people \n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "'#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "#plot the overall genome coverage by repetitive element category\n",
    "cov_per_class_df.plot(kind='barh', y='%', ax=ax0,  color='r')\n",
    "ax0.set_xlim([-5,60])\n",
    "ax0.legend().set_visible(False)\n",
    "ax0.set_yticklabels(list(cov_per_class_df.index),fontsize=10, fontweight='bold')\n",
    "ax0.set_ylabel(ylabel='RE categories', fontsize=14, fontweight='bold')\n",
    "\n",
    "#plot class I \n",
    "classI_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'Retrotransposon'].sort_values('%',\\\n",
    "                                                            ascending=True)\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classI_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classI_df['Order'].unique(), tmp_colors))\n",
    "classI_df['Color'] = classI_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "ax1.barh(np.arange(len(classI_df.index)), classI_df['%'],\n",
    "        color=classI_df['Color'], ecolor='black')\n",
    "ax1.set_yticks(np.arange(len(classI_df.index)))\n",
    "ax1.set_xlim([-2,25])\n",
    "ax1.set_yticklabels(list(classI_df.index),fontsize=10, fontweight='bold')\n",
    "ax1.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax1.set_title('ClassI: Retrotransposons', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax1.patches, classI_df['%']):\n",
    "    ax1.annotate('{0:.3f}'.format(value), (18,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "\n",
    "#plot class II\n",
    "classII_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'DNA_transposon'].sort_values('%',\\\n",
    "                                                                                        ascending=True)\n",
    "\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classII_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classII_df['Order'].unique(), tmp_colors))\n",
    "classII_df['Color'] = classII_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "\n",
    "#plot the class II out\n",
    "\n",
    "ax2.barh(np.arange(len(classII_df.index)), classII_df['%'],\n",
    "        color=classII_df['Color'], ecolor='black')\n",
    "\n",
    "ax2.set_xlim([-2,25])\n",
    "ax2.set_yticks(np.arange(len(classII_df.index)))\n",
    "\n",
    "ax2.set_yticklabels(list(classII_df.index),fontsize=10, fontweight='bold')\n",
    "ax2.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax2.set_title('ClassII: DNA transposons', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('% genome coverage', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax2.patches, classII_df['%']):\n",
    "    ax2.annotate('{0:.3f}'.format(value), (18 ,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "    \n",
    "fig.savefig(os.path.join(out_dir, genome+'.REPET_summary_pc.seaborn-talk.png'), dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:34.501Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-talk')\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, ncols=1, figsize=(12,15))\n",
    "fig.suptitle(\"Repetitive elements in P. striformis f. sp. tritici %s\" % genome, fontsize=14, fontweight = 'bold')\n",
    "\n",
    "#color cycle from color blind people \n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "'#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "#plot the overall genome coverage by repetitive element category\n",
    "cov_per_class_df.plot(kind='barh', y='bp', ax=ax0,  color='r')\n",
    "ax0.set_xlim([-5,50000000])\n",
    "ax0.legend().set_visible(False)\n",
    "ax0.set_yticklabels(list(cov_per_class_df.index),fontsize=10, fontweight='bold')\n",
    "ax0.set_ylabel(ylabel='RE categories', fontsize=14, fontweight='bold')\n",
    "\n",
    "#plot class I \n",
    "classI_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'Retrotransposon'].sort_values('%',\\\n",
    "                                                            ascending=True)\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classI_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classI_df['Order'].unique(), tmp_colors))\n",
    "classI_df['Color'] = classI_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "ax1.barh(np.arange(len(classI_df.index)), classI_df['bp'],\n",
    "        color=classI_df['Color'], ecolor='black')\n",
    "ax1.set_yticks(np.arange(len(classI_df.index)))\n",
    "ax1.set_xlim([-2,16000000])\n",
    "ax1.set_yticklabels(list(classI_df.index),fontsize=10, fontweight='bold')\n",
    "ax1.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax1.set_title('ClassI: Retrotransposons', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax1.patches, classI_df['bp']):\n",
    "    ax1.annotate('{0:.2E}'.format(value), (16000000,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "\n",
    "#plot class II\n",
    "classII_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'DNA_transposon'].sort_values('%',\\\n",
    "                                                                                        ascending=True)\n",
    "\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classII_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classII_df['Order'].unique(), tmp_colors))\n",
    "classII_df['Color'] = classII_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "\n",
    "#plot the class II out\n",
    "\n",
    "ax2.barh(np.arange(len(classII_df.index)), classII_df['bp'],\n",
    "        color=classII_df['Color'], ecolor='black')\n",
    "\n",
    "ax2.set_xlim([-2,16000000])\n",
    "ax2.set_yticks(np.arange(len(classII_df.index)))\n",
    "\n",
    "ax2.set_yticklabels(list(classII_df.index),fontsize=10, fontweight='bold')\n",
    "ax2.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax2.set_title('ClassII: DNA transposons', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('bp genome coverage', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax2.patches, classII_df['bp']):\n",
    "    ax2.annotate('{0:.2E}'.format(value), (16000000 ,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "    \n",
    "#fig.savefig(os.path.join(out_dir, genome+'.REPET_summary_bpcov.seaborn-talk.png'), dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now some analysis of the divergence of the TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:34.983Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now get the summary of allTEs == TEs specificaly identified by TEdenovo from REPET\n",
    "REPET_denovoTEs_df = pd.read_csv(\\\n",
    "        os.path.join(TE_postanalysis_dir, '%s_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE.tab' % genome_repet),\\\n",
    "                                names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n",
    "\n",
    "#now get in the summary of all bankBLRx TEs == TEs identified by repbase20.05_ntSeq_cleaned_TE\n",
    "REPET_nt_repbase_df = pd.read_csv(\\\n",
    "    os.path.join(TE_postanalysis_dir, '%s_chr_bankBLRx_path.annotStatsPerTE.tab' % genome_repet) ,\\\n",
    "    names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n",
    "\n",
    "#now get in the summary of all bankBLRtx TEs == TEs identified by repbase20.05_aaSeq_cleaned_TE\n",
    "REPET_aa_repbase_df = pd.read_csv(\\\n",
    "    os.path.join(TE_postanalysis_dir, '%s_chr_bankBLRtx_path.annotStatsPerTE.tab' % genome_repet) ,\\\n",
    "    names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:35.057Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate a df that contains all TEs: TEdenovo, blastx, blastn\n",
    "REPET_all_TEs_df = pd.concat([REPET_denovoTEs_df ,REPET_nt_repbase_df,\\\n",
    "                                       REPET_aa_repbase_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:35.132Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_all_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.copies > 0]\n",
    "REPET_all_TEs_df = REPET_all_TEs_df[~REPET_all_TEs_df.TE.str.startswith(\"Potential\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:35.387Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#update the TE_COS_dict with missing values that come mostly from blastx and blastn searches.\n",
    "missing_TE_keys = list(set(REPET_all_TEs_df.TE.unique())- set(TE_COS_dict.keys()))\n",
    "missing_TE_values  = [x[x.find(':')+1:] for x in missing_TE_keys]\n",
    "TE_COS_dict.update(dict(zip(missing_TE_keys ,missing_TE_values )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:35.945Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the Class/order/superfamily column to the dataframe based on the TE_COS_dict\n",
    "REPET_all_TEs_df[\"COS\"] = REPET_all_TEs_df[\"TE\"].apply(lambda x: TE_COS_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:36.229Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using the formula T=D/t in arXiv:1209.0176 [q-bio] to approximate TE age\n",
    "# where D = (100-meanId)/100 and \n",
    "# t the substitution rate per site per year\n",
    "# generations per year are estimate at 15 10.1111/j.1365-294X.2007.03513.x\n",
    "# estimate of subsitution rate per year = 2 * 10-9 10.1093/oxfordjournals.molbev.a004056 and\n",
    "# 10.1016/j.fbr.2010.03.001\n",
    "REPET_all_TEs_df['TE_age_Mya'] = (((100-REPET_all_TEs_df.meanId)/100)\\\n",
    "                                        /(2*10**-9))/10**6\n",
    "REPET_all_TEs_df['TE_age'] = (((100-REPET_all_TEs_df.meanId)/100)\\\n",
    "                                        /(2*10**-9))\n",
    "REPET_all_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.copies > 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:36.453Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_ClassI_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.COS.str.startswith('ClassI:')]\n",
    "REPET_ClassII_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.COS.str.startswith('ClassII:')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:36.708Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 20}\n",
    "label_config_x = {'fontsize'            : 'large',\n",
    "      'verticalalignment'   : 'top',\n",
    "      'horizontalalignment' : 'center'\n",
    "      }\n",
    "label_config_y = {'fontsize'            : 'large',\n",
    "      'verticalalignment'   : 'bottom',\n",
    "      'horizontalalignment' : 'center'\n",
    "      }\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:37.642Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassI_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassI_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**4, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassI_age.png' % (genome, Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:38.154Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassI_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassI_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**6, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassI_age.png' % (genome, Tenovodb))\n",
    "f.savefig(out_fn, dpi=600,bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:38.572Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassII_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassII_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**6, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassII_age.png' % (genome, Tenovodb))\n",
    "f.savefig(out_fn, dpi=600,bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:39.226Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassII_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassII_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**4, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassII_age.png' % (genome, Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:40.186Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df_young_many = REPET_all_TEs_df[(REPET_all_TEs_df.copies > 50) &( REPET_all_TEs_df.TE_age_Mya < 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:40.698Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df_young_many_by_COS_sum = sub_df_young_many.groupby('COS').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:41.066Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df_young_many_by_COS_sum['Class'] = 'noCat'\n",
    "sub_df_young_many_by_COS_sum[\"Index\"] = sub_df_young_many_by_COS_sum.index\n",
    "sub_df_young_many_by_COS_sum['Order'] = 'noCat'\n",
    "sub_df_young_many_by_COS_sum['Class:Order'] = 'noCat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:41.279Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate Class column or noCat\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Class\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].Index.apply\\\n",
    "(lambda x: x.split(':')[0])\n",
    "\n",
    "#generate Order column or noCat\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Order\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].Index.apply\\\n",
    "(lambda x: x.split(':')[1])\n",
    "\n",
    "\n",
    "#generate Class order column\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Class:Order\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')]['Class']\\\n",
    "+ ':' +\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')]['Order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:42.250Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get color column sorted\n",
    "colors = sns.color_palette('cubehelix', n_colors=\\\n",
    "                           len(sub_df_young_many_by_COS_sum['Class:Order'].unique()))\n",
    "color_dict = dict(zip(sub_df_young_many_by_COS_sum['Class:Order'].unique(), colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:43.306Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df_young_many_by_COS_sum['color'] = sub_df_young_many_by_COS_sum['Class:Order'].apply(\\\n",
    "        lambda x: color_dict[x])\n",
    "color_index_dict = dict(zip(sub_df_young_many_by_COS_sum.Index, sub_df_young_many_by_COS_sum.color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:09:44.393Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "sns.barplot(sub_df_young_many_by_COS_sum.index, sub_df_young_many_by_COS_sum.covg/10**6,\\\n",
    "           palette=color_index_dict)\n",
    "\n",
    "plt.ylabel(\"Coverage [Mb]\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"\",fontsize = 12, weight= 'bold'\"\")\n",
    "sns.despine(trim=True)\n",
    "\n",
    "#change the colors of the legend\n",
    "key_list = list(color_dict.keys())\n",
    "key_list.sort()\n",
    "plt.legend(key_list, loc=(1, 0.1))\n",
    "leg = ax.get_legend()\n",
    "for (x,y) in zip(key_list, leg.legendHandles):\n",
    "    y.set_color(color_dict[x])\n",
    "    \n",
    "\n",
    "\n",
    "for l in ax.get_xticklabels():\n",
    "    l.set_rotation(90)\n",
    "\n",
    "out_fn = os.path.join(out_dir, '%s_%s_TEs_young_and_plenty.png'  % (genome, Tenovodb))\n",
    "f.savefig(out_fn, dpi=600, bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For haplotigs run only up to here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now on to do the coverage analysis for the TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.491Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_window_1k200_bed = BedTool().window_maker(g=genome_file_fh, w=window_size, s=slide_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.494Z"
    }
   },
   "outputs": [],
   "source": [
    "#sort the TE gff file for easier handling with bedtools and convert some to bed files\n",
    "TE_gff_sorted_fh = TE_gff_fh.replace('.gff3', '.sorted.gff3')\n",
    "TE_gff_superfamily_fh = os.path.join(out_dir,'%s.%s.REPET.superfamily.gff' % (genome, Tenovodb))\n",
    "TE_gff_superfamily_sorted_fh = TE_gff_superfamily_fh.replace('.gff', '.sorted.bed')\n",
    "TE_gff_TEfamily_fh = os.path.join(out_dir,'%s.%s.REPET.TE.gff' % (genome, Tenovodb))\n",
    "TE_gff_TEfamily_sorted_fh = TE_gff_TEfamily_fh.replace('.gff', '.sorted.bed') \n",
    "\n",
    "gff3sort_pl = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/get_homologues/gff3sort/gff3sort.pl'\n",
    "cmd1 = 'perl %s %s > %s' %(gff3sort_pl, TE_gff_fh , TE_gff_sorted_fh)\n",
    "cmd2 = \"perl %s %s | awk -v OFS='\\t' '{print $1, $4, $5, $9, $8, $7 }' > %s \" % (gff3sort_pl, TE_gff_superfamily_fh,TE_gff_superfamily_sorted_fh )\n",
    "cmd3 = \"perl %s %s | awk -v OFS='\\t' '{print $1, $4, $5, $9, $8, $7 }' > %s \" % (gff3sort_pl, TE_gff_TEfamily_fh ,TE_gff_TEfamily_sorted_fh )\n",
    "\n",
    "\n",
    "subprocess.check_output(cmd1, shell=True, stderr=subprocess.STDOUT)\n",
    "subprocess.check_output(cmd2, shell=True, stderr=subprocess.STDOUT)\n",
    "subprocess.check_output(cmd3, shell=True, stderr=subprocess.STDOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the bed objects that are windows that will be used for the coverage analysis\n",
    "TE_bed = BedTool(fn=TE_gff_sorted_fh)\n",
    "g_TE_1k200_bed = g_window_1k200_bed.intersect(TE_bed)\n",
    "g_noTE_1k200_bed = g_window_1k200_bed.subtract(TE_bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.505Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now read in the bam files as beds\n",
    "pbam_bed = BedTool(fn=pbam_fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.509Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define outfile names to write out the coverage files\n",
    "TE_cov_dir = os.path.join(out_dir, 'TE_COV')\n",
    "if not os.path.exists(TE_cov_dir):\n",
    "    os.mkdir(TE_cov_dir)\n",
    "#really we want to do samtools bedcov    \n",
    "g_TE_1k200_samcovfh = os.path.join(TE_cov_dir, '%s.%s.g_TE_%ik%i.samcov' % (genome, Tenovodb, window_size/1000, slide_size ))\n",
    "g_noTE_1k200_samcovfh = os.path.join(TE_cov_dir, '%s.%s.g_noTE_%ik%i.samcov' % (genome, Tenovodb, window_size/1000, slide_size ))\n",
    "g_window_1k200_samcovfh = os.path.join(TE_cov_dir, '%s.%s.g_window_%ik%i.samcov' % (genome, Tenovodb, window_size/1000, slide_size ))\n",
    "TE_gff_superfamily_samcovfh = os.path.join(TE_cov_dir, TE_gff_superfamily_sorted_fh.split('/')[-1].replace('.bed','.samcov'))\n",
    "TE_gff_TEfamily_samcovfh = os.path.join(TE_cov_dir,TE_gff_TEfamily_sorted_fh.split('/')[-1].replace('.bed','.samcov'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.513Z"
    }
   },
   "outputs": [],
   "source": [
    "g_window_1k200_bed.saveas(g_window_1k200_samcovfh.replace('.samcov', '.bed'))\n",
    "g_TE_1k200_bed.saveas(g_TE_1k200_samcovfh.replace('.samcov', '.bed'))\n",
    "g_noTE_1k200_bed.saveas(g_noTE_1k200_samcovfh.replace('.samcov', '.bed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.517Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make the BUSCOs bed file\n",
    "busco_df = pd.read_csv(protein_busco_fh, comment='#', header=None, sep='\\t')\n",
    "single_buscos = busco_df[busco_df[1] == 'Complete'][2].tolist()\n",
    "gene_bed_fh = os.path.join(source_dir, '%s.gene.bed' % genome) \n",
    "gene_bed_df = pd.read_csv(gene_bed_fh, sep='\\t', header=None)\n",
    "single_busco_bed_fh = os.path.join(out_dir, '%s.sBUSCO.bed'%genome)\n",
    "single_busco_samcov_fh = os.path.join(TE_cov_dir, single_busco_bed_fh.split('/')[-1].replace('bed', 'samcov'))\n",
    "gene_bed_df[gene_bed_df[3].isin(single_buscos)].to_csv(single_busco_bed_fh, sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.521Z"
    }
   },
   "outputs": [],
   "source": [
    "beds = [g_TE_1k200_samcovfh.replace('.samcov', '.bed'),\\\n",
    "        g_noTE_1k200_samcovfh.replace('.samcov', '.bed'),\\\n",
    "        g_window_1k200_samcovfh.replace('.samcov', '.bed') ,\\\n",
    "       single_busco_bed_fh,\\\n",
    "       TE_gff_superfamily_sorted_fh,\\\n",
    "        TE_gff_TEfamily_sorted_fh]\n",
    "outs = [g_TE_1k200_samcovfh, g_noTE_1k200_samcovfh, g_window_1k200_samcovfh,\\\n",
    "        single_busco_samcov_fh, TE_gff_superfamily_samcovfh,  TE_gff_TEfamily_samcovfh]\n",
    "Parallel(n_jobs=len(beds))(delayed(run_samtools_bedcov)(bed, pbam_fh, out)\\\n",
    "                      for bed, out in zip(beds, outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.525Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now make the BUSCO dataframe\n",
    "sBUSCO_df = samcov_slurp( single_busco_samcov_fh, fil=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.529Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sBUSCO_df['contig_number'] = [int(x[-1]) for x in sBUSCO_df.contig.str.split('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.533Z"
    }
   },
   "outputs": [],
   "source": [
    "sBUSCO_df.plot(x='contig_number', y='norm_cov', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.537Z"
    }
   },
   "outputs": [],
   "source": [
    "sBUSCO_df['norm_cov'].plot(kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.542Z"
    }
   },
   "outputs": [],
   "source": [
    "sBUSCO_mean = sum(sBUSCO_df.total_cov)/sum(sBUSCO_df.interval_size)\n",
    "print('The single BUSCO mean coverage is %0.2f.' % sBUSCO_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.548Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_TE_1k200_samcov_df = samcov_slurp(g_TE_1k200_samcovfh, mean=sBUSCO_mean ,fil=False)\n",
    "g_noTE_1k200_samcov_df = samcov_slurp(g_noTE_1k200_samcovfh,mean=sBUSCO_mean, fil=False)\n",
    "g_window_1k200_samcov_df = samcov_slurp(g_window_1k200_samcovfh,mean=sBUSCO_mean,fil=False)\n",
    "TE_gff_superfamily_samcov_df = samcov_slurp(TE_gff_superfamily_samcovfh,mean=sBUSCO_mean,fil=False)\n",
    "TE_gff_TEfamily_samcov_df = samcov_slurp(TE_gff_TEfamily_samcovfh,mean=sBUSCO_mean,fil=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T05:33:05.219363Z",
     "start_time": "2018-04-05T05:30:32.313775Z"
    }
   },
   "source": [
    "sBUSCO_df['norm_cov'].plot(kind='kde',color='k')\n",
    "g_TE_1k200_samcov_df['norm_cov'].plot(kind='kde',color='r')\n",
    "g_window_1k200_samcov_df['norm_cov'].plot(kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.724Z"
    }
   },
   "outputs": [],
   "source": [
    "sBUSCO_df['norm_cov'].plot(kind='hist',color='k', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.732Z"
    }
   },
   "outputs": [],
   "source": [
    "TE_gff_superfamily_samcov_df['log10_ncov'] = np.log10(TE_gff_superfamily_samcov_df['norm_cov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.743Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,15))\n",
    "order = pd.concat([classI_df.sort_values('bp', ascending=False)['Class:Order:Superfamily'],  \\\n",
    "                   classII_df.sort_values('bp', ascending=False)['Class:Order:Superfamily']])\n",
    "sns.boxplot(x='ID', y='log10_ncov', data=TE_gff_superfamily_samcov_df, ax=ax, order=order)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.754Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genome_size = pd.read_csv(genome_file_fh, sep='\\t',header=None)[1].sum()\n",
    "mean_genome = sum(g_window_1k200_samcov_df.total_cov)/sum(g_window_1k200_samcov_df.interval_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.761Z"
    }
   },
   "outputs": [],
   "source": [
    "genome_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.773Z"
    }
   },
   "outputs": [],
   "source": [
    "int(genome_size *(mean_genome/sBUSCO_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.781Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_TEs = sum(g_TE_1k200_samcov_df.total_cov)/sum(g_TE_1k200_samcov_df.interval_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.793Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_sfamily_TEs = sum(TE_gff_superfamily_samcov_df.total_cov)/sum(TE_gff_superfamily_samcov_df.interval_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.802Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_sfamily_TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.810Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.825Z"
    }
   },
   "outputs": [],
   "source": [
    "sBUSCO_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.835Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.843Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(g_noTE_1k200_samcov_df.total_cov)/sum(g_noTE_1k200_samcov_df.interval_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.851Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(g_TE_1k200_samcov_df.total_cov)/sum(g_TE_1k200_samcov_df.interval_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.860Z"
    }
   },
   "outputs": [],
   "source": [
    "TE_gff_superfamily_samcov_df.pivot_table(values='norm_cov', columns='ID', aggfunc=[np.mean, np.count_nonzero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.877Z"
    }
   },
   "outputs": [],
   "source": [
    "TE_gff_superfamily_samcov_df.groupby('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-07T07:05:12.892Z"
    }
   },
   "outputs": [],
   "source": [
    "TE_gff_superfamily_samcov_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
