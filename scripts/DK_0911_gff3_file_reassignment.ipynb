{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "ANNOTATION_PATH = '/home/gamran/genome_analysis/Warrior/annotation/'\n",
    "\n",
    "H_GFF_PATH_IN = os.path.join(ANNOTATION_PATH, 'DK_0911_v01_h_ctg/DK_0911_v01_h_ctg.evm.all.lt.gff3')\n",
    "P_GFF_PATH_IN = os.path.join(ANNOTATION_PATH + 'DK_0911_v01_p_ctg/DK_0911_v01_p_ctg.evm.all.lt.gff3')\n",
    "\n",
    "P_GENOME_OUT = 'DK_0911_v031_p_ctg'\n",
    "H_GENOME_OUT = 'DK_0911_v031_h_ctg'\n",
    "\n",
    "P_GFF_PATH_OUT = os.path.join(ANNOTATION_PATH, P_GENOME_OUT, '%s.anno.gff3' % P_GENOME_OUT)\n",
    "H_GFF_PATH_OUT = os.path.join(ANNOTATION_PATH, H_GENOME_OUT, '%s.anno.gff3' % H_GENOME_OUT)\n",
    "\n",
    "pCtg_df = pd.read_table(P_GFF_PATH_IN, skiprows = 1, header = None, index_col = 0, \\\n",
    "                  names = ['seqid', 'source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes'])\n",
    "htg_df = pd.read_table(H_GFF_PATH_IN, skiprows = 1, header = None, index_col = 0, \\\n",
    "                  names = ['seqid', 'source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes']) \n",
    "\n",
    "def assign(pwohNum, pwhNum, pCtg_df, htg_df):\n",
    "    '''Assigns a single pwoh to a pwh, removing the pwoh from the \n",
    "    gff pCtg_df and assigning it to the gff htg_df with the correct\n",
    "    naming convention. For example, pcontig_086 that is a pwoh\n",
    "    belonging to pcontig_039 will be renamed to hcontig_039_086 and\n",
    "    removed from pCtg_df and added to htg_df.'''\n",
    "    '''NOTE that this does not handle duplicates (e.g. if hcontig_039_086\n",
    "    already exists, this function does nothing to handle this case)'''\n",
    "    \n",
    "    # e.g. 86 -> '086'\n",
    "    pwohNum = '0'*(3-len(str(pwohNum))) + str(pwohNum)\n",
    "    pwhNum = '0'*(3-len(str(pwhNum))) + str(pwhNum)\n",
    "    \n",
    "    htg = pCtg_df.loc['pcontig_' + pwohNum]\n",
    "    pCtg_df = pCtg_df.drop('pcontig_' + pwohNum)\n",
    "    htg.index = ['hcontig_%s_%s' % (pwhNum, pwohNum)]*len(htg.index)\n",
    "    htg_df = pd.concat([htg_df, htg])\n",
    "    \n",
    "    return pCtg_df, htg_df\n",
    "\n",
    "# pCtg_df, htg_df = assign(86, 39, pCtg_df, htg_df)\n",
    "\n",
    "def testAssign(pCtg_df, htg_df):\n",
    "    '''tests assign() function with one example case. Checks that pwoh was removed\n",
    "    from pCtg_df and also that it was reassigned to the htg_df with the correct naming'''\n",
    "    \n",
    "    newHtgs = len(pCtg_df[[s.startswith('pcontig_086') for s in pCtg_df.index]])\n",
    "    startHtgs = len(htg_df[[s.startswith('hcontig_039') for s in htg_df.index]])\n",
    "    \n",
    "    pCtg_df, htg_df = assign(86, 39, pCtg_df, htg_df)\n",
    "    assert(len(pCtg_df[[s.startswith('pcontig_086') for s in pCtg_df.index]]) == 0)\n",
    "    \n",
    "    finalHtgs = len(htg_df[[s.startswith('hcontig_039') for s in htg_df.index]])\n",
    "    assert(finalHtgs == newHtgs + startHtgs)\n",
    "\n",
    "    return True\n",
    "\n",
    "testAssign(pCtg_df, htg_df)\n",
    "\n",
    "def assignMany(pairs, pCtg_df, htg_df):\n",
    "    for pwohNum, pwhNum in pairs:\n",
    "        pCtg_df, htg_df = assign(pwohNum, pwhNum, pCtg_df, htg_df)\n",
    "    return pCtg_df, htg_df\n",
    "\n",
    "pairs = [(86, 39), \\\n",
    "        (96, 33), \\\n",
    "        (97, 39), \\\n",
    "        (100, 33), \\\n",
    "        (103, 74)]\n",
    "\n",
    "pCtg_df, htg_df = assignMany(pairs, pCtg_df, htg_df)\n",
    "\n",
    "# pCtg_df[[s.startswith('pcontig_086') for s in pCtg_df.index]]\n",
    "# htg_df[[s.startswith('hcontig_074') for s in htg_df.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write haplotigs to new file (v03)\n",
    "if not os.path.exists(os.path.join(ANNOTATION_PATH, H_GENOME_OUT)):\n",
    "    os.mkdir(os.path.join(ANNOTATION_PATH, H_GENOME_OUT))\n",
    "with open(H_GFF_PATH_OUT, 'w') as outfile:\n",
    "    htg_df.to_csv(outfile, sep='\\t', header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write primary contigs to new file (v03)\n",
    "if not os.path.exists(os.path.join(ANNOTATION_PATH, P_GENOME_OUT)):\n",
    "    os.mkdir(os.path.join(ANNOTATION_PATH, P_GENOME_OUT))\n",
    "with open(P_GFF_PATH_OUT, 'w') as outfile:\n",
    "    pCtg_df.to_csv(outfile, sep='\\t', header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix attributes column\n",
    "def fixHtgAttributes(row):\n",
    "    '''With the above code, the attributes column is not changed for\n",
    "    hcontigs that are manually assigned. This changes the attributes\n",
    "    column of a DataFrame row to the correct format.\n",
    "    \n",
    "    E.g. hcontig_074_103 would have attributes column:\n",
    "    ID=cds.evm.model.pcontig_103.5;Parent=evm.model.pcontig_103.5\n",
    "    \n",
    "    This code will change the column to:\n",
    "    ID=cds.evm.model.hcontig_074_103.5;Parent=evm.model.hcontig_074_103.5'''\n",
    "    \n",
    "    attributes = row['attributes']\n",
    "    contigLoc = row['contigLoc'] # e.g. pcontig_103.5 (incorrect if manually assigned)\n",
    "    seqid = row['seqid'] # e.g. hcontig_074_103\n",
    "    \n",
    "    numberSuffix = contigLoc.split('.')[-1]\n",
    "    \n",
    "    if attributes.find('pcontig') == -1:\n",
    "        return attributes\n",
    "    return attributes.replace(contigLoc, '%s.%s' %(seqid, str(numberSuffix)))\n",
    "\n",
    "pCtg_gff_df = pd.read_table(P_GFF_PATH_OUT, header = None, index_col = None, \\\n",
    "                  names = ['seqid', 'source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes'])\n",
    "htg_gff_df = pd.read_table(H_GFF_PATH_OUT, header = None, index_col = None, \\\n",
    "                  names = ['seqid', 'source', 'type', 'start', 'end', 'score', 'strand', 'phase', 'attributes']) \n",
    "\n",
    "ID_SEARCH = re.compile(r'^.*ID=(.*?)(;|$)')\n",
    "P_CONTIG_LOC_SEARCH = re.compile(r'^.*\\.(pcontig_\\d{3}\\.\\d+)(?:\\.|$)') # P_CONTIG_LOC_SEARCH.match('cds.evm.model.pcontig_000.1').group(1) will extract 'pcontig_000.1' \n",
    "H_CONTIG_LOC_SEARCH = re.compile(r'^.*\\.((?:p|h)contig_\\d{3}(?:_\\d{3})?\\.\\d+)(?:\\.|$)') # H_CONTIG_LOC_SEARCH.match('evm.model.hcontig_006_028.2').group(1) will extract 'hcontig_006_028.2'\n",
    "\n",
    "pCtg_gff_df['contigID'] = pCtg_gff_df['attributes'].apply(lambda s: ID_SEARCH.match(s).group(1))\n",
    "pCtg_gff_df['contigLoc'] = pCtg_gff_df['contigID'].apply(lambda s: P_CONTIG_LOC_SEARCH.match(s).group(1))\n",
    "\n",
    "htg_gff_df['contigID'] = htg_gff_df['attributes'].apply(lambda s: ID_SEARCH.match(s).group(1))\n",
    "htg_gff_df['contigLoc'] = htg_gff_df['contigID'].apply(lambda s: H_CONTIG_LOC_SEARCH.match(s).group(1))\n",
    "\n",
    "# fix attributes column in genome v03, and re-write this as genome v031 \n",
    "htg_gff_df['attributes'] = htg_gff_df.apply(fixHtgAttributes, axis=1)\n",
    "htg_gff_df.drop(['contigID', 'contigLoc'], inplace=True, axis=1)\n",
    "pCtg_gff_df.drop(['contigID', 'contigLoc'], inplace=True, axis=1)\n",
    "\n",
    "htg_gff_df.to_csv(H_GFF_PATH_OUT, sep='\\t', header=None, index=None)\n",
    "pCtg_gff_df.to_csv(P_GFF_PATH_OUT, sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
